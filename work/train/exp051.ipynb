{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyPgEmlV2S+Kei/t+GoNisTc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b5b2ca5afca4466990922545c0cd2dc9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eb197981c25d40b89f5b642d53a242f6","IPY_MODEL_099e2528f9ae4080b7a87f3cedb80282","IPY_MODEL_0c40f26d83b343e6a72be78648f6d7e7"],"layout":"IPY_MODEL_d25fb7c3779a42638a2bd9f95baf70e6"}},"eb197981c25d40b89f5b642d53a242f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1aad23906c644058fe7d0659ea4d9c8","placeholder":"​","style":"IPY_MODEL_04778d35365e4259a63f135db952d34f","value":"Downloading tokenizer_config.json: 100%"}},"099e2528f9ae4080b7a87f3cedb80282":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_302df032defd45939976b2d214bd6fcd","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68614c8f3d9d42489f96c52c412dd0a8","value":52}},"0c40f26d83b343e6a72be78648f6d7e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5898771ef074e33ae883b3c6f5865e0","placeholder":"​","style":"IPY_MODEL_a2066cb5123047b8ab2b95297d9a5352","value":" 52.0/52.0 [00:00&lt;00:00, 4.24kB/s]"}},"d25fb7c3779a42638a2bd9f95baf70e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1aad23906c644058fe7d0659ea4d9c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04778d35365e4259a63f135db952d34f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"302df032defd45939976b2d214bd6fcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68614c8f3d9d42489f96c52c412dd0a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d5898771ef074e33ae883b3c6f5865e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a2066cb5123047b8ab2b95297d9a5352":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c79b57dd0884eb282d9ce5c861e18d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_006d504f4f744d66852de758e636f5c1","IPY_MODEL_6b4208eaef7747078c843a5dc427ff0d","IPY_MODEL_81ee5b979f9449c99fa80190a3e8375c"],"layout":"IPY_MODEL_bf330b407ddd4735b01df967f8a6729c"}},"006d504f4f744d66852de758e636f5c1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f3ffb5d447a43cc9a7bd05437fe9691","placeholder":"​","style":"IPY_MODEL_fa22bb650ea04b44aedfa4353a943c05","value":"Downloading config.json: 100%"}},"6b4208eaef7747078c843a5dc427ff0d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_178d4021b83044cea280ed5d01a04f54","max":580,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae570709b9d445a7b4a148e742ae77b1","value":580}},"81ee5b979f9449c99fa80190a3e8375c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_feb1449800ed4da7b6e35f9ec9b73446","placeholder":"​","style":"IPY_MODEL_21c026243cbd4a4cabe9f415260a5bb5","value":" 580/580 [00:00&lt;00:00, 49.4kB/s]"}},"bf330b407ddd4735b01df967f8a6729c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f3ffb5d447a43cc9a7bd05437fe9691":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa22bb650ea04b44aedfa4353a943c05":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"178d4021b83044cea280ed5d01a04f54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae570709b9d445a7b4a148e742ae77b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"feb1449800ed4da7b6e35f9ec9b73446":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21c026243cbd4a4cabe9f415260a5bb5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84e0ba60d9994cabb4e5dd6d4e8bcab9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80c3a21831e5464e9430bc8b988aabd9","IPY_MODEL_0b2581d9984d4d569395d82f85968b5b","IPY_MODEL_9ff3ce76c37c4f0ea8dcdd3a6278e431"],"layout":"IPY_MODEL_217b46459dde44a78e9687eb5d2abfc3"}},"80c3a21831e5464e9430bc8b988aabd9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dabb88472954014babd5db29cf695c6","placeholder":"​","style":"IPY_MODEL_d3873b75020a4896b0334ad3c38624e6","value":"Downloading spm.model: 100%"}},"0b2581d9984d4d569395d82f85968b5b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5efe0ae0989647b5a2d9974267731603","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee92f988398b49909105f663970d4f54","value":2464616}},"9ff3ce76c37c4f0ea8dcdd3a6278e431":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd99bcc3832e43cb93f2c81440746b9e","placeholder":"​","style":"IPY_MODEL_7d15e25ed8ec40e9b74c1680a7513f28","value":" 2.35M/2.35M [00:00&lt;00:00, 56.6MB/s]"}},"217b46459dde44a78e9687eb5d2abfc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dabb88472954014babd5db29cf695c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3873b75020a4896b0334ad3c38624e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5efe0ae0989647b5a2d9974267731603":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee92f988398b49909105f663970d4f54":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dd99bcc3832e43cb93f2c81440746b9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d15e25ed8ec40e9b74c1680a7513f28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"70f044259b47437295d5aa729b8d0a82":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ce22454b9316415ba6b60c017f7927ef","IPY_MODEL_8f82d74170864279baf636bdb6368cbe","IPY_MODEL_12c089c32f0a45499d68f1d6ef57e240"],"layout":"IPY_MODEL_feada0cfc87d4fccbe6f39c6678a0b31"}},"ce22454b9316415ba6b60c017f7927ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_43cdc6ab78bb4f0fb6088c3782987fa0","placeholder":"​","style":"IPY_MODEL_6a187200701943f3bceddfd52796e833","value":"Downloading pytorch_model.bin: 100%"}},"8f82d74170864279baf636bdb6368cbe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8093e47a4da4e199e6d361c6be784f2","max":873673253,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d304ff7ae7134f75ba9c428f23455e76","value":873673253}},"12c089c32f0a45499d68f1d6ef57e240":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0736921bc8b74fcab6b2ae9d7aad4a32","placeholder":"​","style":"IPY_MODEL_e04c4eb54e754609979db1e40278fbef","value":" 833M/833M [00:10&lt;00:00, 86.9MB/s]"}},"feada0cfc87d4fccbe6f39c6678a0b31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43cdc6ab78bb4f0fb6088c3782987fa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a187200701943f3bceddfd52796e833":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8093e47a4da4e199e6d361c6be784f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d304ff7ae7134f75ba9c428f23455e76":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0736921bc8b74fcab6b2ae9d7aad4a32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e04c4eb54e754609979db1e40278fbef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rr85FWn_hyin","executionInfo":{"status":"ok","timestamp":1696607035582,"user_tz":-540,"elapsed":29406,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"dff11800-6a33-44bb-ea78-7e3d54808d17"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install datasets\n","!pip install sentencepiece\n","!pip install transformers==4.21.2\n","!pip install tokenizers==0.12.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ELMmTK3h2by","executionInfo":{"status":"ok","timestamp":1696607059906,"user_tz":-540,"elapsed":24328,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"920260ea-ccfc-4701-ad2d-3fc800718813"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n","Successfully installed datasets-2.14.5 dill-0.3.7 huggingface-hub-0.17.3 multiprocess-0.70.15 xxhash-3.4.1\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Collecting transformers==4.21.2\n","  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (3.12.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (0.17.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.21.2)\n","  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.2) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.2) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.21.2) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.21.2) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.21.2) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.21.2) (2023.7.22)\n","Installing collected packages: tokenizers, transformers\n","Successfully installed tokenizers-0.12.1 transformers-4.21.2\n","Requirement already satisfied: tokenizers==0.12.1 in /usr/local/lib/python3.10/dist-packages (0.12.1)\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mHhBDONhh4Aa","executionInfo":{"status":"ok","timestamp":1696607060510,"user_tz":-540,"elapsed":608,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"f2343f46-5705-46ca-9ece-a26dac97d21c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Oct  6 15:44:20 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P0    52W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    apex=True\n","    print_freq=20\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-large\"\n","    gradient_checkpointing=False\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=4\n","    encoder_lr=5e-6\n","    decoder_lr=5e-6\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=4\n","    max_len=1024\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    target_size=2\n","    fc_dropout=0.2\n","    target_cols=['content','wording']\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    train=True\n","    freezing=True\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"],"metadata":{"id":"1DXnDEPnh58g","executionInfo":{"status":"ok","timestamp":1696607060510,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","DIR = '/content/drive/MyDrive/Competitions/Kaggle/Commonlit'\n","INPUT_DIR = os.path.join(DIR,'input')\n","OUTPUT_DIR = os.path.join(DIR,'output')\n","OUTPUT_MODEL_DIR = DIR + '/output/EXP051/'\n","if not os.path.exists(OUTPUT_MODEL_DIR):\n","    os.makedirs(OUTPUT_MODEL_DIR)"],"metadata":{"id":"n8DPRxxZiMQ5","executionInfo":{"status":"ok","timestamp":1696607062029,"user_tz":-540,"elapsed":1521,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Library\n","# ====================================================\n","from google.colab import runtime\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","from text_unidecode import unidecode\n","from typing import Dict, List, Tuple\n","import codecs\n","\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW, Optimizer\n","from torch.utils.data import DataLoader, Dataset\n","from torch.autograd.function import InplaceFunction\n","import torch.nn.init as init\n","\n","#os.system('pip uninstall -y transformers')\n","#os.system('pip uninstall -y tokenizers')\n","#os.system('python -m pip install --no-index --find-links=/content/drive/MyDrive/Competitions/Kaggle/FeedBack3/pip_wheel.ipynb transformers')\n","#os.system('python -m pip install --no-index --find-links=/content/drive/MyDrive/Competitions/Kaggle/FeedBack3/pip_wheel.ipynb tokenizers')\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup,get_polynomial_decay_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oeXsVFCtiTfX","executionInfo":{"status":"ok","timestamp":1696607070759,"user_tz":-540,"elapsed":8734,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"d0b82108-af4f-46e6-c362-47cd25ef1e89"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tokenizers.__version__: 0.12.1\n","transformers.__version__: 4.21.2\n","env: TOKENIZERS_PARALLELISM=true\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# Utils\n","# ====================================================\n","def MCRMSE(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]\n","        y_pred = y_preds[:,i]\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n","\n","\n","def get_score(y_trues, y_preds):\n","    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n","    return mcrmse_score, scores\n","\n","\n","def get_logger(filename=OUTPUT_MODEL_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(seed=CFG.seed)"],"metadata":{"id":"T-pk0LlXiX24","executionInfo":{"status":"ok","timestamp":1696607070759,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","\n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","\n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","\n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","\n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","\n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","\n","        if hasattr(embeddings_path, attr_name):\n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"XJzsTvmkigu5","executionInfo":{"status":"ok","timestamp":1696607070759,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["prompts_train = pd.read_csv(os.path.join(INPUT_DIR,'prompts_train.csv'))\n","summary_train = pd.read_csv(os.path.join(INPUT_DIR,'summaries_train.csv'))\n","\n","print(f\"Prompt Train.shape: {prompts_train.shape}\")\n","display(prompts_train.head())\n","print(f\"Summary Train.shape: {summary_train.shape}\")\n","display(summary_train.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"qoiequW3ikcn","executionInfo":{"status":"ok","timestamp":1696607072466,"user_tz":-540,"elapsed":1710,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"981a38b4-a07a-4839-bc26-254d1d2737d9"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Prompt Train.shape: (4, 4)\n"]},{"output_type":"display_data","data":{"text/plain":["  prompt_id                                    prompt_question               prompt_title                                        prompt_text\n","0    39c16e  Summarize at least 3 elements of an ideal trag...                 On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...\n","1    3b9047  In complete sentences, summarize the structure...  Egyptian Social Structure  Egyptian society was structured like a pyramid...\n","2    814d6b  Summarize how the Third Wave developed over su...             The Third Wave  Background \\r\\nThe Third Wave experiment took ...\n","3    ebad26  Summarize the various ways the factory would u...    Excerpt from The Jungle  With one member trimming beef in a cannery, an..."],"text/html":["\n","  <div id=\"df-b52f15f5-80f5-4689-b411-1ccbed11d94f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt_id</th>\n","      <th>prompt_question</th>\n","      <th>prompt_title</th>\n","      <th>prompt_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3b9047</td>\n","      <td>In complete sentences, summarize the structure...</td>\n","      <td>Egyptian Social Structure</td>\n","      <td>Egyptian society was structured like a pyramid...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>814d6b</td>\n","      <td>Summarize how the Third Wave developed over su...</td>\n","      <td>The Third Wave</td>\n","      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ebad26</td>\n","      <td>Summarize the various ways the factory would u...</td>\n","      <td>Excerpt from The Jungle</td>\n","      <td>With one member trimming beef in a cannery, an...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b52f15f5-80f5-4689-b411-1ccbed11d94f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b52f15f5-80f5-4689-b411-1ccbed11d94f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b52f15f5-80f5-4689-b411-1ccbed11d94f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-db24859c-d30d-4322-8c82-0c97c14cabc4\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db24859c-d30d-4322-8c82-0c97c14cabc4')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-db24859c-d30d-4322-8c82-0c97c14cabc4 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Summary Train.shape: (7165, 5)\n"]},{"output_type":"display_data","data":{"text/plain":["     student_id prompt_id                                               text   content   wording\n","0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...  0.205683  0.380538\n","1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme... -0.548304  0.506755\n","2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...  3.128928  4.231226\n","3  005ab0199905    3b9047  The highest class was Pharaohs these people we... -0.210614 -0.471415\n","4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...  3.272894  3.219757"],"text/html":["\n","  <div id=\"df-28430ece-48a0-4d69-9638-2985373a52b6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>prompt_id</th>\n","      <th>text</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000e8c3c7ddb</td>\n","      <td>814d6b</td>\n","      <td>The third wave was an experimentto see how peo...</td>\n","      <td>0.205683</td>\n","      <td>0.380538</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0020ae56ffbf</td>\n","      <td>ebad26</td>\n","      <td>They would rub it up with soda to make the sme...</td>\n","      <td>-0.548304</td>\n","      <td>0.506755</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>004e978e639e</td>\n","      <td>3b9047</td>\n","      <td>In Egypt, there were many occupations and soci...</td>\n","      <td>3.128928</td>\n","      <td>4.231226</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>005ab0199905</td>\n","      <td>3b9047</td>\n","      <td>The highest class was Pharaohs these people we...</td>\n","      <td>-0.210614</td>\n","      <td>-0.471415</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0070c9e7af47</td>\n","      <td>814d6b</td>\n","      <td>The Third Wave developed  rapidly because the ...</td>\n","      <td>3.272894</td>\n","      <td>3.219757</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28430ece-48a0-4d69-9638-2985373a52b6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-28430ece-48a0-4d69-9638-2985373a52b6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-28430ece-48a0-4d69-9638-2985373a52b6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-6d03f667-0db3-4eb7-b16e-cae9ae8ecbd5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d03f667-0db3-4eb7-b16e-cae9ae8ecbd5')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-6d03f667-0db3-4eb7-b16e-cae9ae8ecbd5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{}}]},{"cell_type":"code","source":["train = prompts_train.merge(summary_train, on=\"prompt_id\")\n","display(train.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"emiPv2lpi1wX","executionInfo":{"status":"ok","timestamp":1696607072467,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"b88d5448-fc87-4498-d153-af5063ac47e2"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["  prompt_id                                    prompt_question prompt_title                                        prompt_text    student_id                                               text   content   wording\n","0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415\n","1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058\n","2    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...  0094589c7a22  Aristotle states that an ideal tragedy should ... -0.387791 -0.584181\n","3    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...  00cd5736026a  One element of an Ideal tragedy is having a co...  0.088882 -0.594710\n","4    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...  00d98b8ff756  The 3 ideal of tragedy is how complex you need... -0.687288 -0.460886"],"text/html":["\n","  <div id=\"df-7cdcf71f-bbbd-4523-8812-741c48a15350\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt_id</th>\n","      <th>prompt_question</th>\n","      <th>prompt_title</th>\n","      <th>prompt_text</th>\n","      <th>student_id</th>\n","      <th>text</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>00791789cc1f</td>\n","      <td>1 element of an ideal tragedy is that it shoul...</td>\n","      <td>-0.210614</td>\n","      <td>-0.471415</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>0086ef22de8f</td>\n","      <td>The three elements of an ideal tragedy are:  H...</td>\n","      <td>-0.970237</td>\n","      <td>-0.417058</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>0094589c7a22</td>\n","      <td>Aristotle states that an ideal tragedy should ...</td>\n","      <td>-0.387791</td>\n","      <td>-0.584181</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>00cd5736026a</td>\n","      <td>One element of an Ideal tragedy is having a co...</td>\n","      <td>0.088882</td>\n","      <td>-0.594710</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>00d98b8ff756</td>\n","      <td>The 3 ideal of tragedy is how complex you need...</td>\n","      <td>-0.687288</td>\n","      <td>-0.460886</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7cdcf71f-bbbd-4523-8812-741c48a15350')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7cdcf71f-bbbd-4523-8812-741c48a15350 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7cdcf71f-bbbd-4523-8812-741c48a15350');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-924ffa81-66a0-4959-8f2e-2bd269e52281\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-924ffa81-66a0-4959-8f2e-2bd269e52281')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-924ffa81-66a0-4959-8f2e-2bd269e52281 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{}}]},{"cell_type":"code","source":["# ====================================================\n","# CV split\n","# ====================================================\n","Fold = GroupKFold(n_splits=CFG.n_fold)\n","for n, (train_index, val_index) in enumerate(Fold.split(train, groups=train[\"prompt_id\"])):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"id":"2oEQGucXi-TM","executionInfo":{"status":"ok","timestamp":1696607072467,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"03d7661a-d6d4-4941-ef4c-229e44668d0f"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    2057\n","1    2009\n","2    1996\n","3    1103\n","dtype: int64"]},"metadata":{}}]},{"cell_type":"code","source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"],"metadata":{"id":"hPNdK-w2jAJb","executionInfo":{"status":"ok","timestamp":1696607072467,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_MODEL_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["b5b2ca5afca4466990922545c0cd2dc9","eb197981c25d40b89f5b642d53a242f6","099e2528f9ae4080b7a87f3cedb80282","0c40f26d83b343e6a72be78648f6d7e7","d25fb7c3779a42638a2bd9f95baf70e6","d1aad23906c644058fe7d0659ea4d9c8","04778d35365e4259a63f135db952d34f","302df032defd45939976b2d214bd6fcd","68614c8f3d9d42489f96c52c412dd0a8","d5898771ef074e33ae883b3c6f5865e0","a2066cb5123047b8ab2b95297d9a5352","9c79b57dd0884eb282d9ce5c861e18d9","006d504f4f744d66852de758e636f5c1","6b4208eaef7747078c843a5dc427ff0d","81ee5b979f9449c99fa80190a3e8375c","bf330b407ddd4735b01df967f8a6729c","3f3ffb5d447a43cc9a7bd05437fe9691","fa22bb650ea04b44aedfa4353a943c05","178d4021b83044cea280ed5d01a04f54","ae570709b9d445a7b4a148e742ae77b1","feb1449800ed4da7b6e35f9ec9b73446","21c026243cbd4a4cabe9f415260a5bb5","84e0ba60d9994cabb4e5dd6d4e8bcab9","80c3a21831e5464e9430bc8b988aabd9","0b2581d9984d4d569395d82f85968b5b","9ff3ce76c37c4f0ea8dcdd3a6278e431","217b46459dde44a78e9687eb5d2abfc3","4dabb88472954014babd5db29cf695c6","d3873b75020a4896b0334ad3c38624e6","5efe0ae0989647b5a2d9974267731603","ee92f988398b49909105f663970d4f54","dd99bcc3832e43cb93f2c81440746b9e","7d15e25ed8ec40e9b74c1680a7513f28"]},"id":"CNt6YdwtjCHR","executionInfo":{"status":"ok","timestamp":1696607080451,"user_tz":-540,"elapsed":7990,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"8325fa3d-02c9-4344-a368-03dd4cea06cc"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5b2ca5afca4466990922545c0cd2dc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c79b57dd0884eb282d9ce5c861e18d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading spm.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84e0ba60d9994cabb4e5dd6d4e8bcab9"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["def len2text(x:str):\n","    if len(x)<200: return 'Quite short'\n","    if len(x)<300: return 'Short'\n","    if len(x)<500: return 'Middle'\n","    else:\n","        return 'Long'"],"metadata":{"id":"4-LeEcCMxp0r","executionInfo":{"status":"ok","timestamp":1696607081054,"user_tz":-540,"elapsed":626,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["train[\"text_length\"] = train['text'].apply(lambda x: len2text(x))\n","SEP = tokenizer.sep_token\n","train['full_text'] = train['text'] + \" \" + train['prompt_question'] + \" \" + train[\"prompt_text\"]"],"metadata":{"id":"4URMsa8ZjZbe","executionInfo":{"status":"ok","timestamp":1696607081055,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer.encode_plus(\n","        text,\n","        return_tensors=None,\n","        add_special_tokens=True,\n","        max_length=CFG.max_len,\n","        pad_to_max_length=True,\n","        truncation=True\n","    )\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['full_text'].values\n","        self.labels = df[cfg.target_cols].values\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs"],"metadata":{"id":"dn-zNJVbja5k","executionInfo":{"status":"ok","timestamp":1696607081055,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        #self.pool = MeanPooling()\n","        self.output = nn.Sequential(\n","            nn.LayerNorm(self.config.hidden_size),\n","            nn.Linear(self.config.hidden_size, self.cfg.target_size)\n","        )\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        feature = outputs[0][:, 0, :]\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.output(feature)\n","        return output"],"metadata":{"id":"KIb1arzTjdRR","executionInfo":{"status":"ok","timestamp":1696607081055,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Loss\n","# ====================================================\n","class RMSELoss(nn.Module):\n","    def __init__(self, reduction='mean', eps=1e-9):\n","        super().__init__()\n","        self.mse = nn.MSELoss(reduction='none')\n","        self.reduction = reduction\n","        self.eps = eps\n","\n","    def forward(self, y_pred, y_true):\n","        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss"],"metadata":{"id":"fxIJL4WojfSl","executionInfo":{"status":"ok","timestamp":1696607081055,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        #if scaler is not None:\n","        #    scaler.unscale_(optimizer)\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader),\n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    return losses.avg, predictions"],"metadata":{"id":"JSU1PJNIjhKu","executionInfo":{"status":"ok","timestamp":1696607081055,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","\n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target_cols].values\n","\n","    print(f\"========== prompt_id: {valid_folds.prompt_id.unique()} validation ==========\")\n","\n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size * 2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_MODEL_DIR+'config.pth')\n","    model.to(device)\n","\n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","\n","        group1=['layer.0.','layer.1.','layer.2.','layer.3.','layer.4.','layer.5.','layer.6.','layer.7.']\n","        group2=['layer.8.','layer.9.','layer.10.','layer.11.','layer.12.','layer.13.','layer.14.','layer.15.']\n","        group3=['layer.16.','layer.17.','layer.18.','layer.19.','layer.20.','layer.21.','layer.22.','layer.23.']\n","        group_all=['layer.0.','layer.1.','layer.2.','layer.3.','layer.4.','layer.5.','layer.6.','layer.7.','layer.8.','layer.9.','layer.10.','layer.11.',\n","                  'layer.12.','layer.13.','layer.14.','layer.15.','layer.16.','layer.17.','layer.18.','layer.19.','layer.20.','layer.21.','layer.22.','layer.23.']\n","\n","\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","\n","        optimizer_parameters2 = [\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': weight_decay, 'lr': encoder_lr/2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': weight_decay, 'lr': encoder_lr},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': weight_decay, 'lr': encoder_lr*2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': 0.0},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': 0.0, 'lr': encoder_lr/2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': 0.0, 'lr': encoder_lr},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': 0.0, 'lr': encoder_lr*2.6},\n","        {'params': [p for n, p in model.named_parameters() if \"model\" not in n], 'lr':decoder_lr, \"momentum\" : 0.99},\n","    ]\n","        return optimizer_parameters2\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr,\n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","\n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","\n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = RMSELoss(reduction=\"mean\")   # nn.SmoothL1Loss(reduction='mean')\n","\n","    best_score = np.inf\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","\n","        # scoring\n","        score, scores = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n","\n","        if best_score > score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return valid_folds"],"metadata":{"id":"5_npZ5IWjle3","executionInfo":{"status":"ok","timestamp":1696607081055,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","\n","    def get_result(oof_df):\n","        labels = oof_df[CFG.target_cols].values\n","        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n","        score, scores = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n","\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_MODEL_DIR+'oof_df.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["70f044259b47437295d5aa729b8d0a82","ce22454b9316415ba6b60c017f7927ef","8f82d74170864279baf636bdb6368cbe","12c089c32f0a45499d68f1d6ef57e240","feada0cfc87d4fccbe6f39c6678a0b31","43cdc6ab78bb4f0fb6088c3782987fa0","6a187200701943f3bceddfd52796e833","f8093e47a4da4e199e6d361c6be784f2","d304ff7ae7134f75ba9c428f23455e76","0736921bc8b74fcab6b2ae9d7aad4a32","e04c4eb54e754609979db1e40278fbef"]},"id":"oN9JEc3yj-x1","outputId":"b3861696-3eb6-47b4-9311-9c50fcc8d3f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["========== prompt_id: ['39c16e'] validation ==========\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/833M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70f044259b47437295d5aa729b8d0a82"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1277] Elapsed 0m 4s (remain 97m 49s) Loss: 0.4300(0.4300) Grad: inf  LR: 0.00000500  \n","Epoch: [1][20/1277] Elapsed 0m 13s (remain 13m 40s) Loss: 1.2283(0.9389) Grad: 578748.1875  LR: 0.00000500  \n","Epoch: [1][40/1277] Elapsed 0m 22s (remain 11m 15s) Loss: 1.0243(0.9173) Grad: 142105.7500  LR: 0.00000500  \n","Epoch: [1][60/1277] Elapsed 0m 30s (remain 10m 15s) Loss: 0.7999(0.8687) Grad: 182823.7031  LR: 0.00000500  \n","Epoch: [1][80/1277] Elapsed 0m 39s (remain 9m 46s) Loss: 0.8943(0.8425) Grad: 140373.2500  LR: 0.00000500  \n","Epoch: [1][100/1277] Elapsed 0m 48s (remain 9m 23s) Loss: 0.4836(0.8123) Grad: 196732.1562  LR: 0.00000500  \n","Epoch: [1][120/1277] Elapsed 0m 57s (remain 9m 8s) Loss: 0.4469(0.7797) Grad: 193994.9688  LR: 0.00000499  \n","Epoch: [1][140/1277] Elapsed 1m 6s (remain 8m 52s) Loss: 0.5742(0.7538) Grad: 509884.6250  LR: 0.00000499  \n","Epoch: [1][160/1277] Elapsed 1m 14s (remain 8m 38s) Loss: 0.5066(0.7300) Grad: 208688.6250  LR: 0.00000499  \n","Epoch: [1][180/1277] Elapsed 1m 23s (remain 8m 25s) Loss: 0.6040(0.7100) Grad: 554598.1250  LR: 0.00000498  \n","Epoch: [1][200/1277] Elapsed 1m 32s (remain 8m 13s) Loss: 0.3238(0.6863) Grad: 136834.0781  LR: 0.00000498  \n","Epoch: [1][220/1277] Elapsed 1m 40s (remain 8m 2s) Loss: 0.5270(0.6680) Grad: 564366.6875  LR: 0.00000498  \n","Epoch: [1][240/1277] Elapsed 1m 49s (remain 7m 52s) Loss: 0.5748(0.6551) Grad: 254057.2812  LR: 0.00000497  \n","Epoch: [1][260/1277] Elapsed 1m 58s (remain 7m 40s) Loss: 0.7092(0.6435) Grad: 696570.3750  LR: 0.00000497  \n","Epoch: [1][280/1277] Elapsed 2m 7s (remain 7m 30s) Loss: 0.3596(0.6285) Grad: 270577.1875  LR: 0.00000496  \n","Epoch: [1][300/1277] Elapsed 2m 15s (remain 7m 20s) Loss: 0.7549(0.6184) Grad: 347570.6875  LR: 0.00000496  \n","Epoch: [1][320/1277] Elapsed 2m 24s (remain 7m 10s) Loss: 0.2432(0.6109) Grad: 362169.5312  LR: 0.00000495  \n","Epoch: [1][340/1277] Elapsed 2m 33s (remain 7m 0s) Loss: 0.8382(0.5996) Grad: 203441.4844  LR: 0.00000495  \n","Epoch: [1][360/1277] Elapsed 2m 41s (remain 6m 49s) Loss: 0.6019(0.5958) Grad: 265456.2812  LR: 0.00000494  \n","Epoch: [1][380/1277] Elapsed 2m 50s (remain 6m 40s) Loss: 0.4096(0.5881) Grad: 152424.8438  LR: 0.00000493  \n","Epoch: [1][400/1277] Elapsed 2m 59s (remain 6m 31s) Loss: 0.2866(0.5807) Grad: 167580.8594  LR: 0.00000492  \n","Epoch: [1][420/1277] Elapsed 3m 7s (remain 6m 21s) Loss: 0.3076(0.5745) Grad: 158642.4219  LR: 0.00000492  \n","Epoch: [1][440/1277] Elapsed 3m 16s (remain 6m 12s) Loss: 0.4657(0.5665) Grad: 587927.4375  LR: 0.00000491  \n","Epoch: [1][460/1277] Elapsed 3m 25s (remain 6m 2s) Loss: 0.2213(0.5617) Grad: 88222.3438  LR: 0.00000490  \n","Epoch: [1][480/1277] Elapsed 3m 33s (remain 5m 52s) Loss: 0.6115(0.5561) Grad: 316604.7812  LR: 0.00000489  \n","Epoch: [1][500/1277] Elapsed 3m 41s (remain 5m 43s) Loss: 0.9742(0.5545) Grad: 188760.7188  LR: 0.00000488  \n","Epoch: [1][520/1277] Elapsed 3m 50s (remain 5m 34s) Loss: 0.3791(0.5479) Grad: 310758.6875  LR: 0.00000487  \n","Epoch: [1][540/1277] Elapsed 3m 59s (remain 5m 25s) Loss: 0.4790(0.5438) Grad: 117378.2422  LR: 0.00000486  \n","Epoch: [1][560/1277] Elapsed 4m 8s (remain 5m 16s) Loss: 0.2098(0.5392) Grad: 155117.8750  LR: 0.00000485  \n","Epoch: [1][580/1277] Elapsed 4m 17s (remain 5m 8s) Loss: 0.2685(0.5334) Grad: 480910.0000  LR: 0.00000484  \n","Epoch: [1][600/1277] Elapsed 4m 26s (remain 4m 59s) Loss: 0.5578(0.5326) Grad: 246876.1719  LR: 0.00000483  \n","Epoch: [1][620/1277] Elapsed 4m 35s (remain 4m 50s) Loss: 0.1371(0.5286) Grad: 122781.8828  LR: 0.00000482  \n","Epoch: [1][640/1277] Elapsed 4m 43s (remain 4m 41s) Loss: 0.5358(0.5253) Grad: 160940.8125  LR: 0.00000481  \n","Epoch: [1][660/1277] Elapsed 4m 52s (remain 4m 32s) Loss: 0.5694(0.5247) Grad: 599534.5625  LR: 0.00000480  \n","Epoch: [1][680/1277] Elapsed 5m 1s (remain 4m 23s) Loss: 0.2675(0.5224) Grad: 200923.7812  LR: 0.00000478  \n","Epoch: [1][700/1277] Elapsed 5m 10s (remain 4m 14s) Loss: 0.5269(0.5195) Grad: 122609.4844  LR: 0.00000477  \n","Epoch: [1][720/1277] Elapsed 5m 18s (remain 4m 5s) Loss: 0.2231(0.5151) Grad: 229427.7969  LR: 0.00000476  \n","Epoch: [1][740/1277] Elapsed 5m 27s (remain 3m 56s) Loss: 0.5333(0.5134) Grad: 271928.0000  LR: 0.00000474  \n","Epoch: [1][760/1277] Elapsed 5m 35s (remain 3m 47s) Loss: 0.3272(0.5138) Grad: 250988.2344  LR: 0.00000473  \n","Epoch: [1][780/1277] Elapsed 5m 44s (remain 3m 38s) Loss: 0.3166(0.5111) Grad: 332911.0312  LR: 0.00000472  \n","Epoch: [1][800/1277] Elapsed 5m 53s (remain 3m 29s) Loss: 0.3473(0.5089) Grad: 112027.7031  LR: 0.00000470  \n","Epoch: [1][820/1277] Elapsed 6m 1s (remain 3m 20s) Loss: 0.2474(0.5060) Grad: 135863.1094  LR: 0.00000469  \n","Epoch: [1][840/1277] Elapsed 6m 10s (remain 3m 12s) Loss: 0.4747(0.5037) Grad: 99827.9375  LR: 0.00000467  \n","Epoch: [1][860/1277] Elapsed 6m 19s (remain 3m 3s) Loss: 0.5200(0.5011) Grad: 236692.2812  LR: 0.00000466  \n","Epoch: [1][880/1277] Elapsed 6m 27s (remain 2m 54s) Loss: 0.4095(0.4983) Grad: 363069.1562  LR: 0.00000464  \n","Epoch: [1][900/1277] Elapsed 6m 36s (remain 2m 45s) Loss: 0.4875(0.4971) Grad: 163845.7188  LR: 0.00000463  \n","Epoch: [1][920/1277] Elapsed 6m 45s (remain 2m 36s) Loss: 0.5484(0.4958) Grad: 236497.9375  LR: 0.00000461  \n","Epoch: [1][940/1277] Elapsed 6m 53s (remain 2m 27s) Loss: 0.4517(0.4931) Grad: 229280.9688  LR: 0.00000459  \n","Epoch: [1][960/1277] Elapsed 7m 2s (remain 2m 18s) Loss: 0.3237(0.4909) Grad: 228489.1562  LR: 0.00000458  \n","Epoch: [1][980/1277] Elapsed 7m 11s (remain 2m 10s) Loss: 0.2787(0.4895) Grad: 185048.5000  LR: 0.00000456  \n","Epoch: [1][1000/1277] Elapsed 7m 20s (remain 2m 1s) Loss: 0.3506(0.4889) Grad: 179950.0938  LR: 0.00000454  \n","Epoch: [1][1020/1277] Elapsed 7m 29s (remain 1m 52s) Loss: 0.5557(0.4875) Grad: 236189.4062  LR: 0.00000452  \n","Epoch: [1][1040/1277] Elapsed 7m 37s (remain 1m 43s) Loss: 0.5809(0.4861) Grad: 151581.3750  LR: 0.00000450  \n","Epoch: [1][1060/1277] Elapsed 7m 46s (remain 1m 35s) Loss: 0.5046(0.4858) Grad: 101336.6562  LR: 0.00000449  \n","Epoch: [1][1080/1277] Elapsed 7m 55s (remain 1m 26s) Loss: 0.5303(0.4841) Grad: 112321.8984  LR: 0.00000447  \n","Epoch: [1][1100/1277] Elapsed 8m 4s (remain 1m 17s) Loss: 0.3064(0.4825) Grad: 236901.0938  LR: 0.00000445  \n","Epoch: [1][1120/1277] Elapsed 8m 12s (remain 1m 8s) Loss: 0.4178(0.4818) Grad: 148862.9688  LR: 0.00000443  \n","Epoch: [1][1140/1277] Elapsed 8m 21s (remain 0m 59s) Loss: 0.4141(0.4811) Grad: 117321.7734  LR: 0.00000441  \n","Epoch: [1][1160/1277] Elapsed 8m 30s (remain 0m 51s) Loss: 0.6897(0.4812) Grad: 271183.9688  LR: 0.00000439  \n","Epoch: [1][1180/1277] Elapsed 8m 39s (remain 0m 42s) Loss: 0.2515(0.4789) Grad: 106473.9922  LR: 0.00000437  \n","Epoch: [1][1200/1277] Elapsed 8m 47s (remain 0m 33s) Loss: 0.2649(0.4785) Grad: 60167.3008  LR: 0.00000435  \n","Epoch: [1][1220/1277] Elapsed 8m 56s (remain 0m 24s) Loss: 0.3872(0.4764) Grad: 280795.4062  LR: 0.00000433  \n","Epoch: [1][1240/1277] Elapsed 9m 5s (remain 0m 15s) Loss: 0.4900(0.4748) Grad: 216050.3750  LR: 0.00000431  \n","Epoch: [1][1260/1277] Elapsed 9m 13s (remain 0m 7s) Loss: 0.3460(0.4738) Grad: 76208.7422  LR: 0.00000429  \n","Epoch: [1][1276/1277] Elapsed 9m 20s (remain 0m 0s) Loss: 0.3204(0.4725) Grad: 110923.6328  LR: 0.00000427  \n","EVAL: [0/258] Elapsed 0m 0s (remain 3m 23s) Loss: 0.2373(0.2373) \n","EVAL: [20/258] Elapsed 0m 12s (remain 2m 25s) Loss: 0.5174(0.4073) \n","EVAL: [40/258] Elapsed 0m 25s (remain 2m 13s) Loss: 0.2899(0.4033) \n","EVAL: [60/258] Elapsed 0m 37s (remain 2m 0s) Loss: 0.3296(0.3934) \n","EVAL: [80/258] Elapsed 0m 49s (remain 1m 47s) Loss: 0.3778(0.3890) \n","EVAL: [100/258] Elapsed 1m 0s (remain 1m 34s) Loss: 0.4833(0.3898) \n","EVAL: [120/258] Elapsed 1m 13s (remain 1m 22s) Loss: 0.4273(0.3923) \n","EVAL: [140/258] Elapsed 1m 25s (remain 1m 10s) Loss: 0.2657(0.3881) \n","EVAL: [160/258] Elapsed 1m 37s (remain 0m 58s) Loss: 0.3135(0.3899) \n","EVAL: [180/258] Elapsed 1m 48s (remain 0m 46s) Loss: 0.2056(0.3861) \n","EVAL: [200/258] Elapsed 2m 0s (remain 0m 34s) Loss: 0.3375(0.3846) \n","EVAL: [220/258] Elapsed 2m 12s (remain 0m 22s) Loss: 0.2397(0.3835) \n","EVAL: [240/258] Elapsed 2m 24s (remain 0m 10s) Loss: 0.3632(0.3828) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.4725  avg_val_loss: 0.3830  time: 716s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4725  avg_val_loss: 0.3830  time: 716s\n","Epoch 1 - Score: 0.5119  Scores: [0.44483420300990417, 0.5790308909567133]\n","INFO:__main__:Epoch 1 - Score: 0.5119  Scores: [0.44483420300990417, 0.5790308909567133]\n","Epoch 1 - Save Best Score: 0.5119 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5119 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [257/258] Elapsed 2m 34s (remain 0m 0s) Loss: 0.3336(0.3830) \n","Epoch: [2][0/1277] Elapsed 0m 0s (remain 14m 28s) Loss: 0.2931(0.2931) Grad: inf  LR: 0.00000427  \n","Epoch: [2][20/1277] Elapsed 0m 9s (remain 9m 38s) Loss: 0.2806(0.3802) Grad: 329069.3438  LR: 0.00000424  \n","Epoch: [2][40/1277] Elapsed 0m 18s (remain 9m 14s) Loss: 0.4352(0.3682) Grad: 424373.7188  LR: 0.00000422  \n","Epoch: [2][60/1277] Elapsed 0m 27s (remain 9m 2s) Loss: 0.1496(0.3560) Grad: 203443.9062  LR: 0.00000420  \n","Epoch: [2][80/1277] Elapsed 0m 35s (remain 8m 45s) Loss: 0.2658(0.3566) Grad: 198044.3281  LR: 0.00000418  \n","Epoch: [2][100/1277] Elapsed 0m 44s (remain 8m 36s) Loss: 0.3042(0.3558) Grad: 188234.9531  LR: 0.00000415  \n","Epoch: [2][120/1277] Elapsed 0m 53s (remain 8m 29s) Loss: 0.3013(0.3610) Grad: 280612.1875  LR: 0.00000413  \n","Epoch: [2][140/1277] Elapsed 1m 1s (remain 8m 18s) Loss: 0.2407(0.3642) Grad: 198914.5469  LR: 0.00000411  \n","Epoch: [2][160/1277] Elapsed 1m 10s (remain 8m 11s) Loss: 0.1903(0.3635) Grad: 165956.9062  LR: 0.00000408  \n","Epoch: [2][180/1277] Elapsed 1m 19s (remain 8m 3s) Loss: 0.2321(0.3618) Grad: 254660.0156  LR: 0.00000406  \n","Epoch: [2][200/1277] Elapsed 1m 28s (remain 7m 54s) Loss: 0.2578(0.3609) Grad: 260655.3594  LR: 0.00000404  \n","Epoch: [2][220/1277] Elapsed 1m 37s (remain 7m 44s) Loss: 0.3383(0.3607) Grad: 196499.7812  LR: 0.00000401  \n","Epoch: [2][240/1277] Elapsed 1m 46s (remain 7m 36s) Loss: 0.4006(0.3586) Grad: 336855.6875  LR: 0.00000399  \n","Epoch: [2][260/1277] Elapsed 1m 55s (remain 7m 27s) Loss: 0.5566(0.3592) Grad: 261443.0156  LR: 0.00000396  \n","Epoch: [2][280/1277] Elapsed 2m 3s (remain 7m 19s) Loss: 0.4043(0.3579) Grad: 211094.5156  LR: 0.00000394  \n","Epoch: [2][300/1277] Elapsed 2m 12s (remain 7m 10s) Loss: 0.4170(0.3592) Grad: 197703.5781  LR: 0.00000391  \n","Epoch: [2][320/1277] Elapsed 2m 21s (remain 7m 1s) Loss: 0.3071(0.3575) Grad: 255997.9531  LR: 0.00000389  \n","Epoch: [2][340/1277] Elapsed 2m 30s (remain 6m 52s) Loss: 0.5389(0.3572) Grad: 441544.6562  LR: 0.00000386  \n","Epoch: [2][360/1277] Elapsed 2m 39s (remain 6m 43s) Loss: 0.4282(0.3552) Grad: 295304.5625  LR: 0.00000384  \n","Epoch: [2][380/1277] Elapsed 2m 47s (remain 6m 34s) Loss: 0.3829(0.3565) Grad: 241767.3125  LR: 0.00000381  \n","Epoch: [2][400/1277] Elapsed 2m 56s (remain 6m 25s) Loss: 0.2673(0.3558) Grad: 353825.0000  LR: 0.00000378  \n","Epoch: [2][420/1277] Elapsed 3m 5s (remain 6m 16s) Loss: 0.2278(0.3563) Grad: 249985.0781  LR: 0.00000376  \n","Epoch: [2][440/1277] Elapsed 3m 14s (remain 6m 8s) Loss: 0.2228(0.3548) Grad: 240552.3125  LR: 0.00000373  \n","Epoch: [2][460/1277] Elapsed 3m 23s (remain 5m 59s) Loss: 0.5071(0.3539) Grad: 192820.7344  LR: 0.00000370  \n","Epoch: [2][480/1277] Elapsed 3m 31s (remain 5m 50s) Loss: 0.2732(0.3526) Grad: 228890.3125  LR: 0.00000368  \n","Epoch: [2][500/1277] Elapsed 3m 40s (remain 5m 41s) Loss: 0.4847(0.3527) Grad: 459700.7188  LR: 0.00000365  \n","Epoch: [2][520/1277] Elapsed 3m 49s (remain 5m 32s) Loss: 0.2868(0.3531) Grad: 264624.8438  LR: 0.00000362  \n","Epoch: [2][540/1277] Elapsed 3m 58s (remain 5m 24s) Loss: 0.3545(0.3527) Grad: 534652.9375  LR: 0.00000359  \n","Epoch: [2][560/1277] Elapsed 4m 6s (remain 5m 15s) Loss: 0.3601(0.3539) Grad: 171734.0938  LR: 0.00000357  \n","Epoch: [2][580/1277] Elapsed 4m 15s (remain 5m 6s) Loss: 0.4011(0.3535) Grad: 184575.7031  LR: 0.00000354  \n","Epoch: [2][600/1277] Elapsed 4m 24s (remain 4m 57s) Loss: 0.3144(0.3538) Grad: 561957.8125  LR: 0.00000351  \n","Epoch: [2][620/1277] Elapsed 4m 33s (remain 4m 48s) Loss: 0.2062(0.3556) Grad: 177431.4219  LR: 0.00000348  \n","Epoch: [2][640/1277] Elapsed 4m 41s (remain 4m 39s) Loss: 0.3419(0.3550) Grad: 173627.7812  LR: 0.00000345  \n","Epoch: [2][660/1277] Elapsed 4m 50s (remain 4m 30s) Loss: 0.3796(0.3534) Grad: 128831.1719  LR: 0.00000342  \n","Epoch: [2][680/1277] Elapsed 4m 59s (remain 4m 21s) Loss: 0.2363(0.3530) Grad: 210531.3906  LR: 0.00000340  \n","Epoch: [2][700/1277] Elapsed 5m 7s (remain 4m 12s) Loss: 0.2882(0.3518) Grad: 139465.8594  LR: 0.00000337  \n","Epoch: [2][720/1277] Elapsed 5m 16s (remain 4m 4s) Loss: 0.3329(0.3512) Grad: 368450.7188  LR: 0.00000334  \n","Epoch: [2][740/1277] Elapsed 5m 25s (remain 3m 55s) Loss: 0.4067(0.3517) Grad: 155867.1875  LR: 0.00000331  \n","Epoch: [2][760/1277] Elapsed 5m 34s (remain 3m 46s) Loss: 0.3055(0.3512) Grad: 255362.4375  LR: 0.00000328  \n","Epoch: [2][780/1277] Elapsed 5m 43s (remain 3m 37s) Loss: 0.1811(0.3508) Grad: 343652.6562  LR: 0.00000325  \n","Epoch: [2][800/1277] Elapsed 5m 51s (remain 3m 29s) Loss: 0.5071(0.3517) Grad: 404503.0625  LR: 0.00000322  \n","Epoch: [2][820/1277] Elapsed 6m 0s (remain 3m 20s) Loss: 0.1409(0.3513) Grad: 134917.6250  LR: 0.00000319  \n","Epoch: [2][840/1277] Elapsed 6m 9s (remain 3m 11s) Loss: 0.2381(0.3513) Grad: 192460.2344  LR: 0.00000316  \n","Epoch: [2][860/1277] Elapsed 6m 18s (remain 3m 2s) Loss: 0.3709(0.3519) Grad: 310682.6250  LR: 0.00000313  \n","Epoch: [2][880/1277] Elapsed 6m 27s (remain 2m 53s) Loss: 0.3450(0.3520) Grad: 266265.9375  LR: 0.00000310  \n","Epoch: [2][900/1277] Elapsed 6m 35s (remain 2m 45s) Loss: 0.2747(0.3510) Grad: 222094.3125  LR: 0.00000307  \n","Epoch: [2][920/1277] Elapsed 6m 44s (remain 2m 36s) Loss: 0.2282(0.3499) Grad: 346626.8438  LR: 0.00000304  \n","Epoch: [2][940/1277] Elapsed 6m 52s (remain 2m 27s) Loss: 0.2902(0.3488) Grad: 130347.9297  LR: 0.00000301  \n","Epoch: [2][960/1277] Elapsed 7m 1s (remain 2m 18s) Loss: 0.2081(0.3492) Grad: 335920.0312  LR: 0.00000298  \n","Epoch: [2][980/1277] Elapsed 7m 10s (remain 2m 9s) Loss: 0.2442(0.3489) Grad: 222915.0781  LR: 0.00000295  \n","Epoch: [2][1000/1277] Elapsed 7m 19s (remain 2m 1s) Loss: 0.5555(0.3496) Grad: 170597.8125  LR: 0.00000292  \n","Epoch: [2][1020/1277] Elapsed 7m 27s (remain 1m 52s) Loss: 0.2724(0.3501) Grad: 380445.5312  LR: 0.00000289  \n","Epoch: [2][1040/1277] Elapsed 7m 36s (remain 1m 43s) Loss: 0.5635(0.3506) Grad: 260244.2812  LR: 0.00000286  \n","Epoch: [2][1060/1277] Elapsed 7m 45s (remain 1m 34s) Loss: 0.5523(0.3501) Grad: 206413.0312  LR: 0.00000283  \n","Epoch: [2][1080/1277] Elapsed 7m 53s (remain 1m 25s) Loss: 0.3060(0.3500) Grad: 399855.1250  LR: 0.00000280  \n","Epoch: [2][1100/1277] Elapsed 8m 2s (remain 1m 17s) Loss: 0.3356(0.3495) Grad: 150818.9375  LR: 0.00000277  \n","Epoch: [2][1120/1277] Elapsed 8m 11s (remain 1m 8s) Loss: 0.2163(0.3489) Grad: 182119.1094  LR: 0.00000274  \n","Epoch: [2][1140/1277] Elapsed 8m 20s (remain 0m 59s) Loss: 0.3469(0.3499) Grad: 321062.1562  LR: 0.00000271  \n","Epoch: [2][1160/1277] Elapsed 8m 29s (remain 0m 50s) Loss: 0.5548(0.3502) Grad: 571792.7500  LR: 0.00000268  \n","Epoch: [2][1180/1277] Elapsed 8m 38s (remain 0m 42s) Loss: 0.6757(0.3508) Grad: 352744.4062  LR: 0.00000265  \n","Epoch: [2][1200/1277] Elapsed 8m 46s (remain 0m 33s) Loss: 0.2650(0.3503) Grad: 528277.9375  LR: 0.00000262  \n","Epoch: [2][1220/1277] Elapsed 8m 55s (remain 0m 24s) Loss: 0.1992(0.3499) Grad: 146733.9844  LR: 0.00000259  \n","Epoch: [2][1240/1277] Elapsed 9m 3s (remain 0m 15s) Loss: 0.3472(0.3501) Grad: 288316.2188  LR: 0.00000256  \n","Epoch: [2][1260/1277] Elapsed 9m 12s (remain 0m 7s) Loss: 0.3441(0.3505) Grad: 282639.3750  LR: 0.00000252  \n","Epoch: [2][1276/1277] Elapsed 9m 19s (remain 0m 0s) Loss: 0.4174(0.3501) Grad: 181520.5938  LR: 0.00000250  \n","EVAL: [0/258] Elapsed 0m 0s (remain 3m 22s) Loss: 0.2272(0.2272) \n","EVAL: [20/258] Elapsed 0m 12s (remain 2m 25s) Loss: 0.5244(0.3783) \n","EVAL: [40/258] Elapsed 0m 25s (remain 2m 13s) Loss: 0.2649(0.3735) \n","EVAL: [60/258] Elapsed 0m 37s (remain 2m 0s) Loss: 0.2541(0.3609) \n","EVAL: [80/258] Elapsed 0m 49s (remain 1m 47s) Loss: 0.3564(0.3617) \n","EVAL: [100/258] Elapsed 1m 0s (remain 1m 34s) Loss: 0.4336(0.3622) \n","EVAL: [120/258] Elapsed 1m 13s (remain 1m 22s) Loss: 0.3924(0.3632) \n","EVAL: [140/258] Elapsed 1m 25s (remain 1m 10s) Loss: 0.2406(0.3621) \n","EVAL: [160/258] Elapsed 1m 37s (remain 0m 58s) Loss: 0.3049(0.3616) \n","EVAL: [180/258] Elapsed 1m 48s (remain 0m 46s) Loss: 0.1912(0.3581) \n","EVAL: [200/258] Elapsed 2m 0s (remain 0m 34s) Loss: 0.3133(0.3579) \n","EVAL: [220/258] Elapsed 2m 12s (remain 0m 22s) Loss: 0.2182(0.3573) \n","EVAL: [240/258] Elapsed 2m 24s (remain 0m 10s) Loss: 0.2549(0.3569) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3501  avg_val_loss: 0.3563  time: 714s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3501  avg_val_loss: 0.3563  time: 714s\n","Epoch 2 - Score: 0.4753  Scores: [0.42690990090064596, 0.5236497811189503]\n","INFO:__main__:Epoch 2 - Score: 0.4753  Scores: [0.42690990090064596, 0.5236497811189503]\n","Epoch 2 - Save Best Score: 0.4753 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4753 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [257/258] Elapsed 2m 34s (remain 0m 0s) Loss: 0.2953(0.3563) \n","Epoch: [3][0/1277] Elapsed 0m 0s (remain 14m 59s) Loss: 0.3812(0.3812) Grad: inf  LR: 0.00000250  \n","Epoch: [3][20/1277] Elapsed 0m 9s (remain 9m 8s) Loss: 0.5053(0.3381) Grad: 275114.9375  LR: 0.00000247  \n","Epoch: [3][40/1277] Elapsed 0m 18s (remain 9m 3s) Loss: 0.3069(0.3337) Grad: 132528.3438  LR: 0.00000244  \n","Epoch: [3][60/1277] Elapsed 0m 26s (remain 8m 52s) Loss: 0.4277(0.3244) Grad: 168061.0781  LR: 0.00000241  \n","Epoch: [3][80/1277] Elapsed 0m 35s (remain 8m 45s) Loss: 0.3552(0.3187) Grad: 771920.1875  LR: 0.00000238  \n","Epoch: [3][100/1277] Elapsed 0m 44s (remain 8m 36s) Loss: 0.6330(0.3284) Grad: 208215.0312  LR: 0.00000234  \n","Epoch: [3][120/1277] Elapsed 0m 53s (remain 8m 29s) Loss: 0.3087(0.3253) Grad: 167086.3281  LR: 0.00000231  \n","Epoch: [3][140/1277] Elapsed 1m 2s (remain 8m 22s) Loss: 0.1950(0.3206) Grad: 204483.8906  LR: 0.00000228  \n","Epoch: [3][160/1277] Elapsed 1m 11s (remain 8m 13s) Loss: 0.4075(0.3233) Grad: 611243.6250  LR: 0.00000225  \n","Epoch: [3][180/1277] Elapsed 1m 19s (remain 8m 4s) Loss: 0.2677(0.3196) Grad: 266756.7500  LR: 0.00000222  \n","Epoch: [3][200/1277] Elapsed 1m 28s (remain 7m 54s) Loss: 0.4240(0.3229) Grad: 203780.0625  LR: 0.00000219  \n","Epoch: [3][220/1277] Elapsed 1m 37s (remain 7m 46s) Loss: 0.1728(0.3213) Grad: 182891.2656  LR: 0.00000216  \n","Epoch: [3][240/1277] Elapsed 1m 46s (remain 7m 37s) Loss: 0.3850(0.3215) Grad: 309250.6875  LR: 0.00000213  \n","Epoch: [3][260/1277] Elapsed 1m 55s (remain 7m 29s) Loss: 0.2426(0.3241) Grad: 217701.7969  LR: 0.00000210  \n","Epoch: [3][280/1277] Elapsed 2m 4s (remain 7m 20s) Loss: 0.8741(0.3234) Grad: 558306.4375  LR: 0.00000207  \n","Epoch: [3][300/1277] Elapsed 2m 12s (remain 7m 10s) Loss: 0.3581(0.3193) Grad: 430209.3438  LR: 0.00000204  \n","Epoch: [3][320/1277] Elapsed 2m 21s (remain 7m 1s) Loss: 0.2907(0.3193) Grad: 239843.4062  LR: 0.00000201  \n","Epoch: [3][340/1277] Elapsed 2m 30s (remain 6m 52s) Loss: 0.4010(0.3183) Grad: 397458.8438  LR: 0.00000198  \n","Epoch: [3][360/1277] Elapsed 2m 38s (remain 6m 43s) Loss: 0.2672(0.3192) Grad: 265655.9688  LR: 0.00000195  \n","Epoch: [3][380/1277] Elapsed 2m 47s (remain 6m 34s) Loss: 0.2226(0.3202) Grad: 140837.0000  LR: 0.00000192  \n","Epoch: [3][400/1277] Elapsed 2m 56s (remain 6m 25s) Loss: 0.4160(0.3205) Grad: 360998.7500  LR: 0.00000189  \n","Epoch: [3][420/1277] Elapsed 3m 4s (remain 6m 15s) Loss: 0.3693(0.3193) Grad: 261853.3594  LR: 0.00000186  \n","Epoch: [3][440/1277] Elapsed 3m 13s (remain 6m 7s) Loss: 0.1738(0.3173) Grad: 245864.7812  LR: 0.00000183  \n","Epoch: [3][460/1277] Elapsed 3m 22s (remain 5m 58s) Loss: 0.2369(0.3166) Grad: 250691.9688  LR: 0.00000180  \n","Epoch: [3][480/1277] Elapsed 3m 31s (remain 5m 49s) Loss: 0.3128(0.3160) Grad: 153635.9219  LR: 0.00000177  \n","Epoch: [3][500/1277] Elapsed 3m 40s (remain 5m 40s) Loss: 0.2820(0.3154) Grad: 125977.4844  LR: 0.00000174  \n","Epoch: [3][520/1277] Elapsed 3m 48s (remain 5m 31s) Loss: 0.2638(0.3139) Grad: 285145.7812  LR: 0.00000171  \n","Epoch: [3][540/1277] Elapsed 3m 57s (remain 5m 22s) Loss: 0.4484(0.3138) Grad: 308854.0312  LR: 0.00000168  \n","Epoch: [3][560/1277] Elapsed 4m 6s (remain 5m 14s) Loss: 0.1342(0.3127) Grad: 197634.4688  LR: 0.00000165  \n","Epoch: [3][580/1277] Elapsed 4m 14s (remain 5m 4s) Loss: 0.6287(0.3122) Grad: 312263.3125  LR: 0.00000163  \n","Epoch: [3][600/1277] Elapsed 4m 23s (remain 4m 55s) Loss: 0.3260(0.3128) Grad: 251141.4844  LR: 0.00000160  \n","Epoch: [3][620/1277] Elapsed 4m 32s (remain 4m 47s) Loss: 0.3580(0.3132) Grad: 314448.9062  LR: 0.00000157  \n","Epoch: [3][640/1277] Elapsed 4m 40s (remain 4m 38s) Loss: 0.1859(0.3139) Grad: 187520.4219  LR: 0.00000154  \n","Epoch: [3][660/1277] Elapsed 4m 49s (remain 4m 29s) Loss: 0.2004(0.3141) Grad: 230018.2812  LR: 0.00000151  \n","Epoch: [3][680/1277] Elapsed 4m 58s (remain 4m 21s) Loss: 0.3569(0.3132) Grad: 323477.1875  LR: 0.00000148  \n","Epoch: [3][700/1277] Elapsed 5m 7s (remain 4m 12s) Loss: 0.1782(0.3117) Grad: 423329.0625  LR: 0.00000146  \n","Epoch: [3][720/1277] Elapsed 5m 16s (remain 4m 3s) Loss: 0.2356(0.3117) Grad: 304637.6562  LR: 0.00000143  \n","Epoch: [3][740/1277] Elapsed 5m 24s (remain 3m 54s) Loss: 0.2196(0.3116) Grad: 283388.5938  LR: 0.00000140  \n","Epoch: [3][760/1277] Elapsed 5m 33s (remain 3m 46s) Loss: 0.3118(0.3118) Grad: 327272.8125  LR: 0.00000137  \n","Epoch: [3][780/1277] Elapsed 5m 42s (remain 3m 37s) Loss: 0.3028(0.3116) Grad: 499561.6562  LR: 0.00000134  \n","Epoch: [3][800/1277] Elapsed 5m 50s (remain 3m 28s) Loss: 0.5057(0.3119) Grad: 196756.2031  LR: 0.00000132  \n","Epoch: [3][820/1277] Elapsed 5m 59s (remain 3m 19s) Loss: 0.3344(0.3126) Grad: 281025.8438  LR: 0.00000129  \n","Epoch: [3][840/1277] Elapsed 6m 8s (remain 3m 10s) Loss: 0.2827(0.3111) Grad: 264550.0625  LR: 0.00000126  \n","Epoch: [3][860/1277] Elapsed 6m 17s (remain 3m 2s) Loss: 0.4912(0.3109) Grad: 369879.6562  LR: 0.00000124  \n","Epoch: [3][880/1277] Elapsed 6m 25s (remain 2m 53s) Loss: 0.2343(0.3104) Grad: 1206746.2500  LR: 0.00000121  \n","Epoch: [3][900/1277] Elapsed 6m 34s (remain 2m 44s) Loss: 0.1957(0.3099) Grad: 172116.7344  LR: 0.00000118  \n","Epoch: [3][920/1277] Elapsed 6m 43s (remain 2m 35s) Loss: 0.3121(0.3101) Grad: 151411.5625  LR: 0.00000116  \n","Epoch: [3][940/1277] Elapsed 6m 51s (remain 2m 27s) Loss: 0.2658(0.3086) Grad: 132712.1875  LR: 0.00000113  \n","Epoch: [3][960/1277] Elapsed 7m 0s (remain 2m 18s) Loss: 0.2925(0.3079) Grad: 210114.6562  LR: 0.00000111  \n","Epoch: [3][980/1277] Elapsed 7m 9s (remain 2m 9s) Loss: 0.2521(0.3073) Grad: 387931.0312  LR: 0.00000108  \n","Epoch: [3][1000/1277] Elapsed 7m 18s (remain 2m 0s) Loss: 0.2110(0.3068) Grad: 567862.2500  LR: 0.00000106  \n","Epoch: [3][1020/1277] Elapsed 7m 26s (remain 1m 52s) Loss: 0.3545(0.3069) Grad: 292726.5312  LR: 0.00000103  \n","Epoch: [3][1040/1277] Elapsed 7m 35s (remain 1m 43s) Loss: 0.4158(0.3061) Grad: 352897.2188  LR: 0.00000101  \n","Epoch: [3][1060/1277] Elapsed 7m 43s (remain 1m 34s) Loss: 0.2753(0.3058) Grad: 211130.2500  LR: 0.00000098  \n","Epoch: [3][1080/1277] Elapsed 7m 52s (remain 1m 25s) Loss: 0.3090(0.3064) Grad: 288262.7812  LR: 0.00000096  \n","Epoch: [3][1100/1277] Elapsed 8m 1s (remain 1m 17s) Loss: 0.6446(0.3064) Grad: 309072.1562  LR: 0.00000093  \n","Epoch: [3][1120/1277] Elapsed 8m 10s (remain 1m 8s) Loss: 0.5603(0.3068) Grad: 372745.9688  LR: 0.00000091  \n","Epoch: [3][1140/1277] Elapsed 8m 19s (remain 0m 59s) Loss: 0.3083(0.3069) Grad: 269368.3438  LR: 0.00000089  \n","Epoch: [3][1160/1277] Elapsed 8m 28s (remain 0m 50s) Loss: 0.3609(0.3068) Grad: 327969.4688  LR: 0.00000086  \n","Epoch: [3][1180/1277] Elapsed 8m 37s (remain 0m 42s) Loss: 0.6102(0.3063) Grad: 286163.8750  LR: 0.00000084  \n","Epoch: [3][1200/1277] Elapsed 8m 45s (remain 0m 33s) Loss: 0.2636(0.3064) Grad: 179775.4375  LR: 0.00000082  \n","Epoch: [3][1220/1277] Elapsed 8m 54s (remain 0m 24s) Loss: 0.2470(0.3067) Grad: 363842.2188  LR: 0.00000079  \n","Epoch: [3][1240/1277] Elapsed 9m 3s (remain 0m 15s) Loss: 0.2447(0.3070) Grad: 354033.6875  LR: 0.00000077  \n","Epoch: [3][1260/1277] Elapsed 9m 12s (remain 0m 7s) Loss: 0.1683(0.3063) Grad: 468064.8438  LR: 0.00000075  \n","Epoch: [3][1276/1277] Elapsed 9m 19s (remain 0m 0s) Loss: 0.2613(0.3060) Grad: 303690.8438  LR: 0.00000073  \n","EVAL: [0/258] Elapsed 0m 0s (remain 3m 26s) Loss: 0.2454(0.2454) \n","EVAL: [20/258] Elapsed 0m 12s (remain 2m 24s) Loss: 0.5173(0.3996) \n","EVAL: [40/258] Elapsed 0m 25s (remain 2m 13s) Loss: 0.2712(0.3876) \n","EVAL: [60/258] Elapsed 0m 37s (remain 2m 0s) Loss: 0.3321(0.3750) \n","EVAL: [80/258] Elapsed 0m 48s (remain 1m 46s) Loss: 0.3447(0.3734) \n","EVAL: [100/258] Elapsed 1m 0s (remain 1m 34s) Loss: 0.3833(0.3748) \n","EVAL: [120/258] Elapsed 1m 12s (remain 1m 22s) Loss: 0.4359(0.3788) \n","EVAL: [140/258] Elapsed 1m 24s (remain 1m 10s) Loss: 0.2646(0.3772) \n","EVAL: [160/258] Elapsed 1m 37s (remain 0m 58s) Loss: 0.2859(0.3763) \n","EVAL: [180/258] Elapsed 1m 48s (remain 0m 46s) Loss: 0.2170(0.3743) \n","EVAL: [200/258] Elapsed 2m 0s (remain 0m 34s) Loss: 0.3177(0.3722) \n","EVAL: [220/258] Elapsed 2m 12s (remain 0m 22s) Loss: 0.2205(0.3723) \n","EVAL: [240/258] Elapsed 2m 24s (remain 0m 10s) Loss: 0.3856(0.3714) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3060  avg_val_loss: 0.3710  time: 714s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3060  avg_val_loss: 0.3710  time: 714s\n","Epoch 3 - Score: 0.4779  Scores: [0.40340548522010666, 0.5523803101758128]\n","INFO:__main__:Epoch 3 - Score: 0.4779  Scores: [0.40340548522010666, 0.5523803101758128]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [257/258] Elapsed 2m 34s (remain 0m 0s) Loss: 0.2561(0.3710) \n","Epoch: [4][0/1277] Elapsed 0m 0s (remain 14m 37s) Loss: 0.2227(0.2227) Grad: inf  LR: 0.00000073  \n","Epoch: [4][20/1277] Elapsed 0m 9s (remain 9m 26s) Loss: 0.3116(0.2796) Grad: 296240.7188  LR: 0.00000071  \n","Epoch: [4][40/1277] Elapsed 0m 18s (remain 9m 5s) Loss: 0.3548(0.2821) Grad: 164856.8594  LR: 0.00000069  \n","Epoch: [4][60/1277] Elapsed 0m 26s (remain 8m 55s) Loss: 0.3339(0.2874) Grad: 226343.3750  LR: 0.00000067  \n","Epoch: [4][80/1277] Elapsed 0m 35s (remain 8m 46s) Loss: 0.1377(0.2827) Grad: 380244.1250  LR: 0.00000065  \n","Epoch: [4][100/1277] Elapsed 0m 44s (remain 8m 38s) Loss: 0.2526(0.2823) Grad: 325458.7188  LR: 0.00000063  \n","Epoch: [4][120/1277] Elapsed 0m 53s (remain 8m 29s) Loss: 0.3951(0.2771) Grad: 259619.6562  LR: 0.00000061  \n","Epoch: [4][140/1277] Elapsed 1m 1s (remain 8m 18s) Loss: 0.1747(0.2720) Grad: 171878.9844  LR: 0.00000059  \n","Epoch: [4][160/1277] Elapsed 1m 10s (remain 8m 9s) Loss: 0.2646(0.2707) Grad: 414354.1250  LR: 0.00000057  \n","Epoch: [4][180/1277] Elapsed 1m 19s (remain 8m 1s) Loss: 0.1750(0.2662) Grad: 196985.4062  LR: 0.00000055  \n","Epoch: [4][200/1277] Elapsed 1m 28s (remain 7m 52s) Loss: 0.2168(0.2657) Grad: 397147.8125  LR: 0.00000053  \n","Epoch: [4][220/1277] Elapsed 1m 37s (remain 7m 44s) Loss: 0.3773(0.2632) Grad: 138913.4062  LR: 0.00000051  \n","Epoch: [4][240/1277] Elapsed 1m 46s (remain 7m 35s) Loss: 0.1533(0.2636) Grad: 381972.7500  LR: 0.00000049  \n","Epoch: [4][260/1277] Elapsed 1m 54s (remain 7m 26s) Loss: 0.2180(0.2615) Grad: 224278.1094  LR: 0.00000047  \n","Epoch: [4][280/1277] Elapsed 2m 3s (remain 7m 18s) Loss: 0.4619(0.2607) Grad: 356399.0312  LR: 0.00000045  \n","Epoch: [4][300/1277] Elapsed 2m 12s (remain 7m 9s) Loss: 0.2758(0.2606) Grad: 256975.0000  LR: 0.00000044  \n","Epoch: [4][320/1277] Elapsed 2m 21s (remain 7m 0s) Loss: 0.1664(0.2630) Grad: 207811.2188  LR: 0.00000042  \n","Epoch: [4][340/1277] Elapsed 2m 30s (remain 6m 52s) Loss: 0.3013(0.2618) Grad: 168760.6094  LR: 0.00000040  \n","Epoch: [4][360/1277] Elapsed 2m 38s (remain 6m 42s) Loss: 0.3583(0.2628) Grad: 351939.3750  LR: 0.00000039  \n","Epoch: [4][380/1277] Elapsed 2m 47s (remain 6m 33s) Loss: 0.1525(0.2646) Grad: 163997.4375  LR: 0.00000037  \n","Epoch: [4][400/1277] Elapsed 2m 56s (remain 6m 24s) Loss: 0.1297(0.2641) Grad: 250097.7656  LR: 0.00000035  \n","Epoch: [4][420/1277] Elapsed 3m 5s (remain 6m 16s) Loss: 0.4423(0.2661) Grad: 296344.1562  LR: 0.00000034  \n","Epoch: [4][440/1277] Elapsed 3m 13s (remain 6m 7s) Loss: 0.3558(0.2663) Grad: 382395.9375  LR: 0.00000032  \n","Epoch: [4][460/1277] Elapsed 3m 22s (remain 5m 58s) Loss: 0.1745(0.2667) Grad: 250217.5625  LR: 0.00000031  \n","Epoch: [4][480/1277] Elapsed 3m 31s (remain 5m 49s) Loss: 0.2903(0.2679) Grad: 173009.7500  LR: 0.00000029  \n","Epoch: [4][500/1277] Elapsed 3m 40s (remain 5m 41s) Loss: 0.2234(0.2687) Grad: 451709.4062  LR: 0.00000028  \n","Epoch: [4][520/1277] Elapsed 3m 49s (remain 5m 32s) Loss: 0.2413(0.2684) Grad: 312000.1250  LR: 0.00000027  \n","Epoch: [4][540/1277] Elapsed 3m 57s (remain 5m 23s) Loss: 0.1940(0.2686) Grad: 192507.2344  LR: 0.00000025  \n","Epoch: [4][560/1277] Elapsed 4m 6s (remain 5m 14s) Loss: 0.1660(0.2687) Grad: 201035.6562  LR: 0.00000024  \n","Epoch: [4][580/1277] Elapsed 4m 15s (remain 5m 6s) Loss: 0.3540(0.2693) Grad: 184998.4688  LR: 0.00000023  \n","Epoch: [4][600/1277] Elapsed 4m 24s (remain 4m 57s) Loss: 0.2546(0.2688) Grad: 258434.5156  LR: 0.00000021  \n","Epoch: [4][620/1277] Elapsed 4m 32s (remain 4m 48s) Loss: 0.3446(0.2697) Grad: 295288.1875  LR: 0.00000020  \n","Epoch: [4][640/1277] Elapsed 4m 41s (remain 4m 39s) Loss: 0.2962(0.2700) Grad: 238618.1406  LR: 0.00000019  \n","Epoch: [4][660/1277] Elapsed 4m 50s (remain 4m 30s) Loss: 0.1532(0.2692) Grad: 246435.3906  LR: 0.00000018  \n","Epoch: [4][680/1277] Elapsed 4m 59s (remain 4m 21s) Loss: 0.2479(0.2690) Grad: 211541.2500  LR: 0.00000017  \n","Epoch: [4][700/1277] Elapsed 5m 7s (remain 4m 12s) Loss: 0.3080(0.2691) Grad: 239190.2500  LR: 0.00000016  \n","Epoch: [4][720/1277] Elapsed 5m 16s (remain 4m 4s) Loss: 0.2052(0.2695) Grad: 321410.0625  LR: 0.00000014  \n","Epoch: [4][740/1277] Elapsed 5m 25s (remain 3m 55s) Loss: 0.2153(0.2695) Grad: 208609.0781  LR: 0.00000013  \n","Epoch: [4][760/1277] Elapsed 5m 34s (remain 3m 46s) Loss: 0.2603(0.2693) Grad: 261663.4375  LR: 0.00000012  \n","Epoch: [4][780/1277] Elapsed 5m 43s (remain 3m 37s) Loss: 0.2389(0.2698) Grad: 299684.7812  LR: 0.00000012  \n","Epoch: [4][800/1277] Elapsed 5m 51s (remain 3m 29s) Loss: 0.1373(0.2688) Grad: 183338.5781  LR: 0.00000011  \n","Epoch: [4][820/1277] Elapsed 6m 0s (remain 3m 20s) Loss: 0.3649(0.2687) Grad: 624708.0625  LR: 0.00000010  \n","Epoch: [4][840/1277] Elapsed 6m 9s (remain 3m 11s) Loss: 0.2995(0.2690) Grad: 143123.9219  LR: 0.00000009  \n","Epoch: [4][860/1277] Elapsed 6m 18s (remain 3m 2s) Loss: 0.1626(0.2694) Grad: 199852.6094  LR: 0.00000008  \n","Epoch: [4][880/1277] Elapsed 6m 27s (remain 2m 54s) Loss: 0.3507(0.2693) Grad: 174428.7031  LR: 0.00000007  \n","Epoch: [4][900/1277] Elapsed 6m 36s (remain 2m 45s) Loss: 0.3860(0.2696) Grad: 500073.4688  LR: 0.00000007  \n","Epoch: [4][920/1277] Elapsed 6m 44s (remain 2m 36s) Loss: 0.2092(0.2696) Grad: 339472.0625  LR: 0.00000006  \n","Epoch: [4][940/1277] Elapsed 6m 53s (remain 2m 27s) Loss: 0.2389(0.2700) Grad: 417305.1562  LR: 0.00000005  \n","Epoch: [4][960/1277] Elapsed 7m 2s (remain 2m 18s) Loss: 0.4579(0.2700) Grad: 412460.8125  LR: 0.00000005  \n","Epoch: [4][980/1277] Elapsed 7m 11s (remain 2m 10s) Loss: 0.2691(0.2700) Grad: 359624.2188  LR: 0.00000004  \n","Epoch: [4][1000/1277] Elapsed 7m 19s (remain 2m 1s) Loss: 0.1518(0.2702) Grad: 250561.0781  LR: 0.00000004  \n","Epoch: [4][1020/1277] Elapsed 7m 28s (remain 1m 52s) Loss: 0.2044(0.2704) Grad: 217486.8750  LR: 0.00000003  \n","Epoch: [4][1040/1277] Elapsed 7m 37s (remain 1m 43s) Loss: 0.3702(0.2706) Grad: 237942.0781  LR: 0.00000003  \n","Epoch: [4][1060/1277] Elapsed 7m 46s (remain 1m 34s) Loss: 0.3561(0.2698) Grad: 266083.6250  LR: 0.00000002  \n","Epoch: [4][1080/1277] Elapsed 7m 55s (remain 1m 26s) Loss: 0.1570(0.2691) Grad: 112932.2656  LR: 0.00000002  \n","Epoch: [4][1100/1277] Elapsed 8m 4s (remain 1m 17s) Loss: 0.3203(0.2689) Grad: 233792.0469  LR: 0.00000001  \n","Epoch: [4][1120/1277] Elapsed 8m 13s (remain 1m 8s) Loss: 0.2733(0.2688) Grad: 116215.4062  LR: 0.00000001  \n","Epoch: [4][1140/1277] Elapsed 8m 21s (remain 0m 59s) Loss: 0.1583(0.2687) Grad: 502598.5000  LR: 0.00000001  \n","Epoch: [4][1160/1277] Elapsed 8m 30s (remain 0m 51s) Loss: 0.1948(0.2684) Grad: 341465.5312  LR: 0.00000001  \n","Epoch: [4][1180/1277] Elapsed 8m 39s (remain 0m 42s) Loss: 0.2284(0.2682) Grad: 183242.0156  LR: 0.00000000  \n","Epoch: [4][1200/1277] Elapsed 8m 48s (remain 0m 33s) Loss: 0.1351(0.2680) Grad: 116422.7578  LR: 0.00000000  \n","Epoch: [4][1220/1277] Elapsed 8m 57s (remain 0m 24s) Loss: 0.1658(0.2672) Grad: 153823.9375  LR: 0.00000000  \n","Epoch: [4][1240/1277] Elapsed 9m 6s (remain 0m 15s) Loss: 0.2115(0.2668) Grad: 380881.6250  LR: 0.00000000  \n","Epoch: [4][1260/1277] Elapsed 9m 14s (remain 0m 7s) Loss: 0.1598(0.2672) Grad: 122834.0156  LR: 0.00000000  \n","Epoch: [4][1276/1277] Elapsed 9m 22s (remain 0m 0s) Loss: 0.2958(0.2672) Grad: 145183.4844  LR: 0.00000000  \n","EVAL: [0/258] Elapsed 0m 0s (remain 3m 28s) Loss: 0.2520(0.2520) \n","EVAL: [20/258] Elapsed 0m 12s (remain 2m 25s) Loss: 0.4767(0.3895) \n","EVAL: [40/258] Elapsed 0m 25s (remain 2m 14s) Loss: 0.2580(0.3775) \n","EVAL: [60/258] Elapsed 0m 37s (remain 2m 1s) Loss: 0.3305(0.3650) \n","EVAL: [80/258] Elapsed 0m 49s (remain 1m 47s) Loss: 0.3521(0.3639) \n","EVAL: [100/258] Elapsed 1m 0s (remain 1m 34s) Loss: 0.3659(0.3662) \n","EVAL: [120/258] Elapsed 1m 13s (remain 1m 22s) Loss: 0.4343(0.3690) \n","EVAL: [140/258] Elapsed 1m 25s (remain 1m 10s) Loss: 0.2293(0.3668) \n","EVAL: [160/258] Elapsed 1m 37s (remain 0m 58s) Loss: 0.2819(0.3658) \n","EVAL: [180/258] Elapsed 1m 48s (remain 0m 46s) Loss: 0.2067(0.3636) \n","EVAL: [200/258] Elapsed 2m 0s (remain 0m 34s) Loss: 0.2995(0.3612) \n","EVAL: [220/258] Elapsed 2m 12s (remain 0m 22s) Loss: 0.2025(0.3608) \n","EVAL: [240/258] Elapsed 2m 25s (remain 0m 10s) Loss: 0.3540(0.3598) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2672  avg_val_loss: 0.3591  time: 717s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2672  avg_val_loss: 0.3591  time: 717s\n","Epoch 4 - Score: 0.4654  Scores: [0.39583632324723655, 0.5349437231233777]\n","INFO:__main__:Epoch 4 - Score: 0.4654  Scores: [0.39583632324723655, 0.5349437231233777]\n","Epoch 4 - Save Best Score: 0.4654 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.4654 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [257/258] Elapsed 2m 34s (remain 0m 0s) Loss: 0.2574(0.3591) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.4654  Scores: [0.39583632324723655, 0.5349437231233777]\n","INFO:__main__:Score: 0.4654  Scores: [0.39583632324723655, 0.5349437231233777]\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["========== prompt_id: ['3b9047'] validation ==========\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1289] Elapsed 0m 0s (remain 18m 10s) Loss: 1.6900(1.6900) Grad: nan  LR: 0.00000500  \n","Epoch: [1][20/1289] Elapsed 0m 9s (remain 9m 48s) Loss: 0.9303(0.8280) Grad: 193538.8438  LR: 0.00000500  \n","Epoch: [1][40/1289] Elapsed 0m 18s (remain 9m 24s) Loss: 1.0490(0.8066) Grad: 128732.6094  LR: 0.00000500  \n","Epoch: [1][60/1289] Elapsed 0m 27s (remain 9m 5s) Loss: 0.6676(0.7884) Grad: 81768.9531  LR: 0.00000500  \n","Epoch: [1][80/1289] Elapsed 0m 35s (remain 8m 56s) Loss: 1.3247(0.7667) Grad: 765052.8750  LR: 0.00000500  \n","Epoch: [1][100/1289] Elapsed 0m 44s (remain 8m 42s) Loss: 0.4763(0.7387) Grad: 359124.5312  LR: 0.00000500  \n","Epoch: [1][120/1289] Elapsed 0m 53s (remain 8m 33s) Loss: 0.5581(0.7130) Grad: 247514.8281  LR: 0.00000499  \n","Epoch: [1][140/1289] Elapsed 1m 2s (remain 8m 25s) Loss: 0.7721(0.6970) Grad: 370200.1875  LR: 0.00000499  \n","Epoch: [1][160/1289] Elapsed 1m 10s (remain 8m 15s) Loss: 0.7688(0.6861) Grad: 1456553.7500  LR: 0.00000499  \n","Epoch: [1][180/1289] Elapsed 1m 19s (remain 8m 5s) Loss: 0.4185(0.6591) Grad: 160909.0781  LR: 0.00000498  \n","Epoch: [1][200/1289] Elapsed 1m 27s (remain 7m 56s) Loss: 0.3431(0.6462) Grad: 643681.9375  LR: 0.00000498  \n","Epoch: [1][220/1289] Elapsed 1m 36s (remain 7m 46s) Loss: 0.3094(0.6321) Grad: 72118.4688  LR: 0.00000498  \n","Epoch: [1][240/1289] Elapsed 1m 45s (remain 7m 37s) Loss: 0.6290(0.6309) Grad: 331641.5625  LR: 0.00000497  \n","Epoch: [1][260/1289] Elapsed 1m 53s (remain 7m 27s) Loss: 0.6411(0.6262) Grad: 280465.7500  LR: 0.00000497  \n","Epoch: [1][280/1289] Elapsed 2m 2s (remain 7m 19s) Loss: 0.6419(0.6219) Grad: 419899.8125  LR: 0.00000496  \n","Epoch: [1][300/1289] Elapsed 2m 11s (remain 7m 10s) Loss: 0.6209(0.6123) Grad: 729531.6250  LR: 0.00000496  \n","Epoch: [1][320/1289] Elapsed 2m 19s (remain 7m 0s) Loss: 0.5808(0.6033) Grad: 287834.6250  LR: 0.00000495  \n","Epoch: [1][340/1289] Elapsed 2m 27s (remain 6m 51s) Loss: 0.2591(0.5918) Grad: 343165.6562  LR: 0.00000495  \n","Epoch: [1][360/1289] Elapsed 2m 36s (remain 6m 42s) Loss: 0.5069(0.5876) Grad: 189708.7344  LR: 0.00000494  \n","Epoch: [1][380/1289] Elapsed 2m 45s (remain 6m 34s) Loss: 0.3171(0.5857) Grad: 272943.3125  LR: 0.00000493  \n","Epoch: [1][400/1289] Elapsed 2m 54s (remain 6m 25s) Loss: 0.4855(0.5798) Grad: 263015.4062  LR: 0.00000493  \n","Epoch: [1][420/1289] Elapsed 3m 2s (remain 6m 16s) Loss: 0.6418(0.5734) Grad: 277508.2500  LR: 0.00000492  \n","Epoch: [1][440/1289] Elapsed 3m 11s (remain 6m 8s) Loss: 0.3276(0.5701) Grad: 281927.4375  LR: 0.00000491  \n","Epoch: [1][460/1289] Elapsed 3m 20s (remain 5m 59s) Loss: 0.3365(0.5635) Grad: 378993.0938  LR: 0.00000490  \n","Epoch: [1][480/1289] Elapsed 3m 28s (remain 5m 50s) Loss: 0.4993(0.5601) Grad: 177667.4688  LR: 0.00000489  \n","Epoch: [1][500/1289] Elapsed 3m 37s (remain 5m 41s) Loss: 0.9548(0.5564) Grad: 605751.2500  LR: 0.00000488  \n","Epoch: [1][520/1289] Elapsed 3m 45s (remain 5m 32s) Loss: 0.5187(0.5522) Grad: 266543.6250  LR: 0.00000488  \n","Epoch: [1][540/1289] Elapsed 3m 54s (remain 5m 23s) Loss: 0.3118(0.5479) Grad: 432290.7812  LR: 0.00000487  \n","Epoch: [1][560/1289] Elapsed 4m 2s (remain 5m 15s) Loss: 0.3030(0.5434) Grad: 103823.9766  LR: 0.00000486  \n","Epoch: [1][580/1289] Elapsed 4m 11s (remain 5m 6s) Loss: 0.3365(0.5400) Grad: 105832.3906  LR: 0.00000484  \n","Epoch: [1][600/1289] Elapsed 4m 20s (remain 4m 58s) Loss: 0.4116(0.5361) Grad: 167488.1094  LR: 0.00000483  \n","Epoch: [1][620/1289] Elapsed 4m 29s (remain 4m 49s) Loss: 0.4135(0.5331) Grad: 676631.0000  LR: 0.00000482  \n","Epoch: [1][640/1289] Elapsed 4m 37s (remain 4m 40s) Loss: 0.4135(0.5294) Grad: 590244.0000  LR: 0.00000481  \n","Epoch: [1][660/1289] Elapsed 4m 46s (remain 4m 32s) Loss: 0.3676(0.5268) Grad: 177882.6094  LR: 0.00000480  \n","Epoch: [1][680/1289] Elapsed 4m 55s (remain 4m 23s) Loss: 0.4464(0.5249) Grad: 139734.6719  LR: 0.00000479  \n","Epoch: [1][700/1289] Elapsed 5m 3s (remain 4m 14s) Loss: 0.3344(0.5203) Grad: 91453.7891  LR: 0.00000478  \n","Epoch: [1][720/1289] Elapsed 5m 12s (remain 4m 5s) Loss: 0.3325(0.5160) Grad: 115013.3828  LR: 0.00000476  \n","Epoch: [1][740/1289] Elapsed 5m 20s (remain 3m 57s) Loss: 0.4133(0.5148) Grad: 286392.0938  LR: 0.00000475  \n","Epoch: [1][760/1289] Elapsed 5m 29s (remain 3m 48s) Loss: 0.4572(0.5127) Grad: 171971.7031  LR: 0.00000474  \n","Epoch: [1][780/1289] Elapsed 5m 37s (remain 3m 39s) Loss: 0.2519(0.5080) Grad: 237717.4375  LR: 0.00000472  \n","Epoch: [1][800/1289] Elapsed 5m 46s (remain 3m 31s) Loss: 0.7939(0.5070) Grad: 367250.6250  LR: 0.00000471  \n","Epoch: [1][820/1289] Elapsed 5m 55s (remain 3m 22s) Loss: 0.5141(0.5053) Grad: 362143.7812  LR: 0.00000469  \n","Epoch: [1][840/1289] Elapsed 6m 3s (remain 3m 13s) Loss: 0.5128(0.5025) Grad: 220605.7188  LR: 0.00000468  \n","Epoch: [1][860/1289] Elapsed 6m 12s (remain 3m 5s) Loss: 0.4513(0.5006) Grad: 137429.1250  LR: 0.00000466  \n","Epoch: [1][880/1289] Elapsed 6m 21s (remain 2m 56s) Loss: 0.3334(0.4978) Grad: 315372.5000  LR: 0.00000465  \n","Epoch: [1][900/1289] Elapsed 6m 30s (remain 2m 47s) Loss: 0.2432(0.4948) Grad: 212418.9219  LR: 0.00000463  \n","Epoch: [1][920/1289] Elapsed 6m 38s (remain 2m 39s) Loss: 0.3526(0.4919) Grad: 63028.7422  LR: 0.00000462  \n","Epoch: [1][940/1289] Elapsed 6m 47s (remain 2m 30s) Loss: 0.2292(0.4888) Grad: 106538.1641  LR: 0.00000460  \n","Epoch: [1][960/1289] Elapsed 6m 55s (remain 2m 21s) Loss: 0.3328(0.4860) Grad: 164814.0156  LR: 0.00000458  \n","Epoch: [1][980/1289] Elapsed 7m 4s (remain 2m 13s) Loss: 0.3097(0.4836) Grad: 76199.1172  LR: 0.00000457  \n","Epoch: [1][1000/1289] Elapsed 7m 13s (remain 2m 4s) Loss: 0.5113(0.4818) Grad: 320737.5312  LR: 0.00000455  \n","Epoch: [1][1020/1289] Elapsed 7m 21s (remain 1m 55s) Loss: 0.6407(0.4815) Grad: 302093.1250  LR: 0.00000453  \n","Epoch: [1][1040/1289] Elapsed 7m 30s (remain 1m 47s) Loss: 0.4208(0.4807) Grad: 138085.7188  LR: 0.00000451  \n","Epoch: [1][1060/1289] Elapsed 7m 39s (remain 1m 38s) Loss: 0.3966(0.4795) Grad: 92096.7031  LR: 0.00000450  \n","Epoch: [1][1080/1289] Elapsed 7m 47s (remain 1m 30s) Loss: 0.3871(0.4773) Grad: 182335.5469  LR: 0.00000448  \n","Epoch: [1][1100/1289] Elapsed 7m 56s (remain 1m 21s) Loss: 0.4895(0.4754) Grad: 310414.2812  LR: 0.00000446  \n","Epoch: [1][1120/1289] Elapsed 8m 5s (remain 1m 12s) Loss: 0.5415(0.4732) Grad: 288850.2188  LR: 0.00000444  \n","Epoch: [1][1140/1289] Elapsed 8m 14s (remain 1m 4s) Loss: 0.4053(0.4728) Grad: 41266.6367  LR: 0.00000442  \n","Epoch: [1][1160/1289] Elapsed 8m 22s (remain 0m 55s) Loss: 0.5361(0.4715) Grad: 223668.7031  LR: 0.00000440  \n","Epoch: [1][1180/1289] Elapsed 8m 31s (remain 0m 46s) Loss: 0.2723(0.4706) Grad: 107783.5703  LR: 0.00000438  \n","Epoch: [1][1200/1289] Elapsed 8m 40s (remain 0m 38s) Loss: 0.4673(0.4697) Grad: 87350.1797  LR: 0.00000436  \n","Epoch: [1][1220/1289] Elapsed 8m 49s (remain 0m 29s) Loss: 0.4937(0.4687) Grad: 171390.1719  LR: 0.00000434  \n","Epoch: [1][1240/1289] Elapsed 8m 57s (remain 0m 20s) Loss: 0.3555(0.4679) Grad: 63796.4023  LR: 0.00000432  \n","Epoch: [1][1260/1289] Elapsed 9m 6s (remain 0m 12s) Loss: 0.3576(0.4668) Grad: 185687.2500  LR: 0.00000430  \n","Epoch: [1][1280/1289] Elapsed 9m 15s (remain 0m 3s) Loss: 0.3729(0.4650) Grad: 124749.0156  LR: 0.00000428  \n","Epoch: [1][1288/1289] Elapsed 9m 18s (remain 0m 0s) Loss: 0.3076(0.4650) Grad: 166933.0312  LR: 0.00000427  \n","EVAL: [0/252] Elapsed 0m 0s (remain 4m 9s) Loss: 0.7930(0.7930) \n","EVAL: [20/252] Elapsed 0m 13s (remain 2m 29s) Loss: 0.7540(0.7063) \n","EVAL: [40/252] Elapsed 0m 25s (remain 2m 12s) Loss: 0.7594(0.7126) \n","EVAL: [60/252] Elapsed 0m 37s (remain 1m 58s) Loss: 0.6775(0.7042) \n","EVAL: [80/252] Elapsed 0m 50s (remain 1m 46s) Loss: 0.8048(0.6961) \n","EVAL: [100/252] Elapsed 1m 2s (remain 1m 33s) Loss: 0.4415(0.6901) \n","EVAL: [120/252] Elapsed 1m 14s (remain 1m 20s) Loss: 0.6625(0.6910) \n","EVAL: [140/252] Elapsed 1m 27s (remain 1m 8s) Loss: 0.7874(0.6938) \n","EVAL: [160/252] Elapsed 1m 39s (remain 0m 56s) Loss: 0.6783(0.6927) \n","EVAL: [180/252] Elapsed 1m 50s (remain 0m 43s) Loss: 1.0592(0.6968) \n","EVAL: [200/252] Elapsed 2m 2s (remain 0m 31s) Loss: 0.8878(0.7015) \n","EVAL: [220/252] Elapsed 2m 15s (remain 0m 19s) Loss: 0.3822(0.7001) \n","EVAL: [240/252] Elapsed 2m 27s (remain 0m 6s) Loss: 0.9333(0.6963) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.4650  avg_val_loss: 0.6953  time: 713s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4650  avg_val_loss: 0.6953  time: 713s\n","Epoch 1 - Score: 0.8406  Scores: [0.7779752297077392, 0.9032787886020053]\n","INFO:__main__:Epoch 1 - Score: 0.8406  Scores: [0.7779752297077392, 0.9032787886020053]\n","Epoch 1 - Save Best Score: 0.8406 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.8406 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [251/252] Elapsed 2m 33s (remain 0m 0s) Loss: 0.7895(0.6953) \n","Epoch: [2][0/1289] Elapsed 0m 0s (remain 16m 43s) Loss: 0.7640(0.7640) Grad: inf  LR: 0.00000427  \n","Epoch: [2][20/1289] Elapsed 0m 9s (remain 9m 32s) Loss: 0.2214(0.4304) Grad: 392023.1875  LR: 0.00000425  \n","Epoch: [2][40/1289] Elapsed 0m 18s (remain 9m 10s) Loss: 0.3764(0.3970) Grad: 217018.8438  LR: 0.00000422  \n","Epoch: [2][60/1289] Elapsed 0m 26s (remain 9m 1s) Loss: 0.2918(0.3738) Grad: 345003.7812  LR: 0.00000420  \n","Epoch: [2][80/1289] Elapsed 0m 35s (remain 8m 50s) Loss: 0.2816(0.3777) Grad: 471616.8438  LR: 0.00000418  \n","Epoch: [2][100/1289] Elapsed 0m 43s (remain 8m 36s) Loss: 0.2585(0.3703) Grad: 369491.1875  LR: 0.00000416  \n","Epoch: [2][120/1289] Elapsed 0m 52s (remain 8m 29s) Loss: 0.2747(0.3663) Grad: 305029.5625  LR: 0.00000413  \n","Epoch: [2][140/1289] Elapsed 1m 1s (remain 8m 21s) Loss: 0.2496(0.3658) Grad: 177834.7188  LR: 0.00000411  \n","Epoch: [2][160/1289] Elapsed 1m 10s (remain 8m 13s) Loss: 0.3504(0.3657) Grad: 213498.6406  LR: 0.00000409  \n","Epoch: [2][180/1289] Elapsed 1m 19s (remain 8m 3s) Loss: 0.5460(0.3631) Grad: 256341.7031  LR: 0.00000406  \n","Epoch: [2][200/1289] Elapsed 1m 27s (remain 7m 53s) Loss: 0.2176(0.3567) Grad: 525774.5000  LR: 0.00000404  \n","Epoch: [2][220/1289] Elapsed 1m 36s (remain 7m 45s) Loss: 0.4063(0.3537) Grad: 426430.0625  LR: 0.00000401  \n","Epoch: [2][240/1289] Elapsed 1m 44s (remain 7m 36s) Loss: 0.2221(0.3522) Grad: 229523.4375  LR: 0.00000399  \n","Epoch: [2][260/1289] Elapsed 1m 53s (remain 7m 27s) Loss: 0.3113(0.3531) Grad: 135370.7344  LR: 0.00000397  \n","Epoch: [2][280/1289] Elapsed 2m 2s (remain 7m 18s) Loss: 0.3342(0.3511) Grad: 187844.7344  LR: 0.00000394  \n","Epoch: [2][300/1289] Elapsed 2m 10s (remain 7m 9s) Loss: 0.3066(0.3540) Grad: 408313.5938  LR: 0.00000392  \n","Epoch: [2][320/1289] Elapsed 2m 19s (remain 7m 0s) Loss: 0.4564(0.3511) Grad: 427758.0312  LR: 0.00000389  \n","Epoch: [2][340/1289] Elapsed 2m 28s (remain 6m 51s) Loss: 0.2114(0.3517) Grad: 142264.4219  LR: 0.00000387  \n","Epoch: [2][360/1289] Elapsed 2m 36s (remain 6m 43s) Loss: 0.2408(0.3516) Grad: 96630.0703  LR: 0.00000384  \n","Epoch: [2][380/1289] Elapsed 2m 45s (remain 6m 34s) Loss: 0.2107(0.3503) Grad: 696744.8125  LR: 0.00000381  \n","Epoch: [2][400/1289] Elapsed 2m 54s (remain 6m 25s) Loss: 0.6055(0.3501) Grad: 508020.0625  LR: 0.00000379  \n","Epoch: [2][420/1289] Elapsed 3m 2s (remain 6m 16s) Loss: 0.2248(0.3514) Grad: 257580.5781  LR: 0.00000376  \n","Epoch: [2][440/1289] Elapsed 3m 11s (remain 6m 7s) Loss: 0.6619(0.3532) Grad: 803215.7500  LR: 0.00000374  \n","Epoch: [2][460/1289] Elapsed 3m 19s (remain 5m 58s) Loss: 0.3341(0.3517) Grad: 337477.7812  LR: 0.00000371  \n","Epoch: [2][480/1289] Elapsed 3m 28s (remain 5m 50s) Loss: 0.3349(0.3510) Grad: 437284.7812  LR: 0.00000368  \n","Epoch: [2][500/1289] Elapsed 3m 37s (remain 5m 41s) Loss: 0.2594(0.3518) Grad: 120491.1484  LR: 0.00000365  \n","Epoch: [2][520/1289] Elapsed 3m 46s (remain 5m 33s) Loss: 0.2130(0.3508) Grad: 186064.6719  LR: 0.00000363  \n","Epoch: [2][540/1289] Elapsed 3m 54s (remain 5m 24s) Loss: 0.2387(0.3508) Grad: 445828.4062  LR: 0.00000360  \n","Epoch: [2][560/1289] Elapsed 4m 3s (remain 5m 16s) Loss: 0.4992(0.3504) Grad: 319077.0312  LR: 0.00000357  \n","Epoch: [2][580/1289] Elapsed 4m 11s (remain 5m 6s) Loss: 0.2784(0.3491) Grad: 300690.4375  LR: 0.00000355  \n","Epoch: [2][600/1289] Elapsed 4m 20s (remain 4m 57s) Loss: 0.3932(0.3475) Grad: 216857.5625  LR: 0.00000352  \n","Epoch: [2][620/1289] Elapsed 4m 28s (remain 4m 49s) Loss: 0.3176(0.3466) Grad: 263549.5000  LR: 0.00000349  \n","Epoch: [2][640/1289] Elapsed 4m 37s (remain 4m 40s) Loss: 0.3002(0.3467) Grad: 360411.5000  LR: 0.00000346  \n","Epoch: [2][660/1289] Elapsed 4m 46s (remain 4m 32s) Loss: 0.5559(0.3455) Grad: 280972.6562  LR: 0.00000343  \n","Epoch: [2][680/1289] Elapsed 4m 54s (remain 4m 22s) Loss: 0.1836(0.3450) Grad: 367912.5000  LR: 0.00000341  \n","Epoch: [2][700/1289] Elapsed 5m 2s (remain 4m 14s) Loss: 0.6455(0.3452) Grad: 414964.2812  LR: 0.00000338  \n","Epoch: [2][720/1289] Elapsed 5m 11s (remain 4m 5s) Loss: 0.3376(0.3454) Grad: 284768.1250  LR: 0.00000335  \n","Epoch: [2][740/1289] Elapsed 5m 20s (remain 3m 56s) Loss: 0.3336(0.3449) Grad: 137520.4688  LR: 0.00000332  \n","Epoch: [2][760/1289] Elapsed 5m 28s (remain 3m 48s) Loss: 0.7663(0.3452) Grad: 246870.7812  LR: 0.00000329  \n","Epoch: [2][780/1289] Elapsed 5m 37s (remain 3m 39s) Loss: 0.5221(0.3443) Grad: 323772.0000  LR: 0.00000326  \n","Epoch: [2][800/1289] Elapsed 5m 45s (remain 3m 30s) Loss: 0.2134(0.3437) Grad: 101636.1641  LR: 0.00000323  \n","Epoch: [2][820/1289] Elapsed 5m 54s (remain 3m 22s) Loss: 0.2322(0.3428) Grad: 205362.4531  LR: 0.00000320  \n","Epoch: [2][840/1289] Elapsed 6m 3s (remain 3m 13s) Loss: 0.4006(0.3426) Grad: 212738.7656  LR: 0.00000317  \n","Epoch: [2][860/1289] Elapsed 6m 11s (remain 3m 4s) Loss: 0.1783(0.3425) Grad: 205086.7812  LR: 0.00000314  \n","Epoch: [2][880/1289] Elapsed 6m 20s (remain 2m 56s) Loss: 0.1813(0.3418) Grad: 485308.1250  LR: 0.00000312  \n","Epoch: [2][900/1289] Elapsed 6m 29s (remain 2m 47s) Loss: 0.5826(0.3418) Grad: 128567.1094  LR: 0.00000309  \n","Epoch: [2][920/1289] Elapsed 6m 38s (remain 2m 39s) Loss: 0.1926(0.3420) Grad: 182945.3125  LR: 0.00000306  \n","Epoch: [2][940/1289] Elapsed 6m 46s (remain 2m 30s) Loss: 0.3092(0.3417) Grad: 259422.9531  LR: 0.00000303  \n","Epoch: [2][960/1289] Elapsed 6m 55s (remain 2m 21s) Loss: 0.2951(0.3413) Grad: 269612.4375  LR: 0.00000300  \n","Epoch: [2][980/1289] Elapsed 7m 3s (remain 2m 12s) Loss: 0.2502(0.3411) Grad: 201113.2500  LR: 0.00000297  \n","Epoch: [2][1000/1289] Elapsed 7m 12s (remain 2m 4s) Loss: 0.4906(0.3410) Grad: 538081.7500  LR: 0.00000294  \n","Epoch: [2][1020/1289] Elapsed 7m 20s (remain 1m 55s) Loss: 0.2922(0.3401) Grad: 402603.7812  LR: 0.00000291  \n","Epoch: [2][1040/1289] Elapsed 7m 29s (remain 1m 46s) Loss: 0.3136(0.3394) Grad: 145454.3906  LR: 0.00000288  \n","Epoch: [2][1060/1289] Elapsed 7m 37s (remain 1m 38s) Loss: 0.4199(0.3384) Grad: 145858.1406  LR: 0.00000285  \n","Epoch: [2][1080/1289] Elapsed 7m 46s (remain 1m 29s) Loss: 0.1629(0.3388) Grad: 310950.1250  LR: 0.00000282  \n","Epoch: [2][1100/1289] Elapsed 7m 54s (remain 1m 21s) Loss: 0.2679(0.3389) Grad: 218448.5625  LR: 0.00000279  \n","Epoch: [2][1120/1289] Elapsed 8m 3s (remain 1m 12s) Loss: 0.3188(0.3394) Grad: 90363.8281  LR: 0.00000276  \n","Epoch: [2][1140/1289] Elapsed 8m 11s (remain 1m 3s) Loss: 0.3357(0.3394) Grad: 124372.6875  LR: 0.00000273  \n","Epoch: [2][1160/1289] Elapsed 8m 20s (remain 0m 55s) Loss: 0.2671(0.3389) Grad: 243198.2500  LR: 0.00000269  \n","Epoch: [2][1180/1289] Elapsed 8m 28s (remain 0m 46s) Loss: 0.3912(0.3385) Grad: 535499.8125  LR: 0.00000266  \n","Epoch: [2][1200/1289] Elapsed 8m 37s (remain 0m 37s) Loss: 0.3612(0.3383) Grad: 167661.9688  LR: 0.00000263  \n","Epoch: [2][1220/1289] Elapsed 8m 46s (remain 0m 29s) Loss: 0.1592(0.3381) Grad: 145762.5781  LR: 0.00000260  \n","Epoch: [2][1240/1289] Elapsed 8m 54s (remain 0m 20s) Loss: 0.2961(0.3376) Grad: 177177.4219  LR: 0.00000257  \n","Epoch: [2][1260/1289] Elapsed 9m 3s (remain 0m 12s) Loss: 0.5081(0.3376) Grad: 427943.1562  LR: 0.00000254  \n","Epoch: [2][1280/1289] Elapsed 9m 12s (remain 0m 3s) Loss: 0.3967(0.3373) Grad: 288640.8750  LR: 0.00000251  \n","Epoch: [2][1288/1289] Elapsed 9m 15s (remain 0m 0s) Loss: 0.2888(0.3370) Grad: 251863.0625  LR: 0.00000250  \n","EVAL: [0/252] Elapsed 0m 0s (remain 4m 10s) Loss: 0.4899(0.4899) \n","EVAL: [20/252] Elapsed 0m 13s (remain 2m 28s) Loss: 0.4922(0.4503) \n","EVAL: [40/252] Elapsed 0m 25s (remain 2m 11s) Loss: 0.3440(0.4527) \n","EVAL: [60/252] Elapsed 0m 37s (remain 1m 58s) Loss: 0.4396(0.4473) \n","EVAL: [80/252] Elapsed 0m 50s (remain 1m 45s) Loss: 0.4311(0.4409) \n","EVAL: [100/252] Elapsed 1m 2s (remain 1m 33s) Loss: 0.3282(0.4379) \n","EVAL: [120/252] Elapsed 1m 14s (remain 1m 20s) Loss: 0.3771(0.4324) \n","EVAL: [140/252] Elapsed 1m 26s (remain 1m 8s) Loss: 0.4367(0.4349) \n","EVAL: [160/252] Elapsed 1m 39s (remain 0m 56s) Loss: 0.5066(0.4371) \n","EVAL: [180/252] Elapsed 1m 50s (remain 0m 43s) Loss: 0.4842(0.4383) \n","EVAL: [200/252] Elapsed 2m 2s (remain 0m 31s) Loss: 0.4858(0.4392) \n","EVAL: [220/252] Elapsed 2m 15s (remain 0m 19s) Loss: 0.5001(0.4408) \n","EVAL: [240/252] Elapsed 2m 27s (remain 0m 6s) Loss: 0.5119(0.4383) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3370  avg_val_loss: 0.4390  time: 709s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3370  avg_val_loss: 0.4390  time: 709s\n","Epoch 2 - Score: 0.5606  Scores: [0.5184668684609455, 0.602665491343888]\n","INFO:__main__:Epoch 2 - Score: 0.5606  Scores: [0.5184668684609455, 0.602665491343888]\n","Epoch 2 - Save Best Score: 0.5606 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5606 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [251/252] Elapsed 2m 33s (remain 0m 0s) Loss: 0.4517(0.4390) \n","Epoch: [3][0/1289] Elapsed 0m 0s (remain 16m 30s) Loss: 0.4577(0.4577) Grad: inf  LR: 0.00000250  \n","Epoch: [3][20/1289] Elapsed 0m 9s (remain 9m 13s) Loss: 0.2204(0.2868) Grad: 195042.0312  LR: 0.00000247  \n","Epoch: [3][40/1289] Elapsed 0m 17s (remain 9m 0s) Loss: 0.2570(0.2814) Grad: 285724.2500  LR: 0.00000244  \n","Epoch: [3][60/1289] Elapsed 0m 26s (remain 8m 49s) Loss: 0.4700(0.2770) Grad: 197902.5938  LR: 0.00000241  \n","Epoch: [3][80/1289] Elapsed 0m 35s (remain 8m 42s) Loss: 0.3233(0.2817) Grad: 373620.1875  LR: 0.00000238  \n","Epoch: [3][100/1289] Elapsed 0m 43s (remain 8m 33s) Loss: 0.2997(0.2848) Grad: 529268.9375  LR: 0.00000235  \n","Epoch: [3][120/1289] Elapsed 0m 52s (remain 8m 26s) Loss: 0.3767(0.2886) Grad: 191595.0000  LR: 0.00000232  \n","Epoch: [3][140/1289] Elapsed 1m 1s (remain 8m 17s) Loss: 0.3185(0.2930) Grad: 160826.1406  LR: 0.00000229  \n","Epoch: [3][160/1289] Elapsed 1m 9s (remain 8m 8s) Loss: 0.2224(0.2947) Grad: 436301.5000  LR: 0.00000226  \n","Epoch: [3][180/1289] Elapsed 1m 18s (remain 7m 59s) Loss: 0.1864(0.2936) Grad: 271364.5312  LR: 0.00000222  \n","Epoch: [3][200/1289] Elapsed 1m 26s (remain 7m 49s) Loss: 0.3545(0.2944) Grad: 189005.7344  LR: 0.00000219  \n","Epoch: [3][220/1289] Elapsed 1m 35s (remain 7m 42s) Loss: 0.3675(0.2984) Grad: 112964.5312  LR: 0.00000216  \n","Epoch: [3][240/1289] Elapsed 1m 44s (remain 7m 32s) Loss: 0.4325(0.2996) Grad: 316760.2500  LR: 0.00000213  \n","Epoch: [3][260/1289] Elapsed 1m 52s (remain 7m 23s) Loss: 0.3927(0.3022) Grad: 71378.6719  LR: 0.00000210  \n","Epoch: [3][280/1289] Elapsed 2m 1s (remain 7m 14s) Loss: 0.2568(0.3036) Grad: 166779.1250  LR: 0.00000207  \n","Epoch: [3][300/1289] Elapsed 2m 9s (remain 7m 6s) Loss: 0.2080(0.3045) Grad: 187862.4219  LR: 0.00000204  \n","Epoch: [3][320/1289] Elapsed 2m 18s (remain 6m 56s) Loss: 0.6728(0.3048) Grad: 430185.8750  LR: 0.00000201  \n","Epoch: [3][340/1289] Elapsed 2m 26s (remain 6m 48s) Loss: 0.3419(0.3042) Grad: 127564.1172  LR: 0.00000198  \n","Epoch: [3][360/1289] Elapsed 2m 35s (remain 6m 40s) Loss: 0.3812(0.3020) Grad: 369886.6875  LR: 0.00000195  \n","Epoch: [3][380/1289] Elapsed 2m 44s (remain 6m 31s) Loss: 0.3252(0.3038) Grad: 381048.6562  LR: 0.00000192  \n","Epoch: [3][400/1289] Elapsed 2m 52s (remain 6m 22s) Loss: 0.1354(0.3036) Grad: 220594.8750  LR: 0.00000190  \n","Epoch: [3][420/1289] Elapsed 3m 1s (remain 6m 13s) Loss: 0.2715(0.3039) Grad: 290098.5625  LR: 0.00000187  \n","Epoch: [3][440/1289] Elapsed 3m 9s (remain 6m 5s) Loss: 0.2086(0.3031) Grad: 326267.5625  LR: 0.00000184  \n","Epoch: [3][460/1289] Elapsed 3m 18s (remain 5m 56s) Loss: 0.4277(0.3036) Grad: 386646.8125  LR: 0.00000181  \n","Epoch: [3][480/1289] Elapsed 3m 27s (remain 5m 48s) Loss: 0.4164(0.3051) Grad: 168067.9062  LR: 0.00000178  \n","Epoch: [3][500/1289] Elapsed 3m 35s (remain 5m 39s) Loss: 0.2839(0.3045) Grad: 162855.5938  LR: 0.00000175  \n","Epoch: [3][520/1289] Elapsed 3m 44s (remain 5m 30s) Loss: 0.4185(0.3042) Grad: 213216.6250  LR: 0.00000172  \n","Epoch: [3][540/1289] Elapsed 3m 53s (remain 5m 22s) Loss: 0.2591(0.3042) Grad: 193996.7500  LR: 0.00000169  \n","Epoch: [3][560/1289] Elapsed 4m 1s (remain 5m 13s) Loss: 0.2718(0.3036) Grad: 386583.0625  LR: 0.00000166  \n","Epoch: [3][580/1289] Elapsed 4m 10s (remain 5m 4s) Loss: 0.2150(0.3035) Grad: 235592.4375  LR: 0.00000163  \n","Epoch: [3][600/1289] Elapsed 4m 18s (remain 4m 56s) Loss: 0.2339(0.3041) Grad: 219285.6094  LR: 0.00000160  \n","Epoch: [3][620/1289] Elapsed 4m 27s (remain 4m 47s) Loss: 0.3629(0.3031) Grad: 604610.4375  LR: 0.00000158  \n","Epoch: [3][640/1289] Elapsed 4m 36s (remain 4m 39s) Loss: 0.2971(0.3026) Grad: 143181.6562  LR: 0.00000155  \n","Epoch: [3][660/1289] Elapsed 4m 45s (remain 4m 31s) Loss: 0.1530(0.3013) Grad: 325876.7188  LR: 0.00000152  \n","Epoch: [3][680/1289] Elapsed 4m 53s (remain 4m 22s) Loss: 0.3317(0.3006) Grad: 300113.3438  LR: 0.00000149  \n","Epoch: [3][700/1289] Elapsed 5m 2s (remain 4m 13s) Loss: 0.1901(0.3010) Grad: 230043.0625  LR: 0.00000146  \n","Epoch: [3][720/1289] Elapsed 5m 11s (remain 4m 5s) Loss: 0.1584(0.3013) Grad: 71284.5703  LR: 0.00000144  \n","Epoch: [3][740/1289] Elapsed 5m 19s (remain 3m 56s) Loss: 0.4609(0.3011) Grad: 327287.9062  LR: 0.00000141  \n","Epoch: [3][760/1289] Elapsed 5m 28s (remain 3m 47s) Loss: 0.3914(0.3008) Grad: 120772.8984  LR: 0.00000138  \n","Epoch: [3][780/1289] Elapsed 5m 36s (remain 3m 39s) Loss: 0.1867(0.3007) Grad: 274846.5938  LR: 0.00000135  \n","Epoch: [3][800/1289] Elapsed 5m 45s (remain 3m 30s) Loss: 0.3457(0.3012) Grad: 134085.0625  LR: 0.00000133  \n","Epoch: [3][820/1289] Elapsed 5m 54s (remain 3m 21s) Loss: 0.5390(0.3010) Grad: 188208.4219  LR: 0.00000130  \n","Epoch: [3][840/1289] Elapsed 6m 2s (remain 3m 13s) Loss: 0.2642(0.3015) Grad: 202503.6406  LR: 0.00000127  \n","Epoch: [3][860/1289] Elapsed 6m 11s (remain 3m 4s) Loss: 0.3525(0.3014) Grad: 184964.5469  LR: 0.00000125  \n","Epoch: [3][880/1289] Elapsed 6m 19s (remain 2m 55s) Loss: 0.3140(0.3021) Grad: 172783.8438  LR: 0.00000122  \n","Epoch: [3][900/1289] Elapsed 6m 28s (remain 2m 47s) Loss: 0.3132(0.3023) Grad: 194036.7344  LR: 0.00000120  \n","Epoch: [3][920/1289] Elapsed 6m 36s (remain 2m 38s) Loss: 0.3794(0.3020) Grad: 192721.9844  LR: 0.00000117  \n","Epoch: [3][940/1289] Elapsed 6m 45s (remain 2m 29s) Loss: 0.2681(0.3017) Grad: 233304.8906  LR: 0.00000114  \n","Epoch: [3][960/1289] Elapsed 6m 53s (remain 2m 21s) Loss: 0.2377(0.3014) Grad: 278094.0312  LR: 0.00000112  \n","Epoch: [3][980/1289] Elapsed 7m 2s (remain 2m 12s) Loss: 0.2370(0.3011) Grad: 496621.0625  LR: 0.00000109  \n","Epoch: [3][1000/1289] Elapsed 7m 11s (remain 2m 4s) Loss: 0.3506(0.3012) Grad: 270403.3125  LR: 0.00000107  \n","Epoch: [3][1020/1289] Elapsed 7m 19s (remain 1m 55s) Loss: 0.3004(0.3009) Grad: 178625.1406  LR: 0.00000104  \n","Epoch: [3][1040/1289] Elapsed 7m 27s (remain 1m 46s) Loss: 0.3402(0.3001) Grad: 316081.4062  LR: 0.00000102  \n","Epoch: [3][1060/1289] Elapsed 7m 36s (remain 1m 38s) Loss: 0.4178(0.3006) Grad: 636343.6250  LR: 0.00000099  \n","Epoch: [3][1080/1289] Elapsed 7m 44s (remain 1m 29s) Loss: 0.2762(0.3001) Grad: 180852.8750  LR: 0.00000097  \n","Epoch: [3][1100/1289] Elapsed 7m 53s (remain 1m 20s) Loss: 0.1779(0.2994) Grad: 438513.0625  LR: 0.00000095  \n","Epoch: [3][1120/1289] Elapsed 8m 1s (remain 1m 12s) Loss: 0.2710(0.2988) Grad: 232738.5000  LR: 0.00000092  \n","Epoch: [3][1140/1289] Elapsed 8m 10s (remain 1m 3s) Loss: 0.2929(0.2987) Grad: 386243.3750  LR: 0.00000090  \n","Epoch: [3][1160/1289] Elapsed 8m 19s (remain 0m 55s) Loss: 0.3338(0.2984) Grad: 386298.6250  LR: 0.00000088  \n","Epoch: [3][1180/1289] Elapsed 8m 27s (remain 0m 46s) Loss: 0.2241(0.2982) Grad: 296155.0625  LR: 0.00000085  \n","Epoch: [3][1200/1289] Elapsed 8m 36s (remain 0m 37s) Loss: 0.3373(0.2979) Grad: 181960.7812  LR: 0.00000083  \n","Epoch: [3][1220/1289] Elapsed 8m 45s (remain 0m 29s) Loss: 0.2607(0.2979) Grad: 348413.0000  LR: 0.00000081  \n","Epoch: [3][1240/1289] Elapsed 8m 53s (remain 0m 20s) Loss: 0.3049(0.2976) Grad: 101509.2969  LR: 0.00000078  \n","Epoch: [3][1260/1289] Elapsed 9m 2s (remain 0m 12s) Loss: 0.2912(0.2970) Grad: 296148.1875  LR: 0.00000076  \n","Epoch: [3][1280/1289] Elapsed 9m 10s (remain 0m 3s) Loss: 0.2525(0.2967) Grad: 255023.7500  LR: 0.00000074  \n","Epoch: [3][1288/1289] Elapsed 9m 14s (remain 0m 0s) Loss: 0.3633(0.2970) Grad: 123144.1016  LR: 0.00000073  \n","EVAL: [0/252] Elapsed 0m 0s (remain 4m 5s) Loss: 0.4515(0.4515) \n","EVAL: [20/252] Elapsed 0m 13s (remain 2m 28s) Loss: 0.5143(0.4233) \n","EVAL: [40/252] Elapsed 0m 25s (remain 2m 11s) Loss: 0.3170(0.4216) \n","EVAL: [60/252] Elapsed 0m 37s (remain 1m 58s) Loss: 0.4236(0.4188) \n","EVAL: [80/252] Elapsed 0m 50s (remain 1m 45s) Loss: 0.4189(0.4139) \n","EVAL: [100/252] Elapsed 1m 2s (remain 1m 33s) Loss: 0.2773(0.4126) \n","EVAL: [120/252] Elapsed 1m 14s (remain 1m 20s) Loss: 0.3871(0.4066) \n","EVAL: [140/252] Elapsed 1m 26s (remain 1m 8s) Loss: 0.3903(0.4080) \n","EVAL: [160/252] Elapsed 1m 39s (remain 0m 56s) Loss: 0.4464(0.4097) \n","EVAL: [180/252] Elapsed 1m 50s (remain 0m 43s) Loss: 0.4074(0.4087) \n","EVAL: [200/252] Elapsed 2m 2s (remain 0m 31s) Loss: 0.3987(0.4091) \n","EVAL: [220/252] Elapsed 2m 15s (remain 0m 19s) Loss: 0.5145(0.4108) \n","EVAL: [240/252] Elapsed 2m 27s (remain 0m 6s) Loss: 0.4353(0.4093) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2970  avg_val_loss: 0.4101  time: 708s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2970  avg_val_loss: 0.4101  time: 708s\n","Epoch 3 - Score: 0.5323  Scores: [0.45984544460468624, 0.6047384115187127]\n","INFO:__main__:Epoch 3 - Score: 0.5323  Scores: [0.45984544460468624, 0.6047384115187127]\n","Epoch 3 - Save Best Score: 0.5323 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5323 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [251/252] Elapsed 2m 33s (remain 0m 0s) Loss: 0.3365(0.4101) \n","Epoch: [4][0/1289] Elapsed 0m 0s (remain 16m 23s) Loss: 0.4230(0.4230) Grad: inf  LR: 0.00000073  \n","Epoch: [4][20/1289] Elapsed 0m 9s (remain 9m 39s) Loss: 0.2925(0.2850) Grad: 472680.2500  LR: 0.00000071  \n","Epoch: [4][40/1289] Elapsed 0m 18s (remain 9m 9s) Loss: 0.1523(0.2788) Grad: 224410.2500  LR: 0.00000069  \n","Epoch: [4][60/1289] Elapsed 0m 26s (remain 8m 56s) Loss: 0.2947(0.2732) Grad: 180090.2656  LR: 0.00000067  \n","Epoch: [4][80/1289] Elapsed 0m 35s (remain 8m 43s) Loss: 0.1691(0.2663) Grad: 186970.6094  LR: 0.00000065  \n","Epoch: [4][100/1289] Elapsed 0m 43s (remain 8m 34s) Loss: 0.1668(0.2672) Grad: 242058.1250  LR: 0.00000063  \n","Epoch: [4][120/1289] Elapsed 0m 52s (remain 8m 25s) Loss: 0.0862(0.2648) Grad: 138325.8906  LR: 0.00000061  \n","Epoch: [4][140/1289] Elapsed 1m 1s (remain 8m 18s) Loss: 0.4260(0.2695) Grad: 159167.4375  LR: 0.00000059  \n","Epoch: [4][160/1289] Elapsed 1m 10s (remain 8m 11s) Loss: 0.2158(0.2692) Grad: 163846.7031  LR: 0.00000057  \n","Epoch: [4][180/1289] Elapsed 1m 18s (remain 8m 2s) Loss: 0.4068(0.2690) Grad: 300611.5000  LR: 0.00000055  \n","Epoch: [4][200/1289] Elapsed 1m 27s (remain 7m 53s) Loss: 0.3259(0.2699) Grad: 207926.9531  LR: 0.00000053  \n","Epoch: [4][220/1289] Elapsed 1m 35s (remain 7m 43s) Loss: 0.3236(0.2690) Grad: 261113.4219  LR: 0.00000051  \n","Epoch: [4][240/1289] Elapsed 1m 44s (remain 7m 34s) Loss: 0.1860(0.2709) Grad: 273557.5938  LR: 0.00000049  \n","Epoch: [4][260/1289] Elapsed 1m 52s (remain 7m 25s) Loss: 0.1985(0.2683) Grad: 93193.3516  LR: 0.00000047  \n","Epoch: [4][280/1289] Elapsed 2m 1s (remain 7m 16s) Loss: 0.2744(0.2685) Grad: 159868.1875  LR: 0.00000046  \n","Epoch: [4][300/1289] Elapsed 2m 9s (remain 7m 5s) Loss: 0.1225(0.2661) Grad: 263328.9062  LR: 0.00000044  \n","Epoch: [4][320/1289] Elapsed 2m 18s (remain 6m 57s) Loss: 0.2748(0.2666) Grad: 163251.6250  LR: 0.00000042  \n","Epoch: [4][340/1289] Elapsed 2m 27s (remain 6m 48s) Loss: 0.1563(0.2689) Grad: 139430.7969  LR: 0.00000041  \n","Epoch: [4][360/1289] Elapsed 2m 35s (remain 6m 39s) Loss: 0.1227(0.2684) Grad: 342748.6562  LR: 0.00000039  \n","Epoch: [4][380/1289] Elapsed 2m 43s (remain 6m 29s) Loss: 0.2802(0.2697) Grad: 398573.7188  LR: 0.00000037  \n","Epoch: [4][400/1289] Elapsed 2m 52s (remain 6m 21s) Loss: 0.2849(0.2688) Grad: 204689.3594  LR: 0.00000036  \n","Epoch: [4][420/1289] Elapsed 3m 0s (remain 6m 12s) Loss: 0.1976(0.2671) Grad: 376060.2812  LR: 0.00000034  \n","Epoch: [4][440/1289] Elapsed 3m 9s (remain 6m 4s) Loss: 0.3694(0.2653) Grad: 96389.4453  LR: 0.00000033  \n","Epoch: [4][460/1289] Elapsed 3m 18s (remain 5m 55s) Loss: 0.2339(0.2640) Grad: 191644.7031  LR: 0.00000031  \n","Epoch: [4][480/1289] Elapsed 3m 26s (remain 5m 46s) Loss: 0.2210(0.2632) Grad: 183488.4062  LR: 0.00000030  \n","Epoch: [4][500/1289] Elapsed 3m 35s (remain 5m 38s) Loss: 0.1789(0.2625) Grad: 315888.9688  LR: 0.00000028  \n","Epoch: [4][520/1289] Elapsed 3m 43s (remain 5m 29s) Loss: 0.2459(0.2626) Grad: 223203.4062  LR: 0.00000027  \n","Epoch: [4][540/1289] Elapsed 3m 52s (remain 5m 21s) Loss: 0.2605(0.2627) Grad: 293126.0625  LR: 0.00000026  \n","Epoch: [4][560/1289] Elapsed 4m 1s (remain 5m 12s) Loss: 0.2179(0.2631) Grad: 235993.9531  LR: 0.00000024  \n","Epoch: [4][580/1289] Elapsed 4m 9s (remain 5m 4s) Loss: 0.4054(0.2631) Grad: 200099.7188  LR: 0.00000023  \n","Epoch: [4][600/1289] Elapsed 4m 18s (remain 4m 55s) Loss: 0.2609(0.2633) Grad: 367106.7812  LR: 0.00000022  \n","Epoch: [4][620/1289] Elapsed 4m 26s (remain 4m 46s) Loss: 0.3609(0.2644) Grad: 179196.3750  LR: 0.00000020  \n","Epoch: [4][640/1289] Elapsed 4m 35s (remain 4m 38s) Loss: 0.2676(0.2641) Grad: 468582.8750  LR: 0.00000019  \n","Epoch: [4][660/1289] Elapsed 4m 43s (remain 4m 29s) Loss: 0.1684(0.2644) Grad: 301090.9062  LR: 0.00000018  \n","Epoch: [4][680/1289] Elapsed 4m 52s (remain 4m 20s) Loss: 0.1161(0.2635) Grad: 111216.0625  LR: 0.00000017  \n","Epoch: [4][700/1289] Elapsed 5m 0s (remain 4m 12s) Loss: 0.2790(0.2637) Grad: 225819.3594  LR: 0.00000016  \n","Epoch: [4][720/1289] Elapsed 5m 9s (remain 4m 3s) Loss: 0.1953(0.2636) Grad: 184393.6406  LR: 0.00000015  \n","Epoch: [4][740/1289] Elapsed 5m 17s (remain 3m 55s) Loss: 0.3145(0.2644) Grad: 201375.5312  LR: 0.00000014  \n","Epoch: [4][760/1289] Elapsed 5m 26s (remain 3m 46s) Loss: 0.3821(0.2653) Grad: 251810.1094  LR: 0.00000013  \n","Epoch: [4][780/1289] Elapsed 5m 35s (remain 3m 38s) Loss: 0.3963(0.2652) Grad: 183583.5781  LR: 0.00000012  \n","Epoch: [4][800/1289] Elapsed 5m 43s (remain 3m 29s) Loss: 0.3163(0.2664) Grad: 167529.3125  LR: 0.00000011  \n","Epoch: [4][820/1289] Elapsed 5m 52s (remain 3m 20s) Loss: 0.2313(0.2663) Grad: 440784.0312  LR: 0.00000010  \n","Epoch: [4][840/1289] Elapsed 6m 0s (remain 3m 12s) Loss: 0.2019(0.2664) Grad: 333550.0312  LR: 0.00000009  \n","Epoch: [4][860/1289] Elapsed 6m 9s (remain 3m 3s) Loss: 0.2843(0.2659) Grad: 134898.8594  LR: 0.00000008  \n","Epoch: [4][880/1289] Elapsed 6m 17s (remain 2m 55s) Loss: 0.3095(0.2652) Grad: 212136.2500  LR: 0.00000008  \n","Epoch: [4][900/1289] Elapsed 6m 26s (remain 2m 46s) Loss: 0.2355(0.2648) Grad: 197185.4688  LR: 0.00000007  \n","Epoch: [4][920/1289] Elapsed 6m 34s (remain 2m 37s) Loss: 0.1791(0.2644) Grad: 145694.1250  LR: 0.00000006  \n","Epoch: [4][940/1289] Elapsed 6m 43s (remain 2m 29s) Loss: 0.2849(0.2647) Grad: 147976.2969  LR: 0.00000006  \n","Epoch: [4][960/1289] Elapsed 6m 52s (remain 2m 20s) Loss: 0.2255(0.2642) Grad: 101053.8750  LR: 0.00000005  \n","Epoch: [4][980/1289] Elapsed 7m 0s (remain 2m 12s) Loss: 0.3586(0.2635) Grad: 557693.6250  LR: 0.00000004  \n","Epoch: [4][1000/1289] Elapsed 7m 9s (remain 2m 3s) Loss: 0.2663(0.2634) Grad: 247391.2500  LR: 0.00000004  \n","Epoch: [4][1020/1289] Elapsed 7m 17s (remain 1m 54s) Loss: 0.2390(0.2639) Grad: 201489.4688  LR: 0.00000003  \n","Epoch: [4][1040/1289] Elapsed 7m 26s (remain 1m 46s) Loss: 0.3895(0.2636) Grad: 252520.4062  LR: 0.00000003  \n","Epoch: [4][1060/1289] Elapsed 7m 34s (remain 1m 37s) Loss: 0.1976(0.2637) Grad: 109599.0781  LR: 0.00000002  \n","Epoch: [4][1080/1289] Elapsed 7m 43s (remain 1m 29s) Loss: 0.2445(0.2638) Grad: 225794.0312  LR: 0.00000002  \n","Epoch: [4][1100/1289] Elapsed 7m 52s (remain 1m 20s) Loss: 0.2113(0.2637) Grad: 152048.8281  LR: 0.00000002  \n","Epoch: [4][1120/1289] Elapsed 8m 0s (remain 1m 12s) Loss: 0.2631(0.2635) Grad: 322599.8438  LR: 0.00000001  \n","Epoch: [4][1140/1289] Elapsed 8m 8s (remain 1m 3s) Loss: 0.3259(0.2633) Grad: 179322.8125  LR: 0.00000001  \n","Epoch: [4][1160/1289] Elapsed 8m 17s (remain 0m 54s) Loss: 0.3142(0.2639) Grad: 239194.0938  LR: 0.00000001  \n","Epoch: [4][1180/1289] Elapsed 8m 26s (remain 0m 46s) Loss: 0.1284(0.2629) Grad: 386425.3750  LR: 0.00000001  \n","Epoch: [4][1200/1289] Elapsed 8m 34s (remain 0m 37s) Loss: 0.2172(0.2628) Grad: 173147.0000  LR: 0.00000000  \n","Epoch: [4][1220/1289] Elapsed 8m 43s (remain 0m 29s) Loss: 0.3271(0.2630) Grad: 405435.5625  LR: 0.00000000  \n","Epoch: [4][1240/1289] Elapsed 8m 52s (remain 0m 20s) Loss: 0.0670(0.2627) Grad: 244495.5938  LR: 0.00000000  \n","Epoch: [4][1260/1289] Elapsed 9m 1s (remain 0m 12s) Loss: 0.3141(0.2626) Grad: 219098.3125  LR: 0.00000000  \n","Epoch: [4][1280/1289] Elapsed 9m 9s (remain 0m 3s) Loss: 0.3888(0.2631) Grad: 282795.1562  LR: 0.00000000  \n","Epoch: [4][1288/1289] Elapsed 9m 12s (remain 0m 0s) Loss: 0.2754(0.2629) Grad: 132094.9531  LR: 0.00000000  \n","EVAL: [0/252] Elapsed 0m 0s (remain 4m 6s) Loss: 0.4515(0.4515) \n","EVAL: [20/252] Elapsed 0m 13s (remain 2m 28s) Loss: 0.5332(0.4293) \n","EVAL: [40/252] Elapsed 0m 25s (remain 2m 11s) Loss: 0.3193(0.4282) \n","EVAL: [60/252] Elapsed 0m 37s (remain 1m 58s) Loss: 0.3958(0.4244) \n","EVAL: [80/252] Elapsed 0m 50s (remain 1m 45s) Loss: 0.4218(0.4175) \n","EVAL: [100/252] Elapsed 1m 2s (remain 1m 33s) Loss: 0.2915(0.4153) \n","EVAL: [120/252] Elapsed 1m 14s (remain 1m 20s) Loss: 0.3660(0.4089) \n","EVAL: [140/252] Elapsed 1m 26s (remain 1m 8s) Loss: 0.4092(0.4107) \n","EVAL: [160/252] Elapsed 1m 39s (remain 0m 56s) Loss: 0.4606(0.4129) \n","EVAL: [180/252] Elapsed 1m 50s (remain 0m 43s) Loss: 0.3976(0.4116) \n","EVAL: [200/252] Elapsed 2m 2s (remain 0m 31s) Loss: 0.3930(0.4120) \n","EVAL: [220/252] Elapsed 2m 15s (remain 0m 19s) Loss: 0.5048(0.4134) \n","EVAL: [240/252] Elapsed 2m 27s (remain 0m 6s) Loss: 0.4316(0.4116) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2629  avg_val_loss: 0.4126  time: 707s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2629  avg_val_loss: 0.4126  time: 707s\n","Epoch 4 - Score: 0.5328  Scores: [0.4658163611150141, 0.5997514901145253]\n","INFO:__main__:Epoch 4 - Score: 0.5328  Scores: [0.4658163611150141, 0.5997514901145253]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [251/252] Elapsed 2m 33s (remain 0m 0s) Loss: 0.3849(0.4126) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.5323  Scores: [0.45984544460468624, 0.6047384115187127]\n","INFO:__main__:Score: 0.5323  Scores: [0.45984544460468624, 0.6047384115187127]\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["========== prompt_id: ['ebad26'] validation ==========\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1292] Elapsed 0m 0s (remain 16m 17s) Loss: 2.1244(2.1244) Grad: inf  LR: 0.00000500  \n","Epoch: [1][20/1292] Elapsed 0m 7s (remain 7m 45s) Loss: 0.7573(1.0166) Grad: 122319.5938  LR: 0.00000500  \n","Epoch: [1][40/1292] Elapsed 0m 14s (remain 7m 32s) Loss: 0.5295(0.9044) Grad: 815699.7500  LR: 0.00000500  \n","Epoch: [1][60/1292] Elapsed 0m 21s (remain 7m 21s) Loss: 0.8274(0.8522) Grad: 3309849.7500  LR: 0.00000500  \n","Epoch: [1][80/1292] Elapsed 0m 28s (remain 7m 12s) Loss: 0.6208(0.8300) Grad: 119938.0625  LR: 0.00000500  \n","Epoch: [1][100/1292] Elapsed 0m 35s (remain 7m 1s) Loss: 0.6372(0.7817) Grad: 429386.1562  LR: 0.00000500  \n","Epoch: [1][120/1292] Elapsed 0m 42s (remain 6m 54s) Loss: 0.9738(0.7517) Grad: 398015.9375  LR: 0.00000499  \n","Epoch: [1][140/1292] Elapsed 0m 49s (remain 6m 44s) Loss: 0.5852(0.7302) Grad: 217283.2500  LR: 0.00000499  \n","Epoch: [1][160/1292] Elapsed 0m 56s (remain 6m 38s) Loss: 0.4490(0.7132) Grad: 192011.3750  LR: 0.00000499  \n","Epoch: [1][180/1292] Elapsed 1m 3s (remain 6m 31s) Loss: 0.5716(0.6908) Grad: 206059.5625  LR: 0.00000498  \n","Epoch: [1][200/1292] Elapsed 1m 11s (remain 6m 26s) Loss: 0.6850(0.6736) Grad: 218829.1406  LR: 0.00000498  \n","Epoch: [1][220/1292] Elapsed 1m 18s (remain 6m 20s) Loss: 0.3722(0.6574) Grad: 230672.0469  LR: 0.00000498  \n","Epoch: [1][240/1292] Elapsed 1m 25s (remain 6m 11s) Loss: 0.7481(0.6501) Grad: 210107.7188  LR: 0.00000497  \n","Epoch: [1][260/1292] Elapsed 1m 32s (remain 6m 5s) Loss: 0.5800(0.6439) Grad: 257256.7031  LR: 0.00000497  \n","Epoch: [1][280/1292] Elapsed 1m 39s (remain 5m 57s) Loss: 0.4679(0.6354) Grad: 268383.8750  LR: 0.00000496  \n","Epoch: [1][300/1292] Elapsed 1m 46s (remain 5m 49s) Loss: 0.4069(0.6270) Grad: 234530.9375  LR: 0.00000496  \n","Epoch: [1][320/1292] Elapsed 1m 53s (remain 5m 42s) Loss: 0.5742(0.6186) Grad: 231798.3281  LR: 0.00000495  \n","Epoch: [1][340/1292] Elapsed 2m 0s (remain 5m 35s) Loss: 0.5714(0.6112) Grad: 272152.5625  LR: 0.00000495  \n","Epoch: [1][360/1292] Elapsed 2m 7s (remain 5m 27s) Loss: 0.5093(0.6057) Grad: 192805.0312  LR: 0.00000494  \n","Epoch: [1][380/1292] Elapsed 2m 14s (remain 5m 20s) Loss: 0.7382(0.5997) Grad: 409324.9375  LR: 0.00000493  \n","Epoch: [1][400/1292] Elapsed 2m 21s (remain 5m 14s) Loss: 0.5710(0.5935) Grad: 21845.8320  LR: 0.00000493  \n","Epoch: [1][420/1292] Elapsed 2m 28s (remain 5m 7s) Loss: 0.6816(0.5951) Grad: 339730.6250  LR: 0.00000492  \n","Epoch: [1][440/1292] Elapsed 2m 35s (remain 4m 59s) Loss: 0.4822(0.5871) Grad: 155028.1719  LR: 0.00000491  \n","Epoch: [1][460/1292] Elapsed 2m 42s (remain 4m 52s) Loss: 0.6020(0.5830) Grad: 111104.8672  LR: 0.00000490  \n","Epoch: [1][480/1292] Elapsed 2m 48s (remain 4m 44s) Loss: 0.4807(0.5761) Grad: 139707.7031  LR: 0.00000489  \n","Epoch: [1][500/1292] Elapsed 2m 55s (remain 4m 37s) Loss: 0.6268(0.5686) Grad: 181500.1875  LR: 0.00000488  \n","Epoch: [1][520/1292] Elapsed 3m 2s (remain 4m 29s) Loss: 0.3762(0.5633) Grad: 248719.2031  LR: 0.00000488  \n","Epoch: [1][540/1292] Elapsed 3m 9s (remain 4m 22s) Loss: 0.4953(0.5598) Grad: 56001.8867  LR: 0.00000487  \n","Epoch: [1][560/1292] Elapsed 3m 15s (remain 4m 15s) Loss: 0.2900(0.5543) Grad: 52677.9492  LR: 0.00000486  \n","Epoch: [1][580/1292] Elapsed 3m 23s (remain 4m 8s) Loss: 0.2445(0.5491) Grad: 96843.6406  LR: 0.00000485  \n","Epoch: [1][600/1292] Elapsed 3m 29s (remain 4m 1s) Loss: 0.2614(0.5445) Grad: 150832.4062  LR: 0.00000484  \n","Epoch: [1][620/1292] Elapsed 3m 37s (remain 3m 54s) Loss: 0.6139(0.5408) Grad: 132026.5312  LR: 0.00000482  \n","Epoch: [1][640/1292] Elapsed 3m 44s (remain 3m 47s) Loss: 0.2534(0.5351) Grad: 59383.4766  LR: 0.00000481  \n","Epoch: [1][660/1292] Elapsed 3m 51s (remain 3m 40s) Loss: 0.3774(0.5301) Grad: 109087.0156  LR: 0.00000480  \n","Epoch: [1][680/1292] Elapsed 3m 58s (remain 3m 33s) Loss: 0.5690(0.5275) Grad: 106528.3438  LR: 0.00000479  \n","Epoch: [1][700/1292] Elapsed 4m 5s (remain 3m 26s) Loss: 0.4371(0.5235) Grad: 122706.6094  LR: 0.00000478  \n","Epoch: [1][720/1292] Elapsed 4m 12s (remain 3m 19s) Loss: 0.3638(0.5213) Grad: 58101.9492  LR: 0.00000476  \n","Epoch: [1][740/1292] Elapsed 4m 19s (remain 3m 12s) Loss: 0.3466(0.5188) Grad: 180352.0469  LR: 0.00000475  \n","Epoch: [1][760/1292] Elapsed 4m 26s (remain 3m 5s) Loss: 0.4733(0.5161) Grad: 57155.0508  LR: 0.00000474  \n","Epoch: [1][780/1292] Elapsed 4m 33s (remain 2m 59s) Loss: 0.2628(0.5131) Grad: 122411.5781  LR: 0.00000472  \n","Epoch: [1][800/1292] Elapsed 4m 40s (remain 2m 52s) Loss: 0.5399(0.5111) Grad: 76000.7188  LR: 0.00000471  \n","Epoch: [1][820/1292] Elapsed 4m 47s (remain 2m 45s) Loss: 0.5966(0.5078) Grad: 119931.7422  LR: 0.00000470  \n","Epoch: [1][840/1292] Elapsed 4m 54s (remain 2m 37s) Loss: 0.7673(0.5062) Grad: 137207.6562  LR: 0.00000468  \n","Epoch: [1][860/1292] Elapsed 5m 1s (remain 2m 30s) Loss: 0.4258(0.5038) Grad: 113410.9844  LR: 0.00000467  \n","Epoch: [1][880/1292] Elapsed 5m 8s (remain 2m 23s) Loss: 0.4667(0.5017) Grad: 35576.5273  LR: 0.00000465  \n","Epoch: [1][900/1292] Elapsed 5m 15s (remain 2m 16s) Loss: 0.2133(0.5013) Grad: 72732.8516  LR: 0.00000463  \n","Epoch: [1][920/1292] Elapsed 5m 22s (remain 2m 9s) Loss: 0.6079(0.4984) Grad: 63427.2539  LR: 0.00000462  \n","Epoch: [1][940/1292] Elapsed 5m 29s (remain 2m 2s) Loss: 0.4585(0.4974) Grad: 53509.5742  LR: 0.00000460  \n","Epoch: [1][960/1292] Elapsed 5m 36s (remain 1m 55s) Loss: 0.3353(0.4967) Grad: 54249.1758  LR: 0.00000459  \n","Epoch: [1][980/1292] Elapsed 5m 43s (remain 1m 48s) Loss: 0.2767(0.4945) Grad: 50101.8438  LR: 0.00000457  \n","Epoch: [1][1000/1292] Elapsed 5m 50s (remain 1m 41s) Loss: 0.2537(0.4936) Grad: 39994.5898  LR: 0.00000455  \n","Epoch: [1][1020/1292] Elapsed 5m 57s (remain 1m 34s) Loss: 0.5593(0.4913) Grad: 124995.5859  LR: 0.00000453  \n","Epoch: [1][1040/1292] Elapsed 6m 4s (remain 1m 27s) Loss: 0.3721(0.4898) Grad: 94312.7969  LR: 0.00000452  \n","Epoch: [1][1060/1292] Elapsed 6m 11s (remain 1m 20s) Loss: 0.3579(0.4876) Grad: 39664.8516  LR: 0.00000450  \n","Epoch: [1][1080/1292] Elapsed 6m 18s (remain 1m 13s) Loss: 0.1671(0.4862) Grad: 132122.6875  LR: 0.00000448  \n","Epoch: [1][1100/1292] Elapsed 6m 25s (remain 1m 6s) Loss: 0.5326(0.4846) Grad: 52817.8711  LR: 0.00000446  \n","Epoch: [1][1120/1292] Elapsed 6m 33s (remain 0m 59s) Loss: 0.4479(0.4828) Grad: 67096.0000  LR: 0.00000444  \n","Epoch: [1][1140/1292] Elapsed 6m 39s (remain 0m 52s) Loss: 0.5083(0.4812) Grad: 124102.8906  LR: 0.00000442  \n","Epoch: [1][1160/1292] Elapsed 6m 46s (remain 0m 45s) Loss: 0.3402(0.4806) Grad: 125774.8516  LR: 0.00000440  \n","Epoch: [1][1180/1292] Elapsed 6m 53s (remain 0m 38s) Loss: 0.4763(0.4799) Grad: 48877.1055  LR: 0.00000438  \n","Epoch: [1][1200/1292] Elapsed 7m 0s (remain 0m 31s) Loss: 0.2918(0.4780) Grad: 127345.0312  LR: 0.00000436  \n","Epoch: [1][1220/1292] Elapsed 7m 7s (remain 0m 24s) Loss: 0.3966(0.4768) Grad: 47773.0508  LR: 0.00000434  \n","Epoch: [1][1240/1292] Elapsed 7m 14s (remain 0m 17s) Loss: 0.2877(0.4759) Grad: 43658.2812  LR: 0.00000432  \n","Epoch: [1][1260/1292] Elapsed 7m 21s (remain 0m 10s) Loss: 0.6060(0.4748) Grad: 60871.9336  LR: 0.00000430  \n","Epoch: [1][1280/1292] Elapsed 7m 28s (remain 0m 3s) Loss: 0.2988(0.4743) Grad: 48891.8203  LR: 0.00000428  \n","Epoch: [1][1291/1292] Elapsed 7m 32s (remain 0m 0s) Loss: 0.3680(0.4737) Grad: 52681.2656  LR: 0.00000427  \n","EVAL: [0/250] Elapsed 0m 1s (remain 4m 31s) Loss: 0.4749(0.4749) \n","EVAL: [20/250] Elapsed 0m 15s (remain 2m 50s) Loss: 0.3506(0.3545) \n","EVAL: [40/250] Elapsed 0m 30s (remain 2m 34s) Loss: 0.2985(0.3715) \n","EVAL: [60/250] Elapsed 0m 44s (remain 2m 18s) Loss: 0.2100(0.3901) \n","EVAL: [80/250] Elapsed 0m 59s (remain 2m 3s) Loss: 0.3624(0.3927) \n","EVAL: [100/250] Elapsed 1m 13s (remain 1m 49s) Loss: 0.2281(0.3898) \n","EVAL: [120/250] Elapsed 1m 28s (remain 1m 34s) Loss: 0.3883(0.3856) \n","EVAL: [140/250] Elapsed 1m 43s (remain 1m 19s) Loss: 0.3588(0.3933) \n","EVAL: [160/250] Elapsed 1m 57s (remain 1m 5s) Loss: 0.2632(0.3896) \n","EVAL: [180/250] Elapsed 2m 12s (remain 0m 50s) Loss: 0.3389(0.3842) \n","EVAL: [200/250] Elapsed 2m 26s (remain 0m 35s) Loss: 0.3572(0.3782) \n","EVAL: [220/250] Elapsed 2m 41s (remain 0m 21s) Loss: 0.4159(0.3811) \n","EVAL: [240/250] Elapsed 2m 55s (remain 0m 6s) Loss: 0.3115(0.3806) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.4737  avg_val_loss: 0.3807  time: 635s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4737  avg_val_loss: 0.3807  time: 635s\n","Epoch 1 - Score: 0.5020  Scores: [0.49288389891292894, 0.5111690069662758]\n","INFO:__main__:Epoch 1 - Score: 0.5020  Scores: [0.49288389891292894, 0.5111690069662758]\n","Epoch 1 - Save Best Score: 0.5020 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5020 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [249/250] Elapsed 3m 2s (remain 0m 0s) Loss: 0.5259(0.3807) \n","Epoch: [2][0/1292] Elapsed 0m 0s (remain 15m 0s) Loss: 0.3451(0.3451) Grad: inf  LR: 0.00000427  \n","Epoch: [2][20/1292] Elapsed 0m 8s (remain 8m 5s) Loss: 0.3735(0.3380) Grad: 207337.8125  LR: 0.00000425  \n","Epoch: [2][40/1292] Elapsed 0m 14s (remain 7m 29s) Loss: 0.7063(0.3466) Grad: 371340.0312  LR: 0.00000422  \n","Epoch: [2][60/1292] Elapsed 0m 21s (remain 7m 19s) Loss: 0.3748(0.3538) Grad: 126224.0781  LR: 0.00000420  \n","Epoch: [2][80/1292] Elapsed 0m 28s (remain 7m 9s) Loss: 0.2387(0.3430) Grad: 590144.0625  LR: 0.00000418  \n","Epoch: [2][100/1292] Elapsed 0m 35s (remain 7m 0s) Loss: 0.5908(0.3382) Grad: 513365.3438  LR: 0.00000416  \n","Epoch: [2][120/1292] Elapsed 0m 42s (remain 6m 53s) Loss: 0.5250(0.3359) Grad: 405289.5938  LR: 0.00000413  \n","Epoch: [2][140/1292] Elapsed 0m 50s (remain 6m 48s) Loss: 0.3880(0.3341) Grad: 181201.1406  LR: 0.00000411  \n","Epoch: [2][160/1292] Elapsed 0m 57s (remain 6m 41s) Loss: 0.3833(0.3311) Grad: 211945.2812  LR: 0.00000409  \n","Epoch: [2][180/1292] Elapsed 1m 4s (remain 6m 33s) Loss: 0.2988(0.3318) Grad: 337764.5625  LR: 0.00000406  \n","Epoch: [2][200/1292] Elapsed 1m 10s (remain 6m 24s) Loss: 0.4331(0.3284) Grad: 159390.5312  LR: 0.00000404  \n","Epoch: [2][220/1292] Elapsed 1m 17s (remain 6m 16s) Loss: 0.3290(0.3285) Grad: 250812.7031  LR: 0.00000402  \n","Epoch: [2][240/1292] Elapsed 1m 24s (remain 6m 8s) Loss: 0.4071(0.3301) Grad: 293900.5000  LR: 0.00000399  \n","Epoch: [2][260/1292] Elapsed 1m 31s (remain 6m 1s) Loss: 0.3102(0.3289) Grad: 387463.4062  LR: 0.00000397  \n","Epoch: [2][280/1292] Elapsed 1m 38s (remain 5m 54s) Loss: 0.2853(0.3309) Grad: 305152.3125  LR: 0.00000394  \n","Epoch: [2][300/1292] Elapsed 1m 45s (remain 5m 47s) Loss: 0.5588(0.3339) Grad: 658604.1875  LR: 0.00000392  \n","Epoch: [2][320/1292] Elapsed 1m 52s (remain 5m 41s) Loss: 0.2080(0.3349) Grad: 325929.1875  LR: 0.00000389  \n","Epoch: [2][340/1292] Elapsed 1m 59s (remain 5m 33s) Loss: 0.2497(0.3374) Grad: 161617.4375  LR: 0.00000387  \n","Epoch: [2][360/1292] Elapsed 2m 6s (remain 5m 26s) Loss: 0.3682(0.3387) Grad: 226308.0938  LR: 0.00000384  \n","Epoch: [2][380/1292] Elapsed 2m 13s (remain 5m 19s) Loss: 0.4792(0.3391) Grad: 215648.3125  LR: 0.00000382  \n","Epoch: [2][400/1292] Elapsed 2m 20s (remain 5m 11s) Loss: 0.3359(0.3380) Grad: 248621.3281  LR: 0.00000379  \n","Epoch: [2][420/1292] Elapsed 2m 27s (remain 5m 4s) Loss: 0.1934(0.3391) Grad: 250671.3125  LR: 0.00000376  \n","Epoch: [2][440/1292] Elapsed 2m 34s (remain 4m 57s) Loss: 0.3507(0.3386) Grad: 282853.3750  LR: 0.00000374  \n","Epoch: [2][460/1292] Elapsed 2m 41s (remain 4m 50s) Loss: 0.4567(0.3395) Grad: 186462.1094  LR: 0.00000371  \n","Epoch: [2][480/1292] Elapsed 2m 48s (remain 4m 43s) Loss: 0.2417(0.3393) Grad: 236881.2188  LR: 0.00000368  \n","Epoch: [2][500/1292] Elapsed 2m 54s (remain 4m 36s) Loss: 0.1549(0.3394) Grad: 140930.2500  LR: 0.00000366  \n","Epoch: [2][520/1292] Elapsed 3m 1s (remain 4m 29s) Loss: 0.1568(0.3413) Grad: 481198.1562  LR: 0.00000363  \n","Epoch: [2][540/1292] Elapsed 3m 8s (remain 4m 22s) Loss: 0.3359(0.3385) Grad: 623557.5625  LR: 0.00000360  \n","Epoch: [2][560/1292] Elapsed 3m 15s (remain 4m 14s) Loss: 0.2466(0.3384) Grad: 382589.9062  LR: 0.00000358  \n","Epoch: [2][580/1292] Elapsed 3m 22s (remain 4m 7s) Loss: 0.4648(0.3387) Grad: 691031.2500  LR: 0.00000355  \n","Epoch: [2][600/1292] Elapsed 3m 29s (remain 4m 0s) Loss: 0.4042(0.3391) Grad: 200591.1406  LR: 0.00000352  \n","Epoch: [2][620/1292] Elapsed 3m 36s (remain 3m 53s) Loss: 0.4915(0.3393) Grad: 177092.7656  LR: 0.00000349  \n","Epoch: [2][640/1292] Elapsed 3m 43s (remain 3m 46s) Loss: 0.6342(0.3395) Grad: 313405.9375  LR: 0.00000346  \n","Epoch: [2][660/1292] Elapsed 3m 50s (remain 3m 39s) Loss: 0.4690(0.3387) Grad: 310801.4375  LR: 0.00000344  \n","Epoch: [2][680/1292] Elapsed 3m 56s (remain 3m 32s) Loss: 0.2701(0.3389) Grad: 253300.6406  LR: 0.00000341  \n","Epoch: [2][700/1292] Elapsed 4m 3s (remain 3m 25s) Loss: 0.2129(0.3380) Grad: 269223.0312  LR: 0.00000338  \n","Epoch: [2][720/1292] Elapsed 4m 10s (remain 3m 18s) Loss: 0.3952(0.3380) Grad: 154046.2188  LR: 0.00000335  \n","Epoch: [2][740/1292] Elapsed 4m 17s (remain 3m 11s) Loss: 0.5113(0.3378) Grad: 346692.8750  LR: 0.00000332  \n","Epoch: [2][760/1292] Elapsed 4m 24s (remain 3m 4s) Loss: 0.3169(0.3373) Grad: 437852.6875  LR: 0.00000329  \n","Epoch: [2][780/1292] Elapsed 4m 31s (remain 2m 57s) Loss: 0.4071(0.3375) Grad: 507861.4688  LR: 0.00000326  \n","Epoch: [2][800/1292] Elapsed 4m 38s (remain 2m 50s) Loss: 0.2858(0.3380) Grad: 363967.4375  LR: 0.00000324  \n","Epoch: [2][820/1292] Elapsed 4m 45s (remain 2m 43s) Loss: 0.3514(0.3386) Grad: 503145.0625  LR: 0.00000321  \n","Epoch: [2][840/1292] Elapsed 4m 52s (remain 2m 36s) Loss: 0.4700(0.3385) Grad: 348354.1875  LR: 0.00000318  \n","Epoch: [2][860/1292] Elapsed 4m 59s (remain 2m 29s) Loss: 0.4842(0.3383) Grad: 280876.5625  LR: 0.00000315  \n","Epoch: [2][880/1292] Elapsed 5m 7s (remain 2m 23s) Loss: 0.2177(0.3380) Grad: 234335.2344  LR: 0.00000312  \n","Epoch: [2][900/1292] Elapsed 5m 13s (remain 2m 16s) Loss: 0.3526(0.3383) Grad: 170537.6719  LR: 0.00000309  \n","Epoch: [2][920/1292] Elapsed 5m 20s (remain 2m 9s) Loss: 0.2743(0.3386) Grad: 596798.3125  LR: 0.00000306  \n","Epoch: [2][940/1292] Elapsed 5m 27s (remain 2m 2s) Loss: 0.2688(0.3385) Grad: 144147.7500  LR: 0.00000303  \n","Epoch: [2][960/1292] Elapsed 5m 34s (remain 1m 55s) Loss: 0.3506(0.3386) Grad: 389475.5312  LR: 0.00000300  \n","Epoch: [2][980/1292] Elapsed 5m 41s (remain 1m 48s) Loss: 0.1727(0.3378) Grad: 271209.5938  LR: 0.00000297  \n","Epoch: [2][1000/1292] Elapsed 5m 48s (remain 1m 41s) Loss: 0.7679(0.3370) Grad: 235658.7031  LR: 0.00000294  \n","Epoch: [2][1020/1292] Elapsed 5m 55s (remain 1m 34s) Loss: 0.3589(0.3371) Grad: 404128.1250  LR: 0.00000291  \n","Epoch: [2][1040/1292] Elapsed 6m 2s (remain 1m 27s) Loss: 0.4683(0.3374) Grad: 218773.7500  LR: 0.00000288  \n","Epoch: [2][1060/1292] Elapsed 6m 9s (remain 1m 20s) Loss: 0.4212(0.3370) Grad: 98359.5234  LR: 0.00000285  \n","Epoch: [2][1080/1292] Elapsed 6m 16s (remain 1m 13s) Loss: 0.2144(0.3362) Grad: 312357.5312  LR: 0.00000282  \n","Epoch: [2][1100/1292] Elapsed 6m 23s (remain 1m 6s) Loss: 0.3566(0.3360) Grad: 532356.6875  LR: 0.00000279  \n","Epoch: [2][1120/1292] Elapsed 6m 30s (remain 0m 59s) Loss: 0.1416(0.3358) Grad: 213198.1719  LR: 0.00000276  \n","Epoch: [2][1140/1292] Elapsed 6m 37s (remain 0m 52s) Loss: 0.4612(0.3353) Grad: 373243.2500  LR: 0.00000273  \n","Epoch: [2][1160/1292] Elapsed 6m 44s (remain 0m 45s) Loss: 0.1924(0.3354) Grad: 175925.2969  LR: 0.00000270  \n","Epoch: [2][1180/1292] Elapsed 6m 52s (remain 0m 38s) Loss: 0.4073(0.3362) Grad: 688911.8125  LR: 0.00000267  \n","Epoch: [2][1200/1292] Elapsed 6m 59s (remain 0m 31s) Loss: 0.3144(0.3360) Grad: 120943.4453  LR: 0.00000264  \n","Epoch: [2][1220/1292] Elapsed 7m 5s (remain 0m 24s) Loss: 0.5795(0.3366) Grad: 281694.0625  LR: 0.00000261  \n","Epoch: [2][1240/1292] Elapsed 7m 12s (remain 0m 17s) Loss: 0.4516(0.3367) Grad: 200947.4844  LR: 0.00000258  \n","Epoch: [2][1260/1292] Elapsed 7m 19s (remain 0m 10s) Loss: 0.2302(0.3368) Grad: 322742.2500  LR: 0.00000255  \n","Epoch: [2][1280/1292] Elapsed 7m 26s (remain 0m 3s) Loss: 0.2743(0.3369) Grad: 119219.1094  LR: 0.00000252  \n","Epoch: [2][1291/1292] Elapsed 7m 30s (remain 0m 0s) Loss: 0.2420(0.3363) Grad: 163696.6562  LR: 0.00000250  \n","EVAL: [0/250] Elapsed 0m 1s (remain 4m 28s) Loss: 0.4726(0.4726) \n","EVAL: [20/250] Elapsed 0m 15s (remain 2m 50s) Loss: 0.3324(0.3286) \n","EVAL: [40/250] Elapsed 0m 30s (remain 2m 33s) Loss: 0.2812(0.3429) \n","EVAL: [60/250] Elapsed 0m 44s (remain 2m 18s) Loss: 0.2168(0.3606) \n","EVAL: [80/250] Elapsed 0m 59s (remain 2m 3s) Loss: 0.3616(0.3632) \n","EVAL: [100/250] Elapsed 1m 13s (remain 1m 48s) Loss: 0.2324(0.3606) \n","EVAL: [120/250] Elapsed 1m 28s (remain 1m 34s) Loss: 0.3871(0.3578) \n","EVAL: [140/250] Elapsed 1m 42s (remain 1m 19s) Loss: 0.3499(0.3630) \n","EVAL: [160/250] Elapsed 1m 57s (remain 1m 4s) Loss: 0.2628(0.3604) \n","EVAL: [180/250] Elapsed 2m 12s (remain 0m 50s) Loss: 0.3162(0.3561) \n","EVAL: [200/250] Elapsed 2m 26s (remain 0m 35s) Loss: 0.3348(0.3511) \n","EVAL: [220/250] Elapsed 2m 41s (remain 0m 21s) Loss: 0.4121(0.3538) \n","EVAL: [240/250] Elapsed 2m 55s (remain 0m 6s) Loss: 0.3604(0.3534) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3363  avg_val_loss: 0.3536  time: 633s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3363  avg_val_loss: 0.3536  time: 633s\n","Epoch 2 - Score: 0.4644  Scores: [0.43860453396902144, 0.4902857944600095]\n","INFO:__main__:Epoch 2 - Score: 0.4644  Scores: [0.43860453396902144, 0.4902857944600095]\n","Epoch 2 - Save Best Score: 0.4644 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4644 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [249/250] Elapsed 3m 1s (remain 0m 0s) Loss: 0.4206(0.3536) \n","Epoch: [3][0/1292] Elapsed 0m 0s (remain 14m 3s) Loss: 0.1283(0.1283) Grad: 719197.8125  LR: 0.00000250  \n","Epoch: [3][20/1292] Elapsed 0m 7s (remain 7m 31s) Loss: 0.3126(0.3006) Grad: 251820.3750  LR: 0.00000247  \n","Epoch: [3][40/1292] Elapsed 0m 14s (remain 7m 22s) Loss: 0.2738(0.2942) Grad: 457109.2812  LR: 0.00000244  \n","Epoch: [3][60/1292] Elapsed 0m 21s (remain 7m 11s) Loss: 0.4466(0.3012) Grad: 355875.0625  LR: 0.00000241  \n","Epoch: [3][80/1292] Elapsed 0m 28s (remain 7m 6s) Loss: 0.3796(0.3072) Grad: 425948.8125  LR: 0.00000238  \n","Epoch: [3][100/1292] Elapsed 0m 35s (remain 6m 57s) Loss: 0.2267(0.2939) Grad: 425327.6562  LR: 0.00000235  \n","Epoch: [3][120/1292] Elapsed 0m 42s (remain 6m 52s) Loss: 0.3050(0.2937) Grad: 249299.2344  LR: 0.00000232  \n","Epoch: [3][140/1292] Elapsed 0m 49s (remain 6m 44s) Loss: 0.2718(0.2953) Grad: 220472.8906  LR: 0.00000229  \n","Epoch: [3][160/1292] Elapsed 0m 56s (remain 6m 37s) Loss: 0.2739(0.2947) Grad: 378463.6562  LR: 0.00000226  \n","Epoch: [3][180/1292] Elapsed 1m 3s (remain 6m 30s) Loss: 0.2125(0.2985) Grad: 355356.3750  LR: 0.00000223  \n","Epoch: [3][200/1292] Elapsed 1m 10s (remain 6m 23s) Loss: 0.3141(0.2977) Grad: 336530.2812  LR: 0.00000220  \n","Epoch: [3][220/1292] Elapsed 1m 17s (remain 6m 14s) Loss: 0.4167(0.2967) Grad: 250790.6562  LR: 0.00000217  \n","Epoch: [3][240/1292] Elapsed 1m 24s (remain 6m 8s) Loss: 0.1761(0.3010) Grad: 329892.9375  LR: 0.00000214  \n","Epoch: [3][260/1292] Elapsed 1m 31s (remain 6m 2s) Loss: 0.3478(0.3006) Grad: 176528.8125  LR: 0.00000211  \n","Epoch: [3][280/1292] Elapsed 1m 38s (remain 5m 55s) Loss: 0.6013(0.3029) Grad: 647212.4375  LR: 0.00000208  \n","Epoch: [3][300/1292] Elapsed 1m 45s (remain 5m 47s) Loss: 0.4671(0.3025) Grad: 243348.7969  LR: 0.00000205  \n","Epoch: [3][320/1292] Elapsed 1m 52s (remain 5m 40s) Loss: 0.2705(0.3015) Grad: 252556.8125  LR: 0.00000202  \n","Epoch: [3][340/1292] Elapsed 1m 59s (remain 5m 32s) Loss: 0.2915(0.3007) Grad: 216242.9688  LR: 0.00000199  \n","Epoch: [3][360/1292] Elapsed 2m 6s (remain 5m 25s) Loss: 0.5082(0.3014) Grad: 406555.2500  LR: 0.00000196  \n","Epoch: [3][380/1292] Elapsed 2m 13s (remain 5m 19s) Loss: 0.3909(0.3039) Grad: 172453.9688  LR: 0.00000193  \n","Epoch: [3][400/1292] Elapsed 2m 20s (remain 5m 12s) Loss: 0.2821(0.3034) Grad: 81437.0547  LR: 0.00000190  \n","Epoch: [3][420/1292] Elapsed 2m 27s (remain 5m 5s) Loss: 0.1481(0.3034) Grad: 212766.1250  LR: 0.00000187  \n","Epoch: [3][440/1292] Elapsed 2m 34s (remain 4m 57s) Loss: 0.2741(0.3048) Grad: 290655.8438  LR: 0.00000184  \n","Epoch: [3][460/1292] Elapsed 2m 41s (remain 4m 50s) Loss: 0.2875(0.3056) Grad: 249030.0469  LR: 0.00000181  \n","Epoch: [3][480/1292] Elapsed 2m 47s (remain 4m 43s) Loss: 0.5135(0.3060) Grad: 150787.7656  LR: 0.00000178  \n","Epoch: [3][500/1292] Elapsed 2m 55s (remain 4m 36s) Loss: 0.1645(0.3063) Grad: 323152.1875  LR: 0.00000175  \n","Epoch: [3][520/1292] Elapsed 3m 1s (remain 4m 29s) Loss: 0.2816(0.3064) Grad: 466591.5000  LR: 0.00000172  \n","Epoch: [3][540/1292] Elapsed 3m 8s (remain 4m 21s) Loss: 0.3453(0.3044) Grad: 247044.6562  LR: 0.00000169  \n","Epoch: [3][560/1292] Elapsed 3m 15s (remain 4m 14s) Loss: 0.2378(0.3032) Grad: 224730.0625  LR: 0.00000166  \n","Epoch: [3][580/1292] Elapsed 3m 22s (remain 4m 7s) Loss: 0.4098(0.3041) Grad: 190924.2188  LR: 0.00000164  \n","Epoch: [3][600/1292] Elapsed 3m 28s (remain 4m 0s) Loss: 0.2081(0.3046) Grad: 297003.8125  LR: 0.00000161  \n","Epoch: [3][620/1292] Elapsed 3m 35s (remain 3m 53s) Loss: 0.2824(0.3046) Grad: 165509.0000  LR: 0.00000158  \n","Epoch: [3][640/1292] Elapsed 3m 42s (remain 3m 45s) Loss: 0.1953(0.3040) Grad: 404193.2500  LR: 0.00000155  \n","Epoch: [3][660/1292] Elapsed 3m 49s (remain 3m 38s) Loss: 0.2764(0.3033) Grad: 164750.1094  LR: 0.00000152  \n","Epoch: [3][680/1292] Elapsed 3m 56s (remain 3m 32s) Loss: 0.3640(0.3024) Grad: 260957.8125  LR: 0.00000150  \n","Epoch: [3][700/1292] Elapsed 4m 3s (remain 3m 25s) Loss: 0.2961(0.3033) Grad: 883703.5000  LR: 0.00000147  \n","Epoch: [3][720/1292] Elapsed 4m 10s (remain 3m 18s) Loss: 0.3998(0.3044) Grad: 255092.7969  LR: 0.00000144  \n","Epoch: [3][740/1292] Elapsed 4m 17s (remain 3m 11s) Loss: 0.4085(0.3044) Grad: 269041.2812  LR: 0.00000141  \n","Epoch: [3][760/1292] Elapsed 4m 25s (remain 3m 4s) Loss: 0.3836(0.3056) Grad: 446832.3750  LR: 0.00000139  \n","Epoch: [3][780/1292] Elapsed 4m 31s (remain 2m 57s) Loss: 0.3317(0.3054) Grad: 224585.7031  LR: 0.00000136  \n","Epoch: [3][800/1292] Elapsed 4m 38s (remain 2m 50s) Loss: 0.2903(0.3046) Grad: 291797.8125  LR: 0.00000133  \n","Epoch: [3][820/1292] Elapsed 4m 45s (remain 2m 43s) Loss: 0.4209(0.3050) Grad: 265949.8438  LR: 0.00000130  \n","Epoch: [3][840/1292] Elapsed 4m 52s (remain 2m 36s) Loss: 0.3153(0.3060) Grad: 462455.2812  LR: 0.00000128  \n","Epoch: [3][860/1292] Elapsed 4m 58s (remain 2m 29s) Loss: 0.2345(0.3059) Grad: 116900.8984  LR: 0.00000125  \n","Epoch: [3][880/1292] Elapsed 5m 5s (remain 2m 22s) Loss: 0.3910(0.3050) Grad: 271689.3438  LR: 0.00000123  \n","Epoch: [3][900/1292] Elapsed 5m 13s (remain 2m 15s) Loss: 0.5347(0.3052) Grad: 479766.3125  LR: 0.00000120  \n","Epoch: [3][920/1292] Elapsed 5m 20s (remain 2m 9s) Loss: 0.2435(0.3056) Grad: 447279.1875  LR: 0.00000117  \n","Epoch: [3][940/1292] Elapsed 5m 27s (remain 2m 1s) Loss: 0.2776(0.3047) Grad: 291260.1562  LR: 0.00000115  \n","Epoch: [3][960/1292] Elapsed 5m 33s (remain 1m 54s) Loss: 0.1652(0.3045) Grad: 329325.7812  LR: 0.00000112  \n","Epoch: [3][980/1292] Elapsed 5m 40s (remain 1m 48s) Loss: 0.3708(0.3054) Grad: 292798.0312  LR: 0.00000110  \n","Epoch: [3][1000/1292] Elapsed 5m 47s (remain 1m 41s) Loss: 0.2788(0.3058) Grad: 190457.7031  LR: 0.00000107  \n","Epoch: [3][1020/1292] Elapsed 5m 54s (remain 1m 34s) Loss: 0.1355(0.3053) Grad: 280144.3125  LR: 0.00000105  \n","Epoch: [3][1040/1292] Elapsed 6m 1s (remain 1m 27s) Loss: 0.2567(0.3049) Grad: 192874.9844  LR: 0.00000102  \n","Epoch: [3][1060/1292] Elapsed 6m 8s (remain 1m 20s) Loss: 0.3599(0.3046) Grad: 451345.7188  LR: 0.00000100  \n","Epoch: [3][1080/1292] Elapsed 6m 15s (remain 1m 13s) Loss: 0.4275(0.3046) Grad: 86712.0859  LR: 0.00000097  \n","Epoch: [3][1100/1292] Elapsed 6m 22s (remain 1m 6s) Loss: 0.3019(0.3038) Grad: 221761.9844  LR: 0.00000095  \n","Epoch: [3][1120/1292] Elapsed 6m 29s (remain 0m 59s) Loss: 0.1217(0.3044) Grad: 204648.7188  LR: 0.00000093  \n","Epoch: [3][1140/1292] Elapsed 6m 36s (remain 0m 52s) Loss: 0.6303(0.3047) Grad: 304365.9062  LR: 0.00000090  \n","Epoch: [3][1160/1292] Elapsed 6m 43s (remain 0m 45s) Loss: 0.2955(0.3048) Grad: 177383.1094  LR: 0.00000088  \n","Epoch: [3][1180/1292] Elapsed 6m 50s (remain 0m 38s) Loss: 0.3166(0.3047) Grad: 361154.5312  LR: 0.00000086  \n","Epoch: [3][1200/1292] Elapsed 6m 57s (remain 0m 31s) Loss: 0.3407(0.3044) Grad: 423748.8125  LR: 0.00000083  \n","Epoch: [3][1220/1292] Elapsed 7m 4s (remain 0m 24s) Loss: 0.6103(0.3043) Grad: 163950.6562  LR: 0.00000081  \n","Epoch: [3][1240/1292] Elapsed 7m 12s (remain 0m 17s) Loss: 0.1801(0.3036) Grad: 239769.4375  LR: 0.00000079  \n","Epoch: [3][1260/1292] Elapsed 7m 19s (remain 0m 10s) Loss: 0.4485(0.3042) Grad: 724439.8750  LR: 0.00000077  \n","Epoch: [3][1280/1292] Elapsed 7m 26s (remain 0m 3s) Loss: 0.3682(0.3039) Grad: 389373.2500  LR: 0.00000074  \n","Epoch: [3][1291/1292] Elapsed 7m 30s (remain 0m 0s) Loss: 0.2980(0.3037) Grad: 180644.7188  LR: 0.00000073  \n","EVAL: [0/250] Elapsed 0m 1s (remain 4m 32s) Loss: 0.4850(0.4850) \n","EVAL: [20/250] Elapsed 0m 15s (remain 2m 50s) Loss: 0.3482(0.3416) \n","EVAL: [40/250] Elapsed 0m 30s (remain 2m 34s) Loss: 0.3109(0.3492) \n","EVAL: [60/250] Elapsed 0m 44s (remain 2m 18s) Loss: 0.2331(0.3592) \n","EVAL: [80/250] Elapsed 0m 59s (remain 2m 3s) Loss: 0.3819(0.3614) \n","EVAL: [100/250] Elapsed 1m 13s (remain 1m 49s) Loss: 0.2232(0.3601) \n","EVAL: [120/250] Elapsed 1m 28s (remain 1m 34s) Loss: 0.3821(0.3544) \n","EVAL: [140/250] Elapsed 1m 43s (remain 1m 19s) Loss: 0.3182(0.3587) \n","EVAL: [160/250] Elapsed 1m 57s (remain 1m 5s) Loss: 0.2744(0.3568) \n","EVAL: [180/250] Elapsed 2m 12s (remain 0m 50s) Loss: 0.2485(0.3515) \n","EVAL: [200/250] Elapsed 2m 26s (remain 0m 35s) Loss: 0.3154(0.3459) \n","EVAL: [220/250] Elapsed 2m 41s (remain 0m 21s) Loss: 0.4430(0.3500) \n","EVAL: [240/250] Elapsed 2m 55s (remain 0m 6s) Loss: 0.3543(0.3495) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3037  avg_val_loss: 0.3494  time: 633s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3037  avg_val_loss: 0.3494  time: 633s\n","Epoch 3 - Score: 0.4546  Scores: [0.41174326642239495, 0.497505934019776]\n","INFO:__main__:Epoch 3 - Score: 0.4546  Scores: [0.41174326642239495, 0.497505934019776]\n","Epoch 3 - Save Best Score: 0.4546 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4546 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [249/250] Elapsed 3m 2s (remain 0m 0s) Loss: 0.4935(0.3494) \n","Epoch: [4][0/1292] Elapsed 0m 0s (remain 13m 53s) Loss: 0.2379(0.2379) Grad: inf  LR: 0.00000073  \n","Epoch: [4][20/1292] Elapsed 0m 7s (remain 7m 55s) Loss: 0.1725(0.3144) Grad: 419119.0938  LR: 0.00000071  \n","Epoch: [4][40/1292] Elapsed 0m 14s (remain 7m 37s) Loss: 0.2443(0.3080) Grad: 313442.1562  LR: 0.00000069  \n","Epoch: [4][60/1292] Elapsed 0m 22s (remain 7m 24s) Loss: 0.4197(0.3040) Grad: 639898.5000  LR: 0.00000067  \n","Epoch: [4][80/1292] Elapsed 0m 28s (remain 7m 12s) Loss: 0.1273(0.2987) Grad: 483162.5625  LR: 0.00000065  \n","Epoch: [4][100/1292] Elapsed 0m 36s (remain 7m 6s) Loss: 0.2096(0.2936) Grad: 232325.3750  LR: 0.00000063  \n","Epoch: [4][120/1292] Elapsed 0m 43s (remain 6m 56s) Loss: 0.3829(0.2912) Grad: 181049.4688  LR: 0.00000061  \n","Epoch: [4][140/1292] Elapsed 0m 49s (remain 6m 46s) Loss: 0.1938(0.2847) Grad: 596755.4375  LR: 0.00000059  \n","Epoch: [4][160/1292] Elapsed 0m 56s (remain 6m 38s) Loss: 0.2299(0.2865) Grad: 341768.2812  LR: 0.00000057  \n","Epoch: [4][180/1292] Elapsed 1m 3s (remain 6m 29s) Loss: 0.2303(0.2792) Grad: 268671.8125  LR: 0.00000055  \n","Epoch: [4][200/1292] Elapsed 1m 10s (remain 6m 22s) Loss: 0.2087(0.2792) Grad: 406134.6250  LR: 0.00000053  \n","Epoch: [4][220/1292] Elapsed 1m 17s (remain 6m 17s) Loss: 0.1876(0.2798) Grad: 206289.4688  LR: 0.00000051  \n","Epoch: [4][240/1292] Elapsed 1m 24s (remain 6m 9s) Loss: 0.2678(0.2778) Grad: 176261.8281  LR: 0.00000049  \n","Epoch: [4][260/1292] Elapsed 1m 31s (remain 6m 1s) Loss: 0.2152(0.2786) Grad: 174278.8906  LR: 0.00000048  \n","Epoch: [4][280/1292] Elapsed 1m 38s (remain 5m 53s) Loss: 0.1979(0.2788) Grad: 216258.1406  LR: 0.00000046  \n","Epoch: [4][300/1292] Elapsed 1m 44s (remain 5m 45s) Loss: 0.1913(0.2777) Grad: 195028.7500  LR: 0.00000044  \n","Epoch: [4][320/1292] Elapsed 1m 52s (remain 5m 39s) Loss: 0.2860(0.2789) Grad: 187923.0781  LR: 0.00000042  \n","Epoch: [4][340/1292] Elapsed 1m 59s (remain 5m 32s) Loss: 0.2037(0.2775) Grad: 180559.2031  LR: 0.00000041  \n","Epoch: [4][360/1292] Elapsed 2m 5s (remain 5m 24s) Loss: 0.2259(0.2784) Grad: 149120.3594  LR: 0.00000039  \n","Epoch: [4][380/1292] Elapsed 2m 12s (remain 5m 17s) Loss: 0.2005(0.2781) Grad: 197003.2969  LR: 0.00000037  \n","Epoch: [4][400/1292] Elapsed 2m 19s (remain 5m 10s) Loss: 0.2635(0.2785) Grad: 397302.2188  LR: 0.00000036  \n","Epoch: [4][420/1292] Elapsed 2m 26s (remain 5m 3s) Loss: 0.2052(0.2801) Grad: 171930.2500  LR: 0.00000034  \n","Epoch: [4][440/1292] Elapsed 2m 33s (remain 4m 56s) Loss: 0.2895(0.2804) Grad: 128898.9531  LR: 0.00000033  \n","Epoch: [4][460/1292] Elapsed 2m 40s (remain 4m 49s) Loss: 0.2842(0.2792) Grad: 293772.8125  LR: 0.00000031  \n","Epoch: [4][480/1292] Elapsed 2m 47s (remain 4m 42s) Loss: 0.1333(0.2783) Grad: 156380.7344  LR: 0.00000030  \n","Epoch: [4][500/1292] Elapsed 2m 54s (remain 4m 35s) Loss: 0.5287(0.2786) Grad: 266671.2812  LR: 0.00000028  \n","Epoch: [4][520/1292] Elapsed 3m 1s (remain 4m 28s) Loss: 0.5622(0.2788) Grad: 201056.5938  LR: 0.00000027  \n","Epoch: [4][540/1292] Elapsed 3m 8s (remain 4m 21s) Loss: 0.1706(0.2779) Grad: 137602.2031  LR: 0.00000026  \n","Epoch: [4][560/1292] Elapsed 3m 15s (remain 4m 15s) Loss: 0.2635(0.2780) Grad: 369322.9688  LR: 0.00000024  \n","Epoch: [4][580/1292] Elapsed 3m 23s (remain 4m 8s) Loss: 0.4814(0.2789) Grad: 233342.6250  LR: 0.00000023  \n","Epoch: [4][600/1292] Elapsed 3m 29s (remain 4m 1s) Loss: 0.3565(0.2785) Grad: 550604.5625  LR: 0.00000022  \n","Epoch: [4][620/1292] Elapsed 3m 36s (remain 3m 53s) Loss: 0.3213(0.2770) Grad: 735766.9375  LR: 0.00000021  \n","Epoch: [4][640/1292] Elapsed 3m 43s (remain 3m 46s) Loss: 0.2438(0.2764) Grad: 216484.6094  LR: 0.00000019  \n","Epoch: [4][660/1292] Elapsed 3m 50s (remain 3m 39s) Loss: 0.2253(0.2763) Grad: 799732.0000  LR: 0.00000018  \n","Epoch: [4][680/1292] Elapsed 3m 57s (remain 3m 32s) Loss: 0.1618(0.2758) Grad: 265971.6562  LR: 0.00000017  \n","Epoch: [4][700/1292] Elapsed 4m 4s (remain 3m 25s) Loss: 0.3098(0.2766) Grad: 211428.9844  LR: 0.00000016  \n","Epoch: [4][720/1292] Elapsed 4m 11s (remain 3m 18s) Loss: 0.3287(0.2772) Grad: 235089.2969  LR: 0.00000015  \n","Epoch: [4][740/1292] Elapsed 4m 18s (remain 3m 11s) Loss: 0.2621(0.2768) Grad: 152264.4688  LR: 0.00000014  \n","Epoch: [4][760/1292] Elapsed 4m 25s (remain 3m 4s) Loss: 0.3584(0.2769) Grad: 402935.7812  LR: 0.00000013  \n","Epoch: [4][780/1292] Elapsed 4m 32s (remain 2m 58s) Loss: 0.5194(0.2777) Grad: 216916.0156  LR: 0.00000012  \n","Epoch: [4][800/1292] Elapsed 4m 39s (remain 2m 51s) Loss: 0.2747(0.2770) Grad: 172458.0625  LR: 0.00000011  \n","Epoch: [4][820/1292] Elapsed 4m 46s (remain 2m 44s) Loss: 0.2119(0.2765) Grad: 214683.8438  LR: 0.00000010  \n","Epoch: [4][840/1292] Elapsed 4m 53s (remain 2m 37s) Loss: 0.2744(0.2766) Grad: 259760.7344  LR: 0.00000009  \n","Epoch: [4][860/1292] Elapsed 5m 0s (remain 2m 30s) Loss: 0.1486(0.2761) Grad: 211936.4375  LR: 0.00000009  \n","Epoch: [4][880/1292] Elapsed 5m 8s (remain 2m 23s) Loss: 0.1028(0.2760) Grad: 157930.8125  LR: 0.00000008  \n","Epoch: [4][900/1292] Elapsed 5m 15s (remain 2m 16s) Loss: 0.1779(0.2758) Grad: 180947.2344  LR: 0.00000007  \n","Epoch: [4][920/1292] Elapsed 5m 21s (remain 2m 9s) Loss: 0.2370(0.2760) Grad: 173098.8594  LR: 0.00000006  \n","Epoch: [4][940/1292] Elapsed 5m 29s (remain 2m 2s) Loss: 0.1586(0.2758) Grad: 251863.3594  LR: 0.00000006  \n","Epoch: [4][960/1292] Elapsed 5m 36s (remain 1m 55s) Loss: 0.3083(0.2758) Grad: 226889.9531  LR: 0.00000005  \n","Epoch: [4][980/1292] Elapsed 5m 43s (remain 1m 48s) Loss: 0.1679(0.2756) Grad: 282840.4062  LR: 0.00000004  \n","Epoch: [4][1000/1292] Elapsed 5m 49s (remain 1m 41s) Loss: 0.2369(0.2754) Grad: 223830.7812  LR: 0.00000004  \n","Epoch: [4][1020/1292] Elapsed 5m 56s (remain 1m 34s) Loss: 0.3052(0.2752) Grad: 236037.5938  LR: 0.00000003  \n","Epoch: [4][1040/1292] Elapsed 6m 3s (remain 1m 27s) Loss: 0.2502(0.2758) Grad: 410355.5000  LR: 0.00000003  \n","Epoch: [4][1060/1292] Elapsed 6m 11s (remain 1m 20s) Loss: 0.2849(0.2766) Grad: 164243.5469  LR: 0.00000002  \n","Epoch: [4][1080/1292] Elapsed 6m 18s (remain 1m 13s) Loss: 0.1918(0.2768) Grad: 170786.8125  LR: 0.00000002  \n","Epoch: [4][1100/1292] Elapsed 6m 25s (remain 1m 6s) Loss: 0.2253(0.2758) Grad: 145049.9844  LR: 0.00000002  \n","Epoch: [4][1120/1292] Elapsed 6m 32s (remain 0m 59s) Loss: 0.3801(0.2757) Grad: 195797.3281  LR: 0.00000001  \n","Epoch: [4][1140/1292] Elapsed 6m 39s (remain 0m 52s) Loss: 0.2150(0.2761) Grad: 144102.5156  LR: 0.00000001  \n","Epoch: [4][1160/1292] Elapsed 6m 46s (remain 0m 45s) Loss: 0.1931(0.2757) Grad: 165902.6250  LR: 0.00000001  \n","Epoch: [4][1180/1292] Elapsed 6m 52s (remain 0m 38s) Loss: 0.1605(0.2754) Grad: 287441.5625  LR: 0.00000001  \n","Epoch: [4][1200/1292] Elapsed 6m 59s (remain 0m 31s) Loss: 0.2034(0.2753) Grad: 228176.9531  LR: 0.00000000  \n","Epoch: [4][1220/1292] Elapsed 7m 6s (remain 0m 24s) Loss: 0.3458(0.2754) Grad: 673013.4375  LR: 0.00000000  \n","Epoch: [4][1240/1292] Elapsed 7m 13s (remain 0m 17s) Loss: 0.2679(0.2751) Grad: 145864.3281  LR: 0.00000000  \n","Epoch: [4][1260/1292] Elapsed 7m 20s (remain 0m 10s) Loss: 0.3820(0.2748) Grad: 194976.0625  LR: 0.00000000  \n","Epoch: [4][1280/1292] Elapsed 7m 27s (remain 0m 3s) Loss: 0.1865(0.2746) Grad: 329921.0625  LR: 0.00000000  \n","Epoch: [4][1291/1292] Elapsed 7m 30s (remain 0m 0s) Loss: 0.2079(0.2746) Grad: 247177.6562  LR: 0.00000000  \n","EVAL: [0/250] Elapsed 0m 1s (remain 4m 29s) Loss: 0.4506(0.4506) \n","EVAL: [20/250] Elapsed 0m 15s (remain 2m 50s) Loss: 0.3355(0.3316) \n","EVAL: [40/250] Elapsed 0m 30s (remain 2m 34s) Loss: 0.3132(0.3424) \n","EVAL: [60/250] Elapsed 0m 44s (remain 2m 18s) Loss: 0.2305(0.3528) \n","EVAL: [80/250] Elapsed 0m 59s (remain 2m 3s) Loss: 0.3719(0.3546) \n","EVAL: [100/250] Elapsed 1m 13s (remain 1m 49s) Loss: 0.2194(0.3529) \n","EVAL: [120/250] Elapsed 1m 28s (remain 1m 34s) Loss: 0.3842(0.3491) \n","EVAL: [140/250] Elapsed 1m 43s (remain 1m 19s) Loss: 0.3512(0.3536) \n","EVAL: [160/250] Elapsed 1m 57s (remain 1m 5s) Loss: 0.2655(0.3516) \n","EVAL: [180/250] Elapsed 2m 12s (remain 0m 50s) Loss: 0.2604(0.3463) \n","EVAL: [200/250] Elapsed 2m 26s (remain 0m 35s) Loss: 0.3099(0.3406) \n","EVAL: [220/250] Elapsed 2m 41s (remain 0m 21s) Loss: 0.4346(0.3441) \n","EVAL: [240/250] Elapsed 2m 55s (remain 0m 6s) Loss: 0.3628(0.3435) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2746  avg_val_loss: 0.3436  time: 633s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2746  avg_val_loss: 0.3436  time: 633s\n","Epoch 4 - Score: 0.4473  Scores: [0.4111314095520786, 0.48350018598369315]\n","INFO:__main__:Epoch 4 - Score: 0.4473  Scores: [0.4111314095520786, 0.48350018598369315]\n","Epoch 4 - Save Best Score: 0.4473 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.4473 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [249/250] Elapsed 3m 2s (remain 0m 0s) Loss: 0.4637(0.3436) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.4473  Scores: [0.4111314095520786, 0.48350018598369315]\n","INFO:__main__:Score: 0.4473  Scores: [0.4111314095520786, 0.48350018598369315]\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["========== prompt_id: ['814d6b'] validation ==========\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1515] Elapsed 0m 0s (remain 21m 37s) Loss: 0.9210(0.9210) Grad: 8166189.5000  LR: 0.00000500  \n","Epoch: [1][20/1515] Elapsed 0m 9s (remain 11m 17s) Loss: 1.0471(0.9011) Grad: 178095.7969  LR: 0.00000500  \n","Epoch: [1][40/1515] Elapsed 0m 18s (remain 10m 51s) Loss: 0.3203(0.8043) Grad: 98480.4219  LR: 0.00000500  \n","Epoch: [1][60/1515] Elapsed 0m 26s (remain 10m 39s) Loss: 0.6012(0.8041) Grad: 471706.9688  LR: 0.00000500  \n","Epoch: [1][80/1515] Elapsed 0m 35s (remain 10m 26s) Loss: 0.4242(0.7976) Grad: 1958238.1250  LR: 0.00000500  \n","Epoch: [1][100/1515] Elapsed 0m 43s (remain 10m 13s) Loss: 0.9157(0.7714) Grad: 247364.3125  LR: 0.00000500  \n","Epoch: [1][120/1515] Elapsed 0m 52s (remain 10m 3s) Loss: 0.5443(0.7474) Grad: 146340.2188  LR: 0.00000500  \n","Epoch: [1][140/1515] Elapsed 1m 0s (remain 9m 52s) Loss: 0.5285(0.7294) Grad: 817501.5000  LR: 0.00000499  \n","Epoch: [1][160/1515] Elapsed 1m 9s (remain 9m 45s) Loss: 0.3111(0.7112) Grad: 445388.5000  LR: 0.00000499  \n","Epoch: [1][180/1515] Elapsed 1m 18s (remain 9m 35s) Loss: 0.2478(0.6829) Grad: 299862.9062  LR: 0.00000499  \n","Epoch: [1][200/1515] Elapsed 1m 26s (remain 9m 27s) Loss: 0.3613(0.6669) Grad: 223711.5938  LR: 0.00000499  \n","Epoch: [1][220/1515] Elapsed 1m 34s (remain 9m 16s) Loss: 0.1658(0.6508) Grad: 258553.2656  LR: 0.00000498  \n","Epoch: [1][240/1515] Elapsed 1m 43s (remain 9m 6s) Loss: 0.3743(0.6376) Grad: 139347.3750  LR: 0.00000498  \n","Epoch: [1][260/1515] Elapsed 1m 51s (remain 8m 57s) Loss: 0.8185(0.6299) Grad: 382904.8125  LR: 0.00000498  \n","Epoch: [1][280/1515] Elapsed 2m 0s (remain 8m 48s) Loss: 0.5721(0.6218) Grad: 374362.3750  LR: 0.00000497  \n","Epoch: [1][300/1515] Elapsed 2m 8s (remain 8m 40s) Loss: 0.3683(0.6145) Grad: 78817.8438  LR: 0.00000497  \n","Epoch: [1][320/1515] Elapsed 2m 17s (remain 8m 31s) Loss: 0.4144(0.6050) Grad: 311199.6875  LR: 0.00000497  \n","Epoch: [1][340/1515] Elapsed 2m 25s (remain 8m 22s) Loss: 0.4120(0.5956) Grad: 403456.5625  LR: 0.00000496  \n","Epoch: [1][360/1515] Elapsed 2m 34s (remain 8m 12s) Loss: 0.3095(0.5899) Grad: 193314.2812  LR: 0.00000496  \n","Epoch: [1][380/1515] Elapsed 2m 42s (remain 8m 4s) Loss: 0.6353(0.5838) Grad: 373472.7812  LR: 0.00000495  \n","Epoch: [1][400/1515] Elapsed 2m 51s (remain 7m 55s) Loss: 0.6035(0.5752) Grad: 112829.3438  LR: 0.00000495  \n","Epoch: [1][420/1515] Elapsed 2m 59s (remain 7m 47s) Loss: 0.6000(0.5649) Grad: 82144.4531  LR: 0.00000494  \n","Epoch: [1][440/1515] Elapsed 3m 8s (remain 7m 38s) Loss: 0.3519(0.5600) Grad: 337718.8125  LR: 0.00000493  \n","Epoch: [1][460/1515] Elapsed 3m 16s (remain 7m 29s) Loss: 0.3330(0.5544) Grad: 72388.9766  LR: 0.00000493  \n","Epoch: [1][480/1515] Elapsed 3m 25s (remain 7m 21s) Loss: 0.3017(0.5483) Grad: 481302.4688  LR: 0.00000492  \n","Epoch: [1][500/1515] Elapsed 3m 33s (remain 7m 12s) Loss: 0.4369(0.5460) Grad: 198834.8906  LR: 0.00000492  \n","Epoch: [1][520/1515] Elapsed 3m 42s (remain 7m 3s) Loss: 0.3312(0.5436) Grad: 245814.6719  LR: 0.00000491  \n","Epoch: [1][540/1515] Elapsed 3m 50s (remain 6m 55s) Loss: 0.4511(0.5390) Grad: 122280.5469  LR: 0.00000490  \n","Epoch: [1][560/1515] Elapsed 3m 59s (remain 6m 46s) Loss: 0.4871(0.5355) Grad: 169952.2656  LR: 0.00000490  \n","Epoch: [1][580/1515] Elapsed 4m 7s (remain 6m 37s) Loss: 0.3729(0.5301) Grad: 181713.3906  LR: 0.00000489  \n","Epoch: [1][600/1515] Elapsed 4m 15s (remain 6m 28s) Loss: 0.6470(0.5250) Grad: 226027.8125  LR: 0.00000488  \n","Epoch: [1][620/1515] Elapsed 4m 24s (remain 6m 20s) Loss: 0.5428(0.5220) Grad: 172436.5312  LR: 0.00000487  \n","Epoch: [1][640/1515] Elapsed 4m 32s (remain 6m 11s) Loss: 0.1782(0.5177) Grad: 56935.2109  LR: 0.00000486  \n","Epoch: [1][660/1515] Elapsed 4m 41s (remain 6m 3s) Loss: 0.4258(0.5141) Grad: 1103188.2500  LR: 0.00000485  \n","Epoch: [1][680/1515] Elapsed 4m 49s (remain 5m 54s) Loss: 0.4832(0.5115) Grad: 265272.4062  LR: 0.00000485  \n","Epoch: [1][700/1515] Elapsed 4m 57s (remain 5m 45s) Loss: 0.3014(0.5085) Grad: 88106.6172  LR: 0.00000484  \n","Epoch: [1][720/1515] Elapsed 5m 6s (remain 5m 37s) Loss: 0.2979(0.5045) Grad: 219755.3438  LR: 0.00000483  \n","Epoch: [1][740/1515] Elapsed 5m 14s (remain 5m 29s) Loss: 0.3002(0.5030) Grad: 148123.0469  LR: 0.00000482  \n","Epoch: [1][760/1515] Elapsed 5m 23s (remain 5m 20s) Loss: 0.3319(0.4995) Grad: 149619.6562  LR: 0.00000481  \n","Epoch: [1][780/1515] Elapsed 5m 31s (remain 5m 11s) Loss: 0.3304(0.4972) Grad: 127727.1875  LR: 0.00000480  \n","Epoch: [1][800/1515] Elapsed 5m 39s (remain 5m 3s) Loss: 0.2936(0.4940) Grad: 268059.2812  LR: 0.00000479  \n","Epoch: [1][820/1515] Elapsed 5m 48s (remain 4m 54s) Loss: 0.3273(0.4927) Grad: 197623.4531  LR: 0.00000478  \n","Epoch: [1][840/1515] Elapsed 5m 57s (remain 4m 46s) Loss: 0.3298(0.4903) Grad: 141544.2812  LR: 0.00000477  \n","Epoch: [1][860/1515] Elapsed 6m 5s (remain 4m 37s) Loss: 0.2950(0.4884) Grad: 47933.7617  LR: 0.00000476  \n","Epoch: [1][880/1515] Elapsed 6m 14s (remain 4m 29s) Loss: 0.3464(0.4853) Grad: 185819.3438  LR: 0.00000474  \n","Epoch: [1][900/1515] Elapsed 6m 22s (remain 4m 21s) Loss: 0.4738(0.4835) Grad: 101529.1406  LR: 0.00000473  \n","Epoch: [1][920/1515] Elapsed 6m 31s (remain 4m 12s) Loss: 0.3533(0.4822) Grad: 102789.6250  LR: 0.00000472  \n","Epoch: [1][940/1515] Elapsed 6m 40s (remain 4m 4s) Loss: 0.3419(0.4810) Grad: 122273.0000  LR: 0.00000471  \n","Epoch: [1][960/1515] Elapsed 6m 48s (remain 3m 55s) Loss: 0.3715(0.4790) Grad: 272026.5312  LR: 0.00000470  \n","Epoch: [1][980/1515] Elapsed 6m 57s (remain 3m 47s) Loss: 0.5721(0.4774) Grad: 131205.1406  LR: 0.00000468  \n","Epoch: [1][1000/1515] Elapsed 7m 5s (remain 3m 38s) Loss: 0.1944(0.4741) Grad: 67646.1250  LR: 0.00000467  \n","Epoch: [1][1020/1515] Elapsed 7m 14s (remain 3m 30s) Loss: 0.3572(0.4727) Grad: 183309.8438  LR: 0.00000466  \n","Epoch: [1][1040/1515] Elapsed 7m 22s (remain 3m 21s) Loss: 0.2828(0.4714) Grad: 85135.4766  LR: 0.00000464  \n","Epoch: [1][1060/1515] Elapsed 7m 31s (remain 3m 13s) Loss: 0.5379(0.4700) Grad: 254206.3438  LR: 0.00000463  \n","Epoch: [1][1080/1515] Elapsed 7m 39s (remain 3m 4s) Loss: 0.3943(0.4676) Grad: 98737.4062  LR: 0.00000462  \n","Epoch: [1][1100/1515] Elapsed 7m 48s (remain 2m 56s) Loss: 0.4181(0.4655) Grad: 141076.5781  LR: 0.00000460  \n","Epoch: [1][1120/1515] Elapsed 7m 56s (remain 2m 47s) Loss: 0.2770(0.4642) Grad: 372834.1250  LR: 0.00000459  \n","Epoch: [1][1140/1515] Elapsed 8m 5s (remain 2m 39s) Loss: 0.3472(0.4632) Grad: 90001.1641  LR: 0.00000458  \n","Epoch: [1][1160/1515] Elapsed 8m 13s (remain 2m 30s) Loss: 0.4148(0.4624) Grad: 87546.4609  LR: 0.00000456  \n","Epoch: [1][1180/1515] Elapsed 8m 22s (remain 2m 22s) Loss: 0.3067(0.4610) Grad: 173765.1562  LR: 0.00000455  \n","Epoch: [1][1200/1515] Elapsed 8m 30s (remain 2m 13s) Loss: 0.2608(0.4605) Grad: 137009.2500  LR: 0.00000453  \n","Epoch: [1][1220/1515] Elapsed 8m 39s (remain 2m 5s) Loss: 0.3453(0.4599) Grad: 66620.0234  LR: 0.00000452  \n","Epoch: [1][1240/1515] Elapsed 8m 48s (remain 1m 56s) Loss: 0.3505(0.4591) Grad: 49220.2461  LR: 0.00000450  \n","Epoch: [1][1260/1515] Elapsed 8m 56s (remain 1m 48s) Loss: 0.6379(0.4585) Grad: 203694.8438  LR: 0.00000448  \n","Epoch: [1][1280/1515] Elapsed 9m 5s (remain 1m 39s) Loss: 0.5382(0.4581) Grad: 85598.8594  LR: 0.00000447  \n","Epoch: [1][1300/1515] Elapsed 9m 13s (remain 1m 31s) Loss: 0.2129(0.4577) Grad: 38801.8828  LR: 0.00000445  \n","Epoch: [1][1320/1515] Elapsed 9m 21s (remain 1m 22s) Loss: 0.3839(0.4568) Grad: 108225.3594  LR: 0.00000444  \n","Epoch: [1][1340/1515] Elapsed 9m 29s (remain 1m 13s) Loss: 0.3214(0.4556) Grad: 38789.7070  LR: 0.00000442  \n","Epoch: [1][1360/1515] Elapsed 9m 38s (remain 1m 5s) Loss: 0.3715(0.4550) Grad: 100979.6953  LR: 0.00000440  \n","Epoch: [1][1380/1515] Elapsed 9m 47s (remain 0m 56s) Loss: 0.5873(0.4541) Grad: 295205.9375  LR: 0.00000439  \n","Epoch: [1][1400/1515] Elapsed 9m 55s (remain 0m 48s) Loss: 0.2071(0.4528) Grad: 68989.5781  LR: 0.00000437  \n","Epoch: [1][1420/1515] Elapsed 10m 3s (remain 0m 39s) Loss: 0.3533(0.4520) Grad: 155833.7188  LR: 0.00000435  \n","Epoch: [1][1440/1515] Elapsed 10m 12s (remain 0m 31s) Loss: 0.4239(0.4516) Grad: 97247.9219  LR: 0.00000433  \n","Epoch: [1][1460/1515] Elapsed 10m 21s (remain 0m 22s) Loss: 0.6256(0.4509) Grad: 178352.1094  LR: 0.00000432  \n","Epoch: [1][1480/1515] Elapsed 10m 29s (remain 0m 14s) Loss: 0.3688(0.4504) Grad: 167080.4844  LR: 0.00000430  \n","Epoch: [1][1500/1515] Elapsed 10m 37s (remain 0m 5s) Loss: 0.3234(0.4492) Grad: 59749.0273  LR: 0.00000428  \n","Epoch: [1][1514/1515] Elapsed 10m 43s (remain 0m 0s) Loss: 0.3626(0.4483) Grad: 153392.4688  LR: 0.00000427  \n","EVAL: [0/138] Elapsed 0m 0s (remain 2m 14s) Loss: 0.6271(0.6271) \n","EVAL: [20/138] Elapsed 0m 12s (remain 1m 8s) Loss: 0.2875(0.4870) \n","EVAL: [40/138] Elapsed 0m 23s (remain 0m 55s) Loss: 0.5338(0.5103) \n","EVAL: [60/138] Elapsed 0m 34s (remain 0m 43s) Loss: 0.4340(0.4946) \n","EVAL: [80/138] Elapsed 0m 46s (remain 0m 32s) Loss: 0.4300(0.4935) \n","EVAL: [100/138] Elapsed 0m 57s (remain 0m 21s) Loss: 0.5268(0.4946) \n","EVAL: [120/138] Elapsed 1m 9s (remain 0m 9s) Loss: 0.3749(0.4932) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.4483  avg_val_loss: 0.4976  time: 723s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4483  avg_val_loss: 0.4976  time: 723s\n","Epoch 1 - Score: 0.6531  Scores: [0.527906272189333, 0.7781947412741725]\n","INFO:__main__:Epoch 1 - Score: 0.6531  Scores: [0.527906272189333, 0.7781947412741725]\n","Epoch 1 - Save Best Score: 0.6531 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6531 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [137/138] Elapsed 1m 19s (remain 0m 0s) Loss: 0.7244(0.4976) \n","Epoch: [2][0/1515] Elapsed 0m 0s (remain 20m 0s) Loss: 0.4402(0.4402) Grad: inf  LR: 0.00000427  \n","Epoch: [2][20/1515] Elapsed 0m 9s (remain 10m 43s) Loss: 0.4217(0.3722) Grad: 208190.2344  LR: 0.00000425  \n","Epoch: [2][40/1515] Elapsed 0m 17s (remain 10m 20s) Loss: 0.3847(0.3755) Grad: 137133.4062  LR: 0.00000423  \n","Epoch: [2][60/1515] Elapsed 0m 25s (remain 10m 13s) Loss: 0.2771(0.3594) Grad: 324603.8750  LR: 0.00000421  \n","Epoch: [2][80/1515] Elapsed 0m 34s (remain 10m 9s) Loss: 0.2957(0.3500) Grad: 275898.8750  LR: 0.00000419  \n","Epoch: [2][100/1515] Elapsed 0m 43s (remain 10m 7s) Loss: 0.4388(0.3588) Grad: 173802.9375  LR: 0.00000417  \n","Epoch: [2][120/1515] Elapsed 0m 51s (remain 9m 58s) Loss: 0.3915(0.3540) Grad: 126000.1406  LR: 0.00000415  \n","Epoch: [2][140/1515] Elapsed 1m 0s (remain 9m 47s) Loss: 0.4625(0.3561) Grad: 259595.0625  LR: 0.00000413  \n","Epoch: [2][160/1515] Elapsed 1m 8s (remain 9m 39s) Loss: 0.2688(0.3555) Grad: 412830.3125  LR: 0.00000411  \n","Epoch: [2][180/1515] Elapsed 1m 17s (remain 9m 29s) Loss: 0.4932(0.3592) Grad: 181953.8125  LR: 0.00000409  \n","Epoch: [2][200/1515] Elapsed 1m 25s (remain 9m 20s) Loss: 0.3625(0.3579) Grad: 64083.6328  LR: 0.00000407  \n","Epoch: [2][220/1515] Elapsed 1m 34s (remain 9m 13s) Loss: 0.3043(0.3550) Grad: 253759.4062  LR: 0.00000405  \n","Epoch: [2][240/1515] Elapsed 1m 42s (remain 9m 2s) Loss: 0.3741(0.3588) Grad: 195003.9375  LR: 0.00000403  \n","Epoch: [2][260/1515] Elapsed 1m 51s (remain 8m 53s) Loss: 0.3190(0.3575) Grad: 78195.2500  LR: 0.00000401  \n","Epoch: [2][280/1515] Elapsed 1m 59s (remain 8m 43s) Loss: 0.4228(0.3566) Grad: 110484.8281  LR: 0.00000399  \n","Epoch: [2][300/1515] Elapsed 2m 7s (remain 8m 35s) Loss: 0.2461(0.3560) Grad: 198114.8125  LR: 0.00000397  \n","Epoch: [2][320/1515] Elapsed 2m 16s (remain 8m 27s) Loss: 0.5930(0.3555) Grad: 630293.2500  LR: 0.00000395  \n","Epoch: [2][340/1515] Elapsed 2m 24s (remain 8m 17s) Loss: 0.3423(0.3542) Grad: 234410.0000  LR: 0.00000393  \n","Epoch: [2][360/1515] Elapsed 2m 33s (remain 8m 9s) Loss: 0.2866(0.3526) Grad: 136881.7656  LR: 0.00000391  \n","Epoch: [2][380/1515] Elapsed 2m 41s (remain 8m 0s) Loss: 0.5539(0.3515) Grad: 284953.6875  LR: 0.00000389  \n","Epoch: [2][400/1515] Elapsed 2m 49s (remain 7m 51s) Loss: 0.4226(0.3504) Grad: 377186.7812  LR: 0.00000387  \n","Epoch: [2][420/1515] Elapsed 2m 58s (remain 7m 43s) Loss: 0.3536(0.3505) Grad: 320347.2812  LR: 0.00000384  \n","Epoch: [2][440/1515] Elapsed 3m 6s (remain 7m 35s) Loss: 0.5327(0.3518) Grad: 270928.6250  LR: 0.00000382  \n","Epoch: [2][460/1515] Elapsed 3m 15s (remain 7m 26s) Loss: 0.3367(0.3501) Grad: 140368.2812  LR: 0.00000380  \n","Epoch: [2][480/1515] Elapsed 3m 24s (remain 7m 18s) Loss: 0.2954(0.3481) Grad: 154702.4375  LR: 0.00000378  \n","Epoch: [2][500/1515] Elapsed 3m 32s (remain 7m 10s) Loss: 0.3186(0.3462) Grad: 508826.4375  LR: 0.00000376  \n","Epoch: [2][520/1515] Elapsed 3m 41s (remain 7m 2s) Loss: 0.4324(0.3463) Grad: 221747.2969  LR: 0.00000373  \n","Epoch: [2][540/1515] Elapsed 3m 49s (remain 6m 53s) Loss: 0.2829(0.3451) Grad: 134738.6875  LR: 0.00000371  \n","Epoch: [2][560/1515] Elapsed 3m 58s (remain 6m 45s) Loss: 0.4470(0.3448) Grad: 144611.8438  LR: 0.00000369  \n","Epoch: [2][580/1515] Elapsed 4m 6s (remain 6m 36s) Loss: 0.3567(0.3441) Grad: 191991.2812  LR: 0.00000366  \n","Epoch: [2][600/1515] Elapsed 4m 15s (remain 6m 28s) Loss: 0.3810(0.3443) Grad: 179567.5000  LR: 0.00000364  \n","Epoch: [2][620/1515] Elapsed 4m 23s (remain 6m 19s) Loss: 0.1926(0.3434) Grad: 169728.8750  LR: 0.00000362  \n","Epoch: [2][640/1515] Elapsed 4m 32s (remain 6m 11s) Loss: 0.4567(0.3417) Grad: 350475.4375  LR: 0.00000360  \n","Epoch: [2][660/1515] Elapsed 4m 41s (remain 6m 3s) Loss: 0.4539(0.3425) Grad: 368693.1562  LR: 0.00000357  \n","Epoch: [2][680/1515] Elapsed 4m 49s (remain 5m 54s) Loss: 0.3479(0.3430) Grad: 224382.5625  LR: 0.00000355  \n","Epoch: [2][700/1515] Elapsed 4m 58s (remain 5m 46s) Loss: 0.2938(0.3417) Grad: 222454.4688  LR: 0.00000352  \n","Epoch: [2][720/1515] Elapsed 5m 6s (remain 5m 37s) Loss: 0.1822(0.3420) Grad: 124998.2734  LR: 0.00000350  \n","Epoch: [2][740/1515] Elapsed 5m 14s (remain 5m 28s) Loss: 0.4308(0.3420) Grad: 410848.3750  LR: 0.00000348  \n","Epoch: [2][760/1515] Elapsed 5m 23s (remain 5m 20s) Loss: 0.1519(0.3406) Grad: 355387.1250  LR: 0.00000345  \n","Epoch: [2][780/1515] Elapsed 5m 31s (remain 5m 11s) Loss: 0.1680(0.3401) Grad: 218945.1250  LR: 0.00000343  \n","Epoch: [2][800/1515] Elapsed 5m 40s (remain 5m 3s) Loss: 0.3172(0.3406) Grad: 180363.6406  LR: 0.00000341  \n","Epoch: [2][820/1515] Elapsed 5m 49s (remain 4m 55s) Loss: 0.1786(0.3396) Grad: 216527.6406  LR: 0.00000338  \n","Epoch: [2][840/1515] Elapsed 5m 57s (remain 4m 46s) Loss: 0.3642(0.3400) Grad: 207666.4844  LR: 0.00000336  \n","Epoch: [2][860/1515] Elapsed 6m 5s (remain 4m 37s) Loss: 0.1863(0.3403) Grad: 71354.1016  LR: 0.00000333  \n","Epoch: [2][880/1515] Elapsed 6m 14s (remain 4m 29s) Loss: 0.2590(0.3397) Grad: 116156.5859  LR: 0.00000331  \n","Epoch: [2][900/1515] Elapsed 6m 22s (remain 4m 20s) Loss: 0.4186(0.3389) Grad: 162115.8750  LR: 0.00000328  \n","Epoch: [2][920/1515] Elapsed 6m 30s (remain 4m 12s) Loss: 0.3373(0.3391) Grad: 197426.1562  LR: 0.00000326  \n","Epoch: [2][940/1515] Elapsed 6m 39s (remain 4m 3s) Loss: 0.4551(0.3390) Grad: 116026.1172  LR: 0.00000323  \n","Epoch: [2][960/1515] Elapsed 6m 47s (remain 3m 55s) Loss: 0.2821(0.3383) Grad: 130768.6328  LR: 0.00000321  \n","Epoch: [2][980/1515] Elapsed 6m 56s (remain 3m 46s) Loss: 0.2283(0.3381) Grad: 104183.4922  LR: 0.00000318  \n","Epoch: [2][1000/1515] Elapsed 7m 5s (remain 3m 38s) Loss: 0.4936(0.3384) Grad: 291442.0000  LR: 0.00000316  \n","Epoch: [2][1020/1515] Elapsed 7m 13s (remain 3m 29s) Loss: 0.2545(0.3383) Grad: 246939.6250  LR: 0.00000313  \n","Epoch: [2][1040/1515] Elapsed 7m 22s (remain 3m 21s) Loss: 0.2737(0.3381) Grad: 206965.7031  LR: 0.00000311  \n","Epoch: [2][1060/1515] Elapsed 7m 30s (remain 3m 12s) Loss: 0.2475(0.3383) Grad: 316355.6562  LR: 0.00000308  \n","Epoch: [2][1080/1515] Elapsed 7m 39s (remain 3m 4s) Loss: 0.3162(0.3379) Grad: 547638.6875  LR: 0.00000306  \n","Epoch: [2][1100/1515] Elapsed 7m 47s (remain 2m 55s) Loss: 0.4736(0.3376) Grad: 300499.0938  LR: 0.00000303  \n","Epoch: [2][1120/1515] Elapsed 7m 56s (remain 2m 47s) Loss: 0.4265(0.3379) Grad: 155981.8906  LR: 0.00000301  \n","Epoch: [2][1140/1515] Elapsed 8m 4s (remain 2m 38s) Loss: 0.2755(0.3375) Grad: 288124.7812  LR: 0.00000298  \n","Epoch: [2][1160/1515] Elapsed 8m 13s (remain 2m 30s) Loss: 0.3649(0.3380) Grad: 241030.5781  LR: 0.00000296  \n","Epoch: [2][1180/1515] Elapsed 8m 22s (remain 2m 22s) Loss: 0.4817(0.3379) Grad: 388006.9062  LR: 0.00000293  \n","Epoch: [2][1200/1515] Elapsed 8m 30s (remain 2m 13s) Loss: 0.5336(0.3384) Grad: 222221.8750  LR: 0.00000291  \n","Epoch: [2][1220/1515] Elapsed 8m 39s (remain 2m 4s) Loss: 0.3730(0.3374) Grad: 106142.8203  LR: 0.00000288  \n","Epoch: [2][1240/1515] Elapsed 8m 47s (remain 1m 56s) Loss: 0.3655(0.3378) Grad: 89558.0938  LR: 0.00000286  \n","Epoch: [2][1260/1515] Elapsed 8m 55s (remain 1m 47s) Loss: 0.4933(0.3377) Grad: 182283.0625  LR: 0.00000283  \n","Epoch: [2][1280/1515] Elapsed 9m 4s (remain 1m 39s) Loss: 0.2472(0.3376) Grad: 389242.2812  LR: 0.00000280  \n","Epoch: [2][1300/1515] Elapsed 9m 12s (remain 1m 30s) Loss: 0.2578(0.3375) Grad: 206872.4688  LR: 0.00000278  \n","Epoch: [2][1320/1515] Elapsed 9m 21s (remain 1m 22s) Loss: 0.1930(0.3373) Grad: 94135.6250  LR: 0.00000275  \n","Epoch: [2][1340/1515] Elapsed 9m 30s (remain 1m 14s) Loss: 0.2417(0.3375) Grad: 262187.2188  LR: 0.00000273  \n","Epoch: [2][1360/1515] Elapsed 9m 39s (remain 1m 5s) Loss: 0.1145(0.3363) Grad: 97634.9141  LR: 0.00000270  \n","Epoch: [2][1380/1515] Elapsed 9m 47s (remain 0m 57s) Loss: 0.1943(0.3362) Grad: 214373.5312  LR: 0.00000267  \n","Epoch: [2][1400/1515] Elapsed 9m 55s (remain 0m 48s) Loss: 0.3590(0.3358) Grad: 76153.4844  LR: 0.00000265  \n","Epoch: [2][1420/1515] Elapsed 10m 3s (remain 0m 39s) Loss: 0.2292(0.3355) Grad: 201298.2031  LR: 0.00000262  \n","Epoch: [2][1440/1515] Elapsed 10m 12s (remain 0m 31s) Loss: 0.4396(0.3358) Grad: 155269.3438  LR: 0.00000260  \n","Epoch: [2][1460/1515] Elapsed 10m 20s (remain 0m 22s) Loss: 0.1930(0.3358) Grad: 245254.6719  LR: 0.00000257  \n","Epoch: [2][1480/1515] Elapsed 10m 29s (remain 0m 14s) Loss: 0.3577(0.3358) Grad: 234936.6562  LR: 0.00000255  \n","Epoch: [2][1500/1515] Elapsed 10m 38s (remain 0m 5s) Loss: 0.2348(0.3360) Grad: 379127.7500  LR: 0.00000252  \n","Epoch: [2][1514/1515] Elapsed 10m 43s (remain 0m 0s) Loss: 0.1817(0.3358) Grad: 153456.4688  LR: 0.00000250  \n","EVAL: [0/138] Elapsed 0m 0s (remain 2m 13s) Loss: 0.5766(0.5766) \n","EVAL: [20/138] Elapsed 0m 12s (remain 1m 8s) Loss: 0.3924(0.4548) \n","EVAL: [40/138] Elapsed 0m 23s (remain 0m 55s) Loss: 0.5261(0.4641) \n","EVAL: [60/138] Elapsed 0m 34s (remain 0m 43s) Loss: 0.3479(0.4510) \n","EVAL: [80/138] Elapsed 0m 45s (remain 0m 32s) Loss: 0.3998(0.4488) \n","EVAL: [100/138] Elapsed 0m 57s (remain 0m 21s) Loss: 0.3968(0.4498) \n","EVAL: [120/138] Elapsed 1m 9s (remain 0m 9s) Loss: 0.2927(0.4484) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3358  avg_val_loss: 0.4502  time: 723s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3358  avg_val_loss: 0.4502  time: 723s\n","Epoch 2 - Score: 0.5909  Scores: [0.49063706703281357, 0.6911610379800536]\n","INFO:__main__:Epoch 2 - Score: 0.5909  Scores: [0.49063706703281357, 0.6911610379800536]\n","Epoch 2 - Save Best Score: 0.5909 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5909 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [137/138] Elapsed 1m 19s (remain 0m 0s) Loss: 0.6126(0.4502) \n","Epoch: [3][0/1515] Elapsed 0m 0s (remain 20m 8s) Loss: 0.1550(0.1550) Grad: inf  LR: 0.00000250  \n","Epoch: [3][20/1515] Elapsed 0m 9s (remain 11m 8s) Loss: 0.2993(0.3417) Grad: 123067.0156  LR: 0.00000247  \n","Epoch: [3][40/1515] Elapsed 0m 18s (remain 10m 48s) Loss: 0.3063(0.3215) Grad: 161034.2031  LR: 0.00000245  \n","Epoch: [3][60/1515] Elapsed 0m 26s (remain 10m 30s) Loss: 0.3846(0.3109) Grad: 218167.7344  LR: 0.00000242  \n","Epoch: [3][80/1515] Elapsed 0m 35s (remain 10m 20s) Loss: 0.2280(0.3142) Grad: 162868.4688  LR: 0.00000240  \n","Epoch: [3][100/1515] Elapsed 0m 43s (remain 10m 10s) Loss: 0.2083(0.3138) Grad: 221295.7812  LR: 0.00000237  \n","Epoch: [3][120/1515] Elapsed 0m 52s (remain 10m 0s) Loss: 0.2978(0.3149) Grad: 173589.9375  LR: 0.00000234  \n","Epoch: [3][140/1515] Elapsed 1m 0s (remain 9m 51s) Loss: 0.3705(0.3138) Grad: 244841.3906  LR: 0.00000232  \n","Epoch: [3][160/1515] Elapsed 1m 9s (remain 9m 44s) Loss: 0.2822(0.3066) Grad: 244807.0312  LR: 0.00000229  \n","Epoch: [3][180/1515] Elapsed 1m 18s (remain 9m 35s) Loss: 0.1685(0.3068) Grad: 246602.5938  LR: 0.00000227  \n","Epoch: [3][200/1515] Elapsed 1m 26s (remain 9m 23s) Loss: 0.5258(0.3083) Grad: 227420.2656  LR: 0.00000224  \n","Epoch: [3][220/1515] Elapsed 1m 34s (remain 9m 15s) Loss: 0.1914(0.3090) Grad: 232115.2344  LR: 0.00000222  \n","Epoch: [3][240/1515] Elapsed 1m 43s (remain 9m 6s) Loss: 0.3310(0.3076) Grad: 214629.2812  LR: 0.00000219  \n","Epoch: [3][260/1515] Elapsed 1m 51s (remain 8m 57s) Loss: 0.3990(0.3061) Grad: 312082.3438  LR: 0.00000216  \n","Epoch: [3][280/1515] Elapsed 2m 0s (remain 8m 48s) Loss: 0.1924(0.3043) Grad: 105448.5469  LR: 0.00000214  \n","Epoch: [3][300/1515] Elapsed 2m 8s (remain 8m 38s) Loss: 0.3689(0.3030) Grad: 271922.9375  LR: 0.00000211  \n","Epoch: [3][320/1515] Elapsed 2m 17s (remain 8m 29s) Loss: 0.3567(0.3022) Grad: 153202.5938  LR: 0.00000209  \n","Epoch: [3][340/1515] Elapsed 2m 25s (remain 8m 21s) Loss: 0.2724(0.3016) Grad: 106235.0781  LR: 0.00000206  \n","Epoch: [3][360/1515] Elapsed 2m 34s (remain 8m 14s) Loss: 0.4004(0.3005) Grad: 310399.0938  LR: 0.00000204  \n","Epoch: [3][380/1515] Elapsed 2m 43s (remain 8m 5s) Loss: 0.4059(0.2989) Grad: 129789.0703  LR: 0.00000201  \n","Epoch: [3][400/1515] Elapsed 2m 51s (remain 7m 57s) Loss: 0.3083(0.2989) Grad: 176461.9844  LR: 0.00000199  \n","Epoch: [3][420/1515] Elapsed 3m 0s (remain 7m 48s) Loss: 0.2625(0.2984) Grad: 113297.7109  LR: 0.00000196  \n","Epoch: [3][440/1515] Elapsed 3m 8s (remain 7m 38s) Loss: 0.3366(0.2973) Grad: 170398.1250  LR: 0.00000193  \n","Epoch: [3][460/1515] Elapsed 3m 17s (remain 7m 30s) Loss: 0.3026(0.2976) Grad: 248381.3125  LR: 0.00000191  \n","Epoch: [3][480/1515] Elapsed 3m 25s (remain 7m 22s) Loss: 0.2800(0.2977) Grad: 186776.1250  LR: 0.00000188  \n","Epoch: [3][500/1515] Elapsed 3m 34s (remain 7m 13s) Loss: 0.3386(0.2993) Grad: 124366.8594  LR: 0.00000186  \n","Epoch: [3][520/1515] Elapsed 3m 42s (remain 7m 4s) Loss: 0.1515(0.2990) Grad: 211181.8125  LR: 0.00000183  \n","Epoch: [3][540/1515] Elapsed 3m 51s (remain 6m 56s) Loss: 0.3467(0.2979) Grad: 317971.7188  LR: 0.00000181  \n","Epoch: [3][560/1515] Elapsed 3m 59s (remain 6m 48s) Loss: 0.3591(0.2991) Grad: 144644.3438  LR: 0.00000178  \n","Epoch: [3][580/1515] Elapsed 4m 8s (remain 6m 39s) Loss: 0.1552(0.2993) Grad: 194061.3281  LR: 0.00000176  \n","Epoch: [3][600/1515] Elapsed 4m 17s (remain 6m 30s) Loss: 0.1916(0.2987) Grad: 307408.2500  LR: 0.00000174  \n","Epoch: [3][620/1515] Elapsed 4m 25s (remain 6m 22s) Loss: 0.2245(0.2992) Grad: 102224.0000  LR: 0.00000171  \n","Epoch: [3][640/1515] Elapsed 4m 34s (remain 6m 14s) Loss: 0.2914(0.2985) Grad: 157274.2344  LR: 0.00000169  \n","Epoch: [3][660/1515] Elapsed 4m 42s (remain 6m 5s) Loss: 0.3648(0.2985) Grad: 89095.4844  LR: 0.00000166  \n","Epoch: [3][680/1515] Elapsed 4m 51s (remain 5m 56s) Loss: 0.2238(0.2977) Grad: 140975.2969  LR: 0.00000164  \n","Epoch: [3][700/1515] Elapsed 5m 0s (remain 5m 48s) Loss: 0.2744(0.2982) Grad: 271807.5312  LR: 0.00000161  \n","Epoch: [3][720/1515] Elapsed 5m 8s (remain 5m 39s) Loss: 0.5162(0.2981) Grad: 134304.9062  LR: 0.00000159  \n","Epoch: [3][740/1515] Elapsed 5m 16s (remain 5m 31s) Loss: 0.3719(0.2976) Grad: 195436.7656  LR: 0.00000156  \n","Epoch: [3][760/1515] Elapsed 5m 25s (remain 5m 22s) Loss: 0.4719(0.2980) Grad: 181678.7656  LR: 0.00000154  \n","Epoch: [3][780/1515] Elapsed 5m 33s (remain 5m 13s) Loss: 0.3259(0.2965) Grad: 215817.6719  LR: 0.00000152  \n","Epoch: [3][800/1515] Elapsed 5m 42s (remain 5m 5s) Loss: 0.1177(0.2970) Grad: 267480.1875  LR: 0.00000149  \n","Epoch: [3][820/1515] Elapsed 5m 50s (remain 4m 56s) Loss: 0.3164(0.2965) Grad: 232384.9062  LR: 0.00000147  \n","Epoch: [3][840/1515] Elapsed 5m 59s (remain 4m 47s) Loss: 0.2520(0.2956) Grad: 346902.8125  LR: 0.00000145  \n","Epoch: [3][860/1515] Elapsed 6m 8s (remain 4m 39s) Loss: 0.3443(0.2961) Grad: 153182.7500  LR: 0.00000142  \n","Epoch: [3][880/1515] Elapsed 6m 16s (remain 4m 30s) Loss: 0.1374(0.2963) Grad: 183416.1094  LR: 0.00000140  \n","Epoch: [3][900/1515] Elapsed 6m 25s (remain 4m 22s) Loss: 0.2635(0.2969) Grad: 94529.1797  LR: 0.00000138  \n","Epoch: [3][920/1515] Elapsed 6m 33s (remain 4m 13s) Loss: 0.2156(0.2967) Grad: 135460.4844  LR: 0.00000135  \n","Epoch: [3][940/1515] Elapsed 6m 42s (remain 4m 5s) Loss: 0.1948(0.2959) Grad: 240516.9531  LR: 0.00000133  \n","Epoch: [3][960/1515] Elapsed 6m 50s (remain 3m 56s) Loss: 0.5316(0.2971) Grad: 268609.5312  LR: 0.00000131  \n","Epoch: [3][980/1515] Elapsed 6m 59s (remain 3m 48s) Loss: 0.2090(0.2969) Grad: 209311.1094  LR: 0.00000128  \n","Epoch: [3][1000/1515] Elapsed 7m 7s (remain 3m 39s) Loss: 0.3609(0.2971) Grad: 195372.6875  LR: 0.00000126  \n","Epoch: [3][1020/1515] Elapsed 7m 16s (remain 3m 31s) Loss: 0.1948(0.2967) Grad: 105530.0156  LR: 0.00000124  \n","Epoch: [3][1040/1515] Elapsed 7m 24s (remain 3m 22s) Loss: 0.1969(0.2971) Grad: 156884.1250  LR: 0.00000122  \n","Epoch: [3][1060/1515] Elapsed 7m 33s (remain 3m 14s) Loss: 0.1904(0.2964) Grad: 150139.4375  LR: 0.00000119  \n","Epoch: [3][1080/1515] Elapsed 7m 41s (remain 3m 5s) Loss: 0.3450(0.2969) Grad: 372487.9688  LR: 0.00000117  \n","Epoch: [3][1100/1515] Elapsed 7m 50s (remain 2m 56s) Loss: 0.3180(0.2976) Grad: 231626.1406  LR: 0.00000115  \n","Epoch: [3][1120/1515] Elapsed 7m 59s (remain 2m 48s) Loss: 0.1335(0.2978) Grad: 147573.4219  LR: 0.00000113  \n","Epoch: [3][1140/1515] Elapsed 8m 7s (remain 2m 39s) Loss: 0.3721(0.2976) Grad: 108198.4609  LR: 0.00000111  \n","Epoch: [3][1160/1515] Elapsed 8m 16s (remain 2m 31s) Loss: 0.2429(0.2974) Grad: 82981.9688  LR: 0.00000109  \n","Epoch: [3][1180/1515] Elapsed 8m 25s (remain 2m 22s) Loss: 0.4560(0.2982) Grad: 318373.2188  LR: 0.00000106  \n","Epoch: [3][1200/1515] Elapsed 8m 33s (remain 2m 14s) Loss: 0.4210(0.2981) Grad: 125257.9062  LR: 0.00000104  \n","Epoch: [3][1220/1515] Elapsed 8m 41s (remain 2m 5s) Loss: 0.2815(0.2979) Grad: 351359.8125  LR: 0.00000102  \n","Epoch: [3][1240/1515] Elapsed 8m 50s (remain 1m 57s) Loss: 0.3367(0.2977) Grad: 192615.9062  LR: 0.00000100  \n","Epoch: [3][1260/1515] Elapsed 8m 58s (remain 1m 48s) Loss: 0.3124(0.2981) Grad: 113582.1719  LR: 0.00000098  \n","Epoch: [3][1280/1515] Elapsed 9m 7s (remain 1m 39s) Loss: 0.3295(0.2987) Grad: 71079.5234  LR: 0.00000096  \n","Epoch: [3][1300/1515] Elapsed 9m 15s (remain 1m 31s) Loss: 0.3286(0.2979) Grad: 282076.0312  LR: 0.00000094  \n","Epoch: [3][1320/1515] Elapsed 9m 23s (remain 1m 22s) Loss: 0.2251(0.2974) Grad: 217160.9844  LR: 0.00000092  \n","Epoch: [3][1340/1515] Elapsed 9m 32s (remain 1m 14s) Loss: 0.2971(0.2964) Grad: 159980.1562  LR: 0.00000090  \n","Epoch: [3][1360/1515] Elapsed 9m 40s (remain 1m 5s) Loss: 0.1962(0.2964) Grad: 269599.7188  LR: 0.00000088  \n","Epoch: [3][1380/1515] Elapsed 9m 49s (remain 0m 57s) Loss: 0.2612(0.2962) Grad: 185185.5938  LR: 0.00000086  \n","Epoch: [3][1400/1515] Elapsed 9m 58s (remain 0m 48s) Loss: 0.2489(0.2962) Grad: 130454.3672  LR: 0.00000084  \n","Epoch: [3][1420/1515] Elapsed 10m 6s (remain 0m 40s) Loss: 0.3403(0.2962) Grad: 109519.6406  LR: 0.00000082  \n","Epoch: [3][1440/1515] Elapsed 10m 15s (remain 0m 31s) Loss: 0.1812(0.2968) Grad: 179993.8594  LR: 0.00000080  \n","Epoch: [3][1460/1515] Elapsed 10m 23s (remain 0m 23s) Loss: 0.1549(0.2966) Grad: 146667.9219  LR: 0.00000078  \n","Epoch: [3][1480/1515] Elapsed 10m 32s (remain 0m 14s) Loss: 0.4039(0.2957) Grad: 153326.2812  LR: 0.00000077  \n","Epoch: [3][1500/1515] Elapsed 10m 40s (remain 0m 5s) Loss: 0.2074(0.2957) Grad: 172892.4688  LR: 0.00000075  \n","Epoch: [3][1514/1515] Elapsed 10m 46s (remain 0m 0s) Loss: 0.2218(0.2955) Grad: 226264.3438  LR: 0.00000073  \n","EVAL: [0/138] Elapsed 0m 0s (remain 2m 15s) Loss: 0.5963(0.5963) \n","EVAL: [20/138] Elapsed 0m 12s (remain 1m 8s) Loss: 0.3949(0.4539) \n","EVAL: [40/138] Elapsed 0m 23s (remain 0m 55s) Loss: 0.5093(0.4714) \n","EVAL: [60/138] Elapsed 0m 34s (remain 0m 43s) Loss: 0.3611(0.4574) \n","EVAL: [80/138] Elapsed 0m 45s (remain 0m 32s) Loss: 0.4168(0.4577) \n","EVAL: [100/138] Elapsed 0m 57s (remain 0m 21s) Loss: 0.4015(0.4594) \n","EVAL: [120/138] Elapsed 1m 9s (remain 0m 9s) Loss: 0.3003(0.4570) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2955  avg_val_loss: 0.4589  time: 726s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2955  avg_val_loss: 0.4589  time: 726s\n","Epoch 3 - Score: 0.6043  Scores: [0.505107575209257, 0.7034044729086261]\n","INFO:__main__:Epoch 3 - Score: 0.6043  Scores: [0.505107575209257, 0.7034044729086261]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [137/138] Elapsed 1m 19s (remain 0m 0s) Loss: 0.6391(0.4589) \n","Epoch: [4][0/1515] Elapsed 0m 0s (remain 19m 58s) Loss: 0.2833(0.2833) Grad: inf  LR: 0.00000073  \n","Epoch: [4][20/1515] Elapsed 0m 9s (remain 10m 42s) Loss: 0.1499(0.2520) Grad: 326217.9062  LR: 0.00000071  \n","Epoch: [4][40/1515] Elapsed 0m 17s (remain 10m 35s) Loss: 0.2483(0.2712) Grad: 175347.5625  LR: 0.00000070  \n","Epoch: [4][60/1515] Elapsed 0m 26s (remain 10m 33s) Loss: 0.1883(0.2583) Grad: 172899.4219  LR: 0.00000068  \n","Epoch: [4][80/1515] Elapsed 0m 35s (remain 10m 25s) Loss: 0.2092(0.2518) Grad: 116701.5469  LR: 0.00000066  \n","Epoch: [4][100/1515] Elapsed 0m 43s (remain 10m 14s) Loss: 0.1376(0.2585) Grad: 151018.1406  LR: 0.00000064  \n","Epoch: [4][120/1515] Elapsed 0m 52s (remain 10m 5s) Loss: 0.3718(0.2641) Grad: 185162.7656  LR: 0.00000063  \n","Epoch: [4][140/1515] Elapsed 1m 1s (remain 9m 55s) Loss: 0.3959(0.2644) Grad: 188688.1094  LR: 0.00000061  \n","Epoch: [4][160/1515] Elapsed 1m 9s (remain 9m 47s) Loss: 0.2058(0.2645) Grad: 155276.7344  LR: 0.00000059  \n","Epoch: [4][180/1515] Elapsed 1m 18s (remain 9m 37s) Loss: 0.3649(0.2644) Grad: 316643.3438  LR: 0.00000058  \n","Epoch: [4][200/1515] Elapsed 1m 26s (remain 9m 27s) Loss: 0.2446(0.2653) Grad: 219608.3281  LR: 0.00000056  \n","Epoch: [4][220/1515] Elapsed 1m 35s (remain 9m 19s) Loss: 0.3413(0.2641) Grad: 129963.6094  LR: 0.00000054  \n","Epoch: [4][240/1515] Elapsed 1m 44s (remain 9m 11s) Loss: 0.1712(0.2639) Grad: 208858.8750  LR: 0.00000053  \n","Epoch: [4][260/1515] Elapsed 1m 53s (remain 9m 2s) Loss: 0.2938(0.2659) Grad: 198498.1094  LR: 0.00000051  \n","Epoch: [4][280/1515] Elapsed 2m 1s (remain 8m 54s) Loss: 0.1962(0.2663) Grad: 160808.6719  LR: 0.00000050  \n","Epoch: [4][300/1515] Elapsed 2m 10s (remain 8m 45s) Loss: 0.1408(0.2678) Grad: 338030.0000  LR: 0.00000048  \n","Epoch: [4][320/1515] Elapsed 2m 18s (remain 8m 36s) Loss: 0.3064(0.2672) Grad: 256235.5469  LR: 0.00000047  \n","Epoch: [4][340/1515] Elapsed 2m 27s (remain 8m 27s) Loss: 0.2227(0.2668) Grad: 169095.5156  LR: 0.00000045  \n","Epoch: [4][360/1515] Elapsed 2m 35s (remain 8m 18s) Loss: 0.1239(0.2659) Grad: 162134.0000  LR: 0.00000044  \n","Epoch: [4][380/1515] Elapsed 2m 44s (remain 8m 8s) Loss: 0.3103(0.2658) Grad: 201356.5469  LR: 0.00000042  \n","Epoch: [4][400/1515] Elapsed 2m 52s (remain 8m 0s) Loss: 0.3030(0.2670) Grad: 83718.0156  LR: 0.00000041  \n","Epoch: [4][420/1515] Elapsed 3m 1s (remain 7m 51s) Loss: 0.1089(0.2668) Grad: 134876.8906  LR: 0.00000039  \n","Epoch: [4][440/1515] Elapsed 3m 9s (remain 7m 42s) Loss: 0.2430(0.2676) Grad: 191664.3750  LR: 0.00000038  \n","Epoch: [4][460/1515] Elapsed 3m 18s (remain 7m 34s) Loss: 0.4446(0.2673) Grad: 161164.2812  LR: 0.00000037  \n","Epoch: [4][480/1515] Elapsed 3m 27s (remain 7m 25s) Loss: 0.1752(0.2663) Grad: 154776.2344  LR: 0.00000035  \n","Epoch: [4][500/1515] Elapsed 3m 35s (remain 7m 16s) Loss: 0.2162(0.2662) Grad: 248954.2969  LR: 0.00000034  \n","Epoch: [4][520/1515] Elapsed 3m 44s (remain 7m 8s) Loss: 0.2470(0.2657) Grad: 180344.9375  LR: 0.00000033  \n","Epoch: [4][540/1515] Elapsed 3m 52s (remain 6m 59s) Loss: 0.3726(0.2663) Grad: 151919.8281  LR: 0.00000031  \n","Epoch: [4][560/1515] Elapsed 4m 1s (remain 6m 50s) Loss: 0.2756(0.2659) Grad: 258783.5625  LR: 0.00000030  \n","Epoch: [4][580/1515] Elapsed 4m 9s (remain 6m 41s) Loss: 0.2983(0.2657) Grad: 141379.4062  LR: 0.00000029  \n","Epoch: [4][600/1515] Elapsed 4m 18s (remain 6m 32s) Loss: 0.3042(0.2653) Grad: 223288.7969  LR: 0.00000028  \n","Epoch: [4][620/1515] Elapsed 4m 27s (remain 6m 24s) Loss: 0.2572(0.2653) Grad: 118866.3281  LR: 0.00000026  \n","Epoch: [4][640/1515] Elapsed 4m 35s (remain 6m 16s) Loss: 0.1458(0.2658) Grad: 394819.8125  LR: 0.00000025  \n","Epoch: [4][660/1515] Elapsed 4m 44s (remain 6m 7s) Loss: 0.1419(0.2656) Grad: 188305.8906  LR: 0.00000024  \n","Epoch: [4][680/1515] Elapsed 4m 52s (remain 5m 58s) Loss: 0.3091(0.2658) Grad: 243730.6719  LR: 0.00000023  \n","Epoch: [4][700/1515] Elapsed 5m 1s (remain 5m 49s) Loss: 0.1706(0.2653) Grad: 141775.5938  LR: 0.00000022  \n","Epoch: [4][720/1515] Elapsed 5m 10s (remain 5m 41s) Loss: 0.2074(0.2648) Grad: 132604.7344  LR: 0.00000021  \n","Epoch: [4][740/1515] Elapsed 5m 18s (remain 5m 33s) Loss: 0.3333(0.2657) Grad: 105476.1562  LR: 0.00000020  \n","Epoch: [4][760/1515] Elapsed 5m 27s (remain 5m 24s) Loss: 0.2077(0.2656) Grad: 133902.8906  LR: 0.00000019  \n","Epoch: [4][780/1515] Elapsed 5m 36s (remain 5m 15s) Loss: 0.0830(0.2653) Grad: 231345.3125  LR: 0.00000018  \n","Epoch: [4][800/1515] Elapsed 5m 44s (remain 5m 7s) Loss: 0.2317(0.2645) Grad: 133335.4531  LR: 0.00000017  \n","Epoch: [4][820/1515] Elapsed 5m 52s (remain 4m 58s) Loss: 0.2636(0.2636) Grad: 191008.2188  LR: 0.00000016  \n","Epoch: [4][840/1515] Elapsed 6m 1s (remain 4m 49s) Loss: 0.3398(0.2636) Grad: 215696.2344  LR: 0.00000015  \n","Epoch: [4][860/1515] Elapsed 6m 10s (remain 4m 41s) Loss: 0.2102(0.2636) Grad: 187204.6406  LR: 0.00000014  \n","Epoch: [4][880/1515] Elapsed 6m 18s (remain 4m 32s) Loss: 0.1727(0.2637) Grad: 98357.2891  LR: 0.00000013  \n","Epoch: [4][900/1515] Elapsed 6m 27s (remain 4m 24s) Loss: 0.4582(0.2638) Grad: 160397.5156  LR: 0.00000013  \n","Epoch: [4][920/1515] Elapsed 6m 35s (remain 4m 15s) Loss: 0.2908(0.2648) Grad: 430727.6562  LR: 0.00000012  \n","Epoch: [4][940/1515] Elapsed 6m 44s (remain 4m 6s) Loss: 0.1504(0.2643) Grad: 151159.4219  LR: 0.00000011  \n","Epoch: [4][960/1515] Elapsed 6m 52s (remain 3m 57s) Loss: 0.2988(0.2646) Grad: 291499.5312  LR: 0.00000010  \n","Epoch: [4][980/1515] Elapsed 7m 0s (remain 3m 48s) Loss: 0.2275(0.2642) Grad: 247843.7344  LR: 0.00000010  \n","Epoch: [4][1000/1515] Elapsed 7m 9s (remain 3m 40s) Loss: 0.3611(0.2638) Grad: 357211.0312  LR: 0.00000009  \n","Epoch: [4][1020/1515] Elapsed 7m 17s (remain 3m 31s) Loss: 0.2561(0.2637) Grad: 207604.4062  LR: 0.00000008  \n","Epoch: [4][1040/1515] Elapsed 7m 26s (remain 3m 23s) Loss: 0.2055(0.2630) Grad: 288648.3438  LR: 0.00000008  \n","Epoch: [4][1060/1515] Elapsed 7m 34s (remain 3m 14s) Loss: 0.1675(0.2624) Grad: 231916.2344  LR: 0.00000007  \n","Epoch: [4][1080/1515] Elapsed 7m 43s (remain 3m 6s) Loss: 0.2201(0.2625) Grad: 101702.9453  LR: 0.00000006  \n","Epoch: [4][1100/1515] Elapsed 7m 51s (remain 2m 57s) Loss: 0.1771(0.2629) Grad: 168076.2031  LR: 0.00000006  \n","Epoch: [4][1120/1515] Elapsed 8m 0s (remain 2m 48s) Loss: 0.3661(0.2633) Grad: 184641.6406  LR: 0.00000005  \n","Epoch: [4][1140/1515] Elapsed 8m 8s (remain 2m 40s) Loss: 0.3918(0.2626) Grad: 267757.0938  LR: 0.00000005  \n","Epoch: [4][1160/1515] Elapsed 8m 17s (remain 2m 31s) Loss: 0.4839(0.2629) Grad: 169759.5000  LR: 0.00000004  \n","Epoch: [4][1180/1515] Elapsed 8m 25s (remain 2m 22s) Loss: 0.2513(0.2632) Grad: 315592.0000  LR: 0.00000004  \n","Epoch: [4][1200/1515] Elapsed 8m 34s (remain 2m 14s) Loss: 0.2534(0.2635) Grad: 151608.1719  LR: 0.00000003  \n","Epoch: [4][1220/1515] Elapsed 8m 42s (remain 2m 5s) Loss: 0.1387(0.2632) Grad: 281934.9062  LR: 0.00000003  \n","Epoch: [4][1240/1515] Elapsed 8m 50s (remain 1m 57s) Loss: 0.3613(0.2627) Grad: 469075.1562  LR: 0.00000003  \n","Epoch: [4][1260/1515] Elapsed 8m 59s (remain 1m 48s) Loss: 0.3373(0.2629) Grad: 160021.6250  LR: 0.00000002  \n","Epoch: [4][1280/1515] Elapsed 9m 7s (remain 1m 40s) Loss: 0.2780(0.2630) Grad: 281840.7188  LR: 0.00000002  \n","Epoch: [4][1300/1515] Elapsed 9m 16s (remain 1m 31s) Loss: 0.7455(0.2630) Grad: 209941.2812  LR: 0.00000002  \n","Epoch: [4][1320/1515] Elapsed 9m 24s (remain 1m 22s) Loss: 0.2667(0.2625) Grad: 97447.1484  LR: 0.00000001  \n","Epoch: [4][1340/1515] Elapsed 9m 33s (remain 1m 14s) Loss: 0.0621(0.2625) Grad: 95612.4219  LR: 0.00000001  \n","Epoch: [4][1360/1515] Elapsed 9m 41s (remain 1m 5s) Loss: 0.1889(0.2628) Grad: 149545.5156  LR: 0.00000001  \n","Epoch: [4][1380/1515] Elapsed 9m 50s (remain 0m 57s) Loss: 0.3533(0.2631) Grad: 146915.0000  LR: 0.00000001  \n","Epoch: [4][1400/1515] Elapsed 9m 59s (remain 0m 48s) Loss: 0.4307(0.2633) Grad: 157017.6875  LR: 0.00000000  \n","Epoch: [4][1420/1515] Elapsed 10m 7s (remain 0m 40s) Loss: 0.2229(0.2633) Grad: 93919.4141  LR: 0.00000000  \n","Epoch: [4][1440/1515] Elapsed 10m 16s (remain 0m 31s) Loss: 0.1129(0.2627) Grad: 122063.6562  LR: 0.00000000  \n","Epoch: [4][1460/1515] Elapsed 10m 24s (remain 0m 23s) Loss: 0.2538(0.2629) Grad: 106382.8281  LR: 0.00000000  \n","Epoch: [4][1480/1515] Elapsed 10m 32s (remain 0m 14s) Loss: 0.1867(0.2626) Grad: 329428.1875  LR: 0.00000000  \n","Epoch: [4][1500/1515] Elapsed 10m 40s (remain 0m 5s) Loss: 0.3161(0.2625) Grad: 182193.4062  LR: 0.00000000  \n","Epoch: [4][1514/1515] Elapsed 10m 46s (remain 0m 0s) Loss: 0.1437(0.2623) Grad: 310546.1250  LR: 0.00000000  \n","EVAL: [0/138] Elapsed 0m 0s (remain 2m 15s) Loss: 0.5482(0.5482) \n","EVAL: [20/138] Elapsed 0m 12s (remain 1m 8s) Loss: 0.3869(0.4318) \n","EVAL: [40/138] Elapsed 0m 23s (remain 0m 55s) Loss: 0.4557(0.4412) \n","EVAL: [60/138] Elapsed 0m 34s (remain 0m 43s) Loss: 0.2919(0.4256) \n","EVAL: [80/138] Elapsed 0m 45s (remain 0m 32s) Loss: 0.4039(0.4241) \n","EVAL: [100/138] Elapsed 0m 57s (remain 0m 21s) Loss: 0.3239(0.4249) \n","EVAL: [120/138] Elapsed 1m 9s (remain 0m 9s) Loss: 0.3044(0.4239) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2623  avg_val_loss: 0.4256  time: 726s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2623  avg_val_loss: 0.4256  time: 726s\n","Epoch 4 - Score: 0.5603  Scores: [0.4889781275212197, 0.631637156143467]\n","INFO:__main__:Epoch 4 - Score: 0.5603  Scores: [0.4889781275212197, 0.631637156143467]\n","Epoch 4 - Save Best Score: 0.5603 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.5603 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [137/138] Elapsed 1m 19s (remain 0m 0s) Loss: 0.5669(0.4256) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 3 result ==========\n"]}]},{"cell_type":"code","source":["labels = oof_df[CFG.target_cols].values\n","preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n","score, scores = get_score(labels, preds)\n","print(f'Score: {score:<.4f}  Scores: {scores}')"],"metadata":{"id":"T0Lm0o28OX3g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["runtime.unassign()"],"metadata":{"id":"Hyij14sOkLv8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"R8hQaR0TZMBv"},"execution_count":null,"outputs":[]}]}