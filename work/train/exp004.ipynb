{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyNrtkMzMNsivCb/o559Z9Us"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2e1ec280cdb94d549caa3966bc239038":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52d344d4d57c441ca8ba3b0c61cf976a","IPY_MODEL_9df31ef5c460490b81ce2572851806ce","IPY_MODEL_7b0b530133c044d493b67018a1165dc9"],"layout":"IPY_MODEL_eb4f8a21eca045bca6adced4fcaf45c5"}},"52d344d4d57c441ca8ba3b0c61cf976a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9de4582a6e044929a5522d5ce82a0855","placeholder":"​","style":"IPY_MODEL_e98a38efbcf548558b760cbc542a57a0","value":"Downloading tokenizer_config.json: 100%"}},"9df31ef5c460490b81ce2572851806ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c5a13c0c6cf48e593951ab110116b91","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c382df45b70243c4948daea54a8905a8","value":52}},"7b0b530133c044d493b67018a1165dc9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a1b2adde2714486bd18805aac77422a","placeholder":"​","style":"IPY_MODEL_8e3ff99c098c4a84ae37c631e3b579e6","value":" 52.0/52.0 [00:00&lt;00:00, 2.25kB/s]"}},"eb4f8a21eca045bca6adced4fcaf45c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9de4582a6e044929a5522d5ce82a0855":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e98a38efbcf548558b760cbc542a57a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c5a13c0c6cf48e593951ab110116b91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c382df45b70243c4948daea54a8905a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a1b2adde2714486bd18805aac77422a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e3ff99c098c4a84ae37c631e3b579e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4450b66ac6444829be7772788e402e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf54219a5a3940878a9b7a71efe98499","IPY_MODEL_aca99e761ff440ae879ca4d99242499c","IPY_MODEL_2398a3a7901f43c4a02d1ede33758723"],"layout":"IPY_MODEL_8074fd02dc124487923cbd17477b15aa"}},"cf54219a5a3940878a9b7a71efe98499":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_737c972d5e254c48946b3e8c1536d321","placeholder":"​","style":"IPY_MODEL_0d06117f6dac4a0ba3818af856d7ad1d","value":"Downloading config.json: 100%"}},"aca99e761ff440ae879ca4d99242499c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4efdc48966064364bda1a143e34ab444","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2a243054141c4703924bd39020390e66","value":579}},"2398a3a7901f43c4a02d1ede33758723":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d9221688acc4d719afb8e134c934b2b","placeholder":"​","style":"IPY_MODEL_bf94844f667d4136b04e07acd6fd7307","value":" 579/579 [00:00&lt;00:00, 32.2kB/s]"}},"8074fd02dc124487923cbd17477b15aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"737c972d5e254c48946b3e8c1536d321":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d06117f6dac4a0ba3818af856d7ad1d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4efdc48966064364bda1a143e34ab444":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a243054141c4703924bd39020390e66":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3d9221688acc4d719afb8e134c934b2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf94844f667d4136b04e07acd6fd7307":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d1eb8e539664548bf1d674f2e9f6d1e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_619c711a3f92437696e236b8d5b6ac92","IPY_MODEL_c4ed94f92a44401bb71a9b6bac6073a1","IPY_MODEL_7c2b5a1931834005ba17f4d6e0ad5847"],"layout":"IPY_MODEL_7db1732df81d4f1eab6e42be8cf8eaf6"}},"619c711a3f92437696e236b8d5b6ac92":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7b19a7b2bb94e97af7ba745d7ab8e4b","placeholder":"​","style":"IPY_MODEL_42e47054ab8e4434ad5d21cb388836ec","value":"Downloading spm.model: 100%"}},"c4ed94f92a44401bb71a9b6bac6073a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eafa4bdee8f444b3bd4e2abbdcf67aee","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66687d2f45d04d96bac7f3ed57bf3888","value":2464616}},"7c2b5a1931834005ba17f4d6e0ad5847":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_00f4b31d391b4675a114ed1c24438690","placeholder":"​","style":"IPY_MODEL_c8f8e652d2a3427aae149948ca890c0b","value":" 2.35M/2.35M [00:00&lt;00:00, 31.3MB/s]"}},"7db1732df81d4f1eab6e42be8cf8eaf6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7b19a7b2bb94e97af7ba745d7ab8e4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42e47054ab8e4434ad5d21cb388836ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eafa4bdee8f444b3bd4e2abbdcf67aee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66687d2f45d04d96bac7f3ed57bf3888":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"00f4b31d391b4675a114ed1c24438690":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8f8e652d2a3427aae149948ca890c0b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c073e94048ac48b097417cc3185492a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_684058f41f734f52850a007092c5ca26","IPY_MODEL_cd531bebd36848fdaa5ce888298ba574","IPY_MODEL_c351cce51dd84ec49fdf0660470d1dad"],"layout":"IPY_MODEL_63959f0b3fe84f83bb60c413331f93a1"}},"684058f41f734f52850a007092c5ca26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_844a93f648da486787f24319036fce8d","placeholder":"​","style":"IPY_MODEL_0f7bb5a7bb9a4c6190d470dd2c536419","value":"Downloading pytorch_model.bin: 100%"}},"cd531bebd36848fdaa5ce888298ba574":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d231006c6714558ac7f207bf16bf2ec","max":371146213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f151bb201db4f12badb38a913e4f840","value":371146213}},"c351cce51dd84ec49fdf0660470d1dad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0005ca703b5e459c91195360e7dd04e7","placeholder":"​","style":"IPY_MODEL_501631c9f0da4fdd8c88a2a358cc3289","value":" 354M/354M [00:14&lt;00:00, 37.0MB/s]"}},"63959f0b3fe84f83bb60c413331f93a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"844a93f648da486787f24319036fce8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f7bb5a7bb9a4c6190d470dd2c536419":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d231006c6714558ac7f207bf16bf2ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f151bb201db4f12badb38a913e4f840":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0005ca703b5e459c91195360e7dd04e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"501631c9f0da4fdd8c88a2a358cc3289":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rr85FWn_hyin","executionInfo":{"status":"ok","timestamp":1696001437189,"user_tz":-540,"elapsed":22487,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"6e7db96f-e35f-4d33-9638-3666478763de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install datasets\n","!pip install sentencepiece\n","!pip install transformers==4.21.2\n","!pip install tokenizers==0.12.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ELMmTK3h2by","executionInfo":{"status":"ok","timestamp":1696001467128,"user_tz":-540,"elapsed":29942,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"45816c86-e5ed-4228-a6d7-ac038592142c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-2.14.5-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.6/519.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n","Successfully installed datasets-2.14.5 dill-0.3.7 huggingface-hub-0.17.3 multiprocess-0.70.15 xxhash-3.3.0\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Collecting transformers==4.21.2\n","  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (0.17.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.21.2)\n","  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.2) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.2) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.21.2) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.21.2) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.21.2) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.21.2) (2023.7.22)\n","Installing collected packages: tokenizers, transformers\n","Successfully installed tokenizers-0.12.1 transformers-4.21.2\n","Requirement already satisfied: tokenizers==0.12.1 in /usr/local/lib/python3.10/dist-packages (0.12.1)\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mHhBDONhh4Aa","executionInfo":{"status":"ok","timestamp":1696001468013,"user_tz":-540,"elapsed":893,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"4c6b92b0-e7e3-4e6e-e4da-08d4e6d21159"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Sep 29 15:31:06 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    23W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    apex=True\n","    print_freq=20\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-base\"\n","    gradient_checkpointing=True\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=4\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=8\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    target_size=2\n","    fc_dropout=0.2\n","    target_cols=['content','wording']\n","    seed=42\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    train=True\n","    freezing=False\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"],"metadata":{"id":"1DXnDEPnh58g","executionInfo":{"status":"ok","timestamp":1696001468014,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","DIR = '/content/drive/MyDrive/Competitions/Kaggle/Commonlit'\n","INPUT_DIR = os.path.join(DIR,'input')\n","OUTPUT_DIR = os.path.join(DIR,'output')\n","OUTPUT_MODEL_DIR = DIR + '/output/EXP004/'\n","if not os.path.exists(OUTPUT_MODEL_DIR):\n","    os.makedirs(OUTPUT_MODEL_DIR)"],"metadata":{"id":"n8DPRxxZiMQ5","executionInfo":{"status":"ok","timestamp":1696001468632,"user_tz":-540,"elapsed":623,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Library\n","# ====================================================\n","from google.colab import runtime\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","from text_unidecode import unidecode\n","from typing import Dict, List, Tuple\n","import codecs\n","\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW, Optimizer\n","from torch.utils.data import DataLoader, Dataset\n","from torch.autograd.function import InplaceFunction\n","import torch.nn.init as init\n","\n","#os.system('pip uninstall -y transformers')\n","#os.system('pip uninstall -y tokenizers')\n","#os.system('python -m pip install --no-index --find-links=/content/drive/MyDrive/Competitions/Kaggle/FeedBack3/pip_wheel.ipynb transformers')\n","#os.system('python -m pip install --no-index --find-links=/content/drive/MyDrive/Competitions/Kaggle/FeedBack3/pip_wheel.ipynb tokenizers')\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup,get_polynomial_decay_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oeXsVFCtiTfX","executionInfo":{"status":"ok","timestamp":1696001484054,"user_tz":-540,"elapsed":15424,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"64158259-8c55-4b55-eeb8-c508b80edd06"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tokenizers.__version__: 0.12.1\n","transformers.__version__: 4.21.2\n","env: TOKENIZERS_PARALLELISM=true\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# Utils\n","# ====================================================\n","def MCRMSE(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]\n","        y_pred = y_preds[:,i]\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n","\n","\n","def get_score(y_trues, y_preds):\n","    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n","    return mcrmse_score, scores\n","\n","\n","def get_logger(filename=OUTPUT_MODEL_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(seed=CFG.seed)"],"metadata":{"id":"T-pk0LlXiX24","executionInfo":{"status":"ok","timestamp":1696001484054,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","\n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","\n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","\n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","\n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","\n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","\n","        if hasattr(embeddings_path, attr_name):\n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"XJzsTvmkigu5","executionInfo":{"status":"ok","timestamp":1696001484054,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["prompts_train = pd.read_csv(os.path.join(INPUT_DIR,'prompts_train.csv'))\n","summary_train = pd.read_csv(os.path.join(INPUT_DIR,'summaries_train.csv'))\n","\n","print(f\"Prompt Train.shape: {prompts_train.shape}\")\n","display(prompts_train.head())\n","print(f\"Summary Train.shape: {summary_train.shape}\")\n","display(summary_train.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"qoiequW3ikcn","executionInfo":{"status":"ok","timestamp":1696001485662,"user_tz":-540,"elapsed":1620,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"51e12594-46fe-4e46-8e73-092d47dcb27b"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Prompt Train.shape: (4, 4)\n"]},{"output_type":"display_data","data":{"text/plain":["  prompt_id                                    prompt_question               prompt_title                                        prompt_text\n","0    39c16e  Summarize at least 3 elements of an ideal trag...                 On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...\n","1    3b9047  In complete sentences, summarize the structure...  Egyptian Social Structure  Egyptian society was structured like a pyramid...\n","2    814d6b  Summarize how the Third Wave developed over su...             The Third Wave  Background \\r\\nThe Third Wave experiment took ...\n","3    ebad26  Summarize the various ways the factory would u...    Excerpt from The Jungle  With one member trimming beef in a cannery, an..."],"text/html":["\n","  <div id=\"df-dd3bd36e-c87b-4ac3-9d41-ee936113c935\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt_id</th>\n","      <th>prompt_question</th>\n","      <th>prompt_title</th>\n","      <th>prompt_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3b9047</td>\n","      <td>In complete sentences, summarize the structure...</td>\n","      <td>Egyptian Social Structure</td>\n","      <td>Egyptian society was structured like a pyramid...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>814d6b</td>\n","      <td>Summarize how the Third Wave developed over su...</td>\n","      <td>The Third Wave</td>\n","      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ebad26</td>\n","      <td>Summarize the various ways the factory would u...</td>\n","      <td>Excerpt from The Jungle</td>\n","      <td>With one member trimming beef in a cannery, an...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd3bd36e-c87b-4ac3-9d41-ee936113c935')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-dd3bd36e-c87b-4ac3-9d41-ee936113c935 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-dd3bd36e-c87b-4ac3-9d41-ee936113c935');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-75aa50f1-f2ff-4bfb-a610-eba54e3518a9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75aa50f1-f2ff-4bfb-a610-eba54e3518a9')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-75aa50f1-f2ff-4bfb-a610-eba54e3518a9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Summary Train.shape: (7165, 5)\n"]},{"output_type":"display_data","data":{"text/plain":["     student_id prompt_id                                               text   content   wording\n","0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...  0.205683  0.380538\n","1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme... -0.548304  0.506755\n","2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...  3.128928  4.231226\n","3  005ab0199905    3b9047  The highest class was Pharaohs these people we... -0.210614 -0.471415\n","4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...  3.272894  3.219757"],"text/html":["\n","  <div id=\"df-75158237-5059-412b-be5d-3eb2df82c422\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>prompt_id</th>\n","      <th>text</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000e8c3c7ddb</td>\n","      <td>814d6b</td>\n","      <td>The third wave was an experimentto see how peo...</td>\n","      <td>0.205683</td>\n","      <td>0.380538</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0020ae56ffbf</td>\n","      <td>ebad26</td>\n","      <td>They would rub it up with soda to make the sme...</td>\n","      <td>-0.548304</td>\n","      <td>0.506755</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>004e978e639e</td>\n","      <td>3b9047</td>\n","      <td>In Egypt, there were many occupations and soci...</td>\n","      <td>3.128928</td>\n","      <td>4.231226</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>005ab0199905</td>\n","      <td>3b9047</td>\n","      <td>The highest class was Pharaohs these people we...</td>\n","      <td>-0.210614</td>\n","      <td>-0.471415</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0070c9e7af47</td>\n","      <td>814d6b</td>\n","      <td>The Third Wave developed  rapidly because the ...</td>\n","      <td>3.272894</td>\n","      <td>3.219757</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75158237-5059-412b-be5d-3eb2df82c422')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-75158237-5059-412b-be5d-3eb2df82c422 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-75158237-5059-412b-be5d-3eb2df82c422');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-e393a14d-0c8b-45d5-b1a0-aa7e9e6f20ee\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e393a14d-0c8b-45d5-b1a0-aa7e9e6f20ee')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-e393a14d-0c8b-45d5-b1a0-aa7e9e6f20ee button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{}}]},{"cell_type":"code","source":["train = prompts_train.merge(summary_train, on=\"prompt_id\")\n","display(train.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"emiPv2lpi1wX","executionInfo":{"status":"ok","timestamp":1696001485663,"user_tz":-540,"elapsed":10,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"b53f9b06-2b1c-402d-9139-fb44a37081e8"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["  prompt_id                                    prompt_question prompt_title                                        prompt_text    student_id                                               text   content   wording\n","0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415\n","1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058\n","2    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...  0094589c7a22  Aristotle states that an ideal tragedy should ... -0.387791 -0.584181\n","3    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...  00cd5736026a  One element of an Ideal tragedy is having a co...  0.088882 -0.594710\n","4    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...  00d98b8ff756  The 3 ideal of tragedy is how complex you need... -0.687288 -0.460886"],"text/html":["\n","  <div id=\"df-6a8b5803-c8f1-402b-bf35-4d9b51df91ed\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt_id</th>\n","      <th>prompt_question</th>\n","      <th>prompt_title</th>\n","      <th>prompt_text</th>\n","      <th>student_id</th>\n","      <th>text</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>00791789cc1f</td>\n","      <td>1 element of an ideal tragedy is that it shoul...</td>\n","      <td>-0.210614</td>\n","      <td>-0.471415</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>0086ef22de8f</td>\n","      <td>The three elements of an ideal tragedy are:  H...</td>\n","      <td>-0.970237</td>\n","      <td>-0.417058</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>0094589c7a22</td>\n","      <td>Aristotle states that an ideal tragedy should ...</td>\n","      <td>-0.387791</td>\n","      <td>-0.584181</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>00cd5736026a</td>\n","      <td>One element of an Ideal tragedy is having a co...</td>\n","      <td>0.088882</td>\n","      <td>-0.594710</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>00d98b8ff756</td>\n","      <td>The 3 ideal of tragedy is how complex you need...</td>\n","      <td>-0.687288</td>\n","      <td>-0.460886</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a8b5803-c8f1-402b-bf35-4d9b51df91ed')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6a8b5803-c8f1-402b-bf35-4d9b51df91ed button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6a8b5803-c8f1-402b-bf35-4d9b51df91ed');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7afa5595-9ee6-468a-831d-678adb21134c\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7afa5595-9ee6-468a-831d-678adb21134c')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7afa5595-9ee6-468a-831d-678adb21134c button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{}}]},{"cell_type":"code","source":["# ====================================================\n","# CV split\n","# ====================================================\n","Fold = GroupKFold(n_splits=CFG.n_fold)\n","for n, (train_index, val_index) in enumerate(Fold.split(train, groups=train[\"prompt_id\"])):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"id":"2oEQGucXi-TM","executionInfo":{"status":"ok","timestamp":1696001485663,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"739cc28e-c0ab-4bb7-e837-df029e45e0e4"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    2057\n","1    2009\n","2    1996\n","3    1103\n","dtype: int64"]},"metadata":{}}]},{"cell_type":"code","source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"],"metadata":{"id":"hPNdK-w2jAJb","executionInfo":{"status":"ok","timestamp":1696001485663,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","# tokenizer.save_pretrained(OUTPUT_MODEL_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["2e1ec280cdb94d549caa3966bc239038","52d344d4d57c441ca8ba3b0c61cf976a","9df31ef5c460490b81ce2572851806ce","7b0b530133c044d493b67018a1165dc9","eb4f8a21eca045bca6adced4fcaf45c5","9de4582a6e044929a5522d5ce82a0855","e98a38efbcf548558b760cbc542a57a0","5c5a13c0c6cf48e593951ab110116b91","c382df45b70243c4948daea54a8905a8","2a1b2adde2714486bd18805aac77422a","8e3ff99c098c4a84ae37c631e3b579e6","f4450b66ac6444829be7772788e402e5","cf54219a5a3940878a9b7a71efe98499","aca99e761ff440ae879ca4d99242499c","2398a3a7901f43c4a02d1ede33758723","8074fd02dc124487923cbd17477b15aa","737c972d5e254c48946b3e8c1536d321","0d06117f6dac4a0ba3818af856d7ad1d","4efdc48966064364bda1a143e34ab444","2a243054141c4703924bd39020390e66","3d9221688acc4d719afb8e134c934b2b","bf94844f667d4136b04e07acd6fd7307","8d1eb8e539664548bf1d674f2e9f6d1e","619c711a3f92437696e236b8d5b6ac92","c4ed94f92a44401bb71a9b6bac6073a1","7c2b5a1931834005ba17f4d6e0ad5847","7db1732df81d4f1eab6e42be8cf8eaf6","e7b19a7b2bb94e97af7ba745d7ab8e4b","42e47054ab8e4434ad5d21cb388836ec","eafa4bdee8f444b3bd4e2abbdcf67aee","66687d2f45d04d96bac7f3ed57bf3888","00f4b31d391b4675a114ed1c24438690","c8f8e652d2a3427aae149948ca890c0b"]},"id":"CNt6YdwtjCHR","executionInfo":{"status":"ok","timestamp":1696001489357,"user_tz":-540,"elapsed":3702,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"0ba11ea3-cd3a-4005-bf6a-6fd038a69883"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e1ec280cdb94d549caa3966bc239038"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4450b66ac6444829be7772788e402e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading spm.model:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d1eb8e539664548bf1d674f2e9f6d1e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["prompt_title = [\n","    'On Tragedy',\n","    'Egyptian Social Structure',\n","    'The Third Wave',\n","    'Excerpt from The Jungle'\n","]\n","cls_tokens_map = {label: f\"[CLS_{label.upper()}]\" for label in prompt_title}\n","end_tokens_map = {label: f\"[END_{label.upper()}]\" for label in prompt_title}\n","tokenizer.add_special_tokens(\n","    {\"additional_special_tokens\": list(cls_tokens_map.values())+list(end_tokens_map.values())}\n",")\n","cls_id_map = {\n","    label: tokenizer.encode(tkn)[1]\n","    for label, tkn in cls_tokens_map.items()\n","}"],"metadata":{"id":"x6R8tj5DjU3T","executionInfo":{"status":"ok","timestamp":1696001489357,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def len2text(x:str):\n","    if len(x)<200: return 'Quite short'\n","    if len(x)<300: return 'Short'\n","    if len(x)<500: return 'Middle'\n","    else:\n","        return 'Long'"],"metadata":{"id":"4-LeEcCMxp0r","executionInfo":{"status":"ok","timestamp":1696001489357,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["train[\"text_length\"] = train['text'].apply(lambda x: len2text(x))\n","SEP = tokenizer.sep_token\n","train['full_text'] = train['prompt_title'] + SEP + train[\"text_length\"] + SEP + train['prompt_question'] + SEP + train['text']"],"metadata":{"id":"4URMsa8ZjZbe","executionInfo":{"status":"ok","timestamp":1696001489357,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer.encode_plus(\n","        text,\n","        return_tensors=None,\n","        add_special_tokens=True,\n","        max_length=CFG.max_len,\n","        pad_to_max_length=True,\n","        truncation=True\n","    )\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['full_text'].values\n","        self.labels = df[cfg.target_cols].values\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs"],"metadata":{"id":"dn-zNJVbja5k","executionInfo":{"status":"ok","timestamp":1696001489358,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        #self.pool = MeanPooling()\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        self._init_weights(self.fc)\n","        self.attention = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, 512),\n","            nn.Tanh(),\n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","        self._init_weights(self.attention)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        weights = self.attention(last_hidden_states)\n","        feature = torch.sum(weights * last_hidden_states, dim=1)\n","        #feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output"],"metadata":{"id":"KIb1arzTjdRR","executionInfo":{"status":"ok","timestamp":1696001489901,"user_tz":-540,"elapsed":546,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Loss\n","# ====================================================\n","class RMSELoss(nn.Module):\n","    def __init__(self, reduction='mean', eps=1e-9):\n","        super().__init__()\n","        self.mse = nn.MSELoss(reduction='none')\n","        self.reduction = reduction\n","        self.eps = eps\n","\n","    def forward(self, y_pred, y_true):\n","        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss"],"metadata":{"id":"fxIJL4WojfSl","executionInfo":{"status":"ok","timestamp":1696001489901,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        #if scaler is not None:\n","        #    scaler.unscale_(optimizer)\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader),\n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    return losses.avg, predictions"],"metadata":{"id":"JSU1PJNIjhKu","executionInfo":{"status":"ok","timestamp":1696001489902,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","\n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target_cols].values\n","\n","    print(f\"========== prompt_id: {valid_folds.prompt_id.unique()} validation ==========\")\n","\n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size * 2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_MODEL_DIR+'config.pth')\n","    model.to(device)\n","\n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr,\n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","\n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","\n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = RMSELoss(reduction=\"mean\") # nn.SmoothL1Loss(reduction='mean')\n","\n","    best_score = np.inf\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","\n","        # scoring\n","        score, scores = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n","\n","        if best_score > score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return valid_folds"],"metadata":{"id":"5_npZ5IWjle3","executionInfo":{"status":"ok","timestamp":1696001489902,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","\n","    def get_result(oof_df):\n","        labels = oof_df[CFG.target_cols].values\n","        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n","        score, scores = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n","\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_MODEL_DIR+'oof_df.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c073e94048ac48b097417cc3185492a3","684058f41f734f52850a007092c5ca26","cd531bebd36848fdaa5ce888298ba574","c351cce51dd84ec49fdf0660470d1dad","63959f0b3fe84f83bb60c413331f93a1","844a93f648da486787f24319036fce8d","0f7bb5a7bb9a4c6190d470dd2c536419","6d231006c6714558ac7f207bf16bf2ec","2f151bb201db4f12badb38a913e4f840","0005ca703b5e459c91195360e7dd04e7","501631c9f0da4fdd8c88a2a358cc3289"]},"id":"oN9JEc3yj-x1","outputId":"0486132b-79cc-4e3c-b6a4-196c707baf79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["========== prompt_id: ['39c16e'] validation ==========\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/354M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c073e94048ac48b097417cc3185492a3"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/638] Elapsed 0m 3s (remain 38m 34s) Loss: 1.0787(1.0787) Grad: inf  LR: 0.00002000  \n","Epoch: [1][20/638] Elapsed 0m 6s (remain 3m 7s) Loss: 0.7830(0.8060) Grad: 107119.1016  LR: 0.00002000  \n","Epoch: [1][40/638] Elapsed 0m 10s (remain 2m 28s) Loss: 0.5049(0.7093) Grad: 18669.7812  LR: 0.00001999  \n","Epoch: [1][60/638] Elapsed 0m 13s (remain 2m 6s) Loss: 0.7573(0.7360) Grad: 131742.1094  LR: 0.00001997  \n","Epoch: [1][80/638] Elapsed 0m 15s (remain 1m 49s) Loss: 0.2470(0.7083) Grad: 57057.6484  LR: 0.00001995  \n","Epoch: [1][100/638] Elapsed 0m 18s (remain 1m 40s) Loss: 0.4739(0.6836) Grad: 79554.0312  LR: 0.00001992  \n","Epoch: [1][120/638] Elapsed 0m 21s (remain 1m 32s) Loss: 0.4988(0.6602) Grad: 55835.1797  LR: 0.00001989  \n","Epoch: [1][140/638] Elapsed 0m 24s (remain 1m 27s) Loss: 0.5879(0.6435) Grad: 66609.8516  LR: 0.00001985  \n","Epoch: [1][160/638] Elapsed 0m 28s (remain 1m 23s) Loss: 0.4867(0.6224) Grad: 109896.9375  LR: 0.00001980  \n","Epoch: [1][180/638] Elapsed 0m 30s (remain 1m 18s) Loss: 0.3640(0.6061) Grad: 57277.0781  LR: 0.00001975  \n","Epoch: [1][200/638] Elapsed 0m 33s (remain 1m 12s) Loss: 0.2750(0.5909) Grad: 138274.5938  LR: 0.00001970  \n","Epoch: [1][220/638] Elapsed 0m 36s (remain 1m 8s) Loss: 0.5473(0.5781) Grad: 64155.5469  LR: 0.00001963  \n","Epoch: [1][240/638] Elapsed 0m 39s (remain 1m 4s) Loss: 0.3968(0.5656) Grad: 53495.4219  LR: 0.00001956  \n","Epoch: [1][260/638] Elapsed 0m 42s (remain 1m 1s) Loss: 0.3157(0.5548) Grad: 83989.8281  LR: 0.00001949  \n","Epoch: [1][280/638] Elapsed 0m 45s (remain 0m 57s) Loss: 0.5738(0.5451) Grad: 54813.4336  LR: 0.00001941  \n","Epoch: [1][300/638] Elapsed 0m 48s (remain 0m 53s) Loss: 0.2680(0.5391) Grad: 62138.4023  LR: 0.00001932  \n","Epoch: [1][320/638] Elapsed 0m 50s (remain 0m 50s) Loss: 0.5628(0.5308) Grad: 93052.9453  LR: 0.00001923  \n","Epoch: [1][340/638] Elapsed 0m 53s (remain 0m 46s) Loss: 0.3853(0.5255) Grad: 59152.7383  LR: 0.00001913  \n","Epoch: [1][360/638] Elapsed 0m 57s (remain 0m 43s) Loss: 0.3738(0.5196) Grad: 60211.4102  LR: 0.00001903  \n","Epoch: [1][380/638] Elapsed 1m 0s (remain 0m 40s) Loss: 0.3963(0.5154) Grad: 67033.3750  LR: 0.00001892  \n","Epoch: [1][400/638] Elapsed 1m 3s (remain 0m 37s) Loss: 0.2258(0.5098) Grad: 23723.1680  LR: 0.00001881  \n","Epoch: [1][420/638] Elapsed 1m 6s (remain 0m 34s) Loss: 0.3731(0.5078) Grad: 40562.9766  LR: 0.00001869  \n","Epoch: [1][440/638] Elapsed 1m 9s (remain 0m 30s) Loss: 0.5307(0.5050) Grad: 40558.1719  LR: 0.00001856  \n","Epoch: [1][460/638] Elapsed 1m 12s (remain 0m 27s) Loss: 0.4863(0.5010) Grad: 50487.7617  LR: 0.00001843  \n","Epoch: [1][480/638] Elapsed 1m 15s (remain 0m 24s) Loss: 0.2535(0.4984) Grad: 62127.3867  LR: 0.00001830  \n","Epoch: [1][500/638] Elapsed 1m 18s (remain 0m 21s) Loss: 0.3660(0.4958) Grad: 94987.0469  LR: 0.00001816  \n","Epoch: [1][520/638] Elapsed 1m 20s (remain 0m 18s) Loss: 0.3885(0.4915) Grad: 112619.5938  LR: 0.00001802  \n","Epoch: [1][540/638] Elapsed 1m 23s (remain 0m 14s) Loss: 0.2978(0.4897) Grad: 54712.9570  LR: 0.00001787  \n","Epoch: [1][560/638] Elapsed 1m 27s (remain 0m 11s) Loss: 0.4838(0.4877) Grad: 87134.0625  LR: 0.00001771  \n","Epoch: [1][580/638] Elapsed 1m 30s (remain 0m 8s) Loss: 0.2217(0.4850) Grad: 78273.5781  LR: 0.00001755  \n","Epoch: [1][600/638] Elapsed 1m 33s (remain 0m 5s) Loss: 0.4972(0.4818) Grad: 48164.5977  LR: 0.00001739  \n","Epoch: [1][620/638] Elapsed 1m 36s (remain 0m 2s) Loss: 0.6253(0.4800) Grad: 58078.2305  LR: 0.00001722  \n","Epoch: [1][637/638] Elapsed 1m 38s (remain 0m 0s) Loss: 0.4925(0.4778) Grad: 55186.2773  LR: 0.00001708  \n","EVAL: [0/129] Elapsed 0m 0s (remain 0m 42s) Loss: 0.3534(0.3534) \n","EVAL: [20/129] Elapsed 0m 2s (remain 0m 12s) Loss: 0.3642(0.3950) \n","EVAL: [40/129] Elapsed 0m 5s (remain 0m 12s) Loss: 0.4688(0.3914) \n","EVAL: [60/129] Elapsed 0m 7s (remain 0m 8s) Loss: 0.3638(0.3907) \n","EVAL: [80/129] Elapsed 0m 9s (remain 0m 5s) Loss: 0.4107(0.3919) \n","EVAL: [100/129] Elapsed 0m 11s (remain 0m 3s) Loss: 0.4853(0.3902) \n","EVAL: [120/129] Elapsed 0m 13s (remain 0m 0s) Loss: 0.3281(0.3892) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.4778  avg_val_loss: 0.3865  time: 112s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4778  avg_val_loss: 0.3865  time: 112s\n","Epoch 1 - Score: 0.4975  Scores: [0.4211151739567935, 0.5739405553485939]\n","INFO:__main__:Epoch 1 - Score: 0.4975  Scores: [0.4211151739567935, 0.5739405553485939]\n","Epoch 1 - Save Best Score: 0.4975 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4975 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Elapsed 0m 13s (remain 0m 0s) Loss: 0.3759(0.3865) \n","Epoch: [2][0/638] Elapsed 0m 0s (remain 4m 8s) Loss: 0.4514(0.4514) Grad: 327608.1250  LR: 0.00001707  \n","Epoch: [2][20/638] Elapsed 0m 3s (remain 1m 43s) Loss: 0.3768(0.3577) Grad: 50675.5938  LR: 0.00001689  \n","Epoch: [2][40/638] Elapsed 0m 7s (remain 1m 42s) Loss: 0.2426(0.3368) Grad: 49984.9414  LR: 0.00001671  \n","Epoch: [2][60/638] Elapsed 0m 10s (remain 1m 38s) Loss: 0.4445(0.3519) Grad: 48312.1328  LR: 0.00001653  \n","Epoch: [2][80/638] Elapsed 0m 13s (remain 1m 33s) Loss: 0.2835(0.3440) Grad: 52430.6719  LR: 0.00001634  \n","Epoch: [2][100/638] Elapsed 0m 16s (remain 1m 30s) Loss: 0.2072(0.3472) Grad: 50460.5391  LR: 0.00001615  \n","Epoch: [2][120/638] Elapsed 0m 20s (remain 1m 29s) Loss: 0.3149(0.3494) Grad: 44646.2383  LR: 0.00001595  \n","Epoch: [2][140/638] Elapsed 0m 24s (remain 1m 24s) Loss: 0.4141(0.3509) Grad: 45635.1172  LR: 0.00001575  \n","Epoch: [2][160/638] Elapsed 0m 26s (remain 1m 19s) Loss: 0.3110(0.3546) Grad: 83432.8828  LR: 0.00001555  \n","Epoch: [2][180/638] Elapsed 0m 29s (remain 1m 15s) Loss: 0.2874(0.3557) Grad: 90655.7422  LR: 0.00001534  \n","Epoch: [2][200/638] Elapsed 0m 32s (remain 1m 10s) Loss: 0.2021(0.3584) Grad: 36440.5703  LR: 0.00001513  \n","Epoch: [2][220/638] Elapsed 0m 35s (remain 1m 7s) Loss: 0.3673(0.3578) Grad: 49904.1758  LR: 0.00001492  \n","Epoch: [2][240/638] Elapsed 0m 39s (remain 1m 4s) Loss: 0.4086(0.3581) Grad: 75278.3047  LR: 0.00001470  \n","Epoch: [2][260/638] Elapsed 0m 41s (remain 1m 0s) Loss: 0.3777(0.3578) Grad: 43543.0156  LR: 0.00001448  \n","Epoch: [2][280/638] Elapsed 0m 44s (remain 0m 56s) Loss: 0.3406(0.3567) Grad: 39771.1797  LR: 0.00001426  \n","Epoch: [2][300/638] Elapsed 0m 46s (remain 0m 52s) Loss: 0.4452(0.3558) Grad: 70491.0781  LR: 0.00001404  \n","Epoch: [2][320/638] Elapsed 0m 49s (remain 0m 49s) Loss: 0.3429(0.3565) Grad: 37361.1016  LR: 0.00001381  \n","Epoch: [2][340/638] Elapsed 0m 53s (remain 0m 46s) Loss: 0.4744(0.3576) Grad: 104442.2969  LR: 0.00001358  \n","Epoch: [2][360/638] Elapsed 0m 56s (remain 0m 43s) Loss: 0.4646(0.3572) Grad: 37982.9727  LR: 0.00001335  \n","Epoch: [2][380/638] Elapsed 0m 59s (remain 0m 39s) Loss: 0.2755(0.3569) Grad: 75399.9531  LR: 0.00001312  \n","Epoch: [2][400/638] Elapsed 1m 1s (remain 0m 36s) Loss: 0.3037(0.3561) Grad: 70201.6719  LR: 0.00001289  \n","Epoch: [2][420/638] Elapsed 1m 4s (remain 0m 33s) Loss: 0.4798(0.3569) Grad: 53105.2109  LR: 0.00001265  \n","Epoch: [2][440/638] Elapsed 1m 8s (remain 0m 30s) Loss: 0.2938(0.3567) Grad: 38040.7227  LR: 0.00001241  \n","Epoch: [2][460/638] Elapsed 1m 11s (remain 0m 27s) Loss: 0.3182(0.3574) Grad: 45454.0391  LR: 0.00001217  \n","Epoch: [2][480/638] Elapsed 1m 13s (remain 0m 24s) Loss: 0.3886(0.3563) Grad: 98530.3984  LR: 0.00001193  \n","Epoch: [2][500/638] Elapsed 1m 16s (remain 0m 20s) Loss: 0.3662(0.3560) Grad: 33609.5977  LR: 0.00001169  \n","Epoch: [2][520/638] Elapsed 1m 19s (remain 0m 17s) Loss: 0.3993(0.3568) Grad: 68419.6406  LR: 0.00001145  \n","Epoch: [2][540/638] Elapsed 1m 22s (remain 0m 14s) Loss: 0.2858(0.3577) Grad: 68527.8594  LR: 0.00001120  \n","Epoch: [2][560/638] Elapsed 1m 26s (remain 0m 11s) Loss: 0.4139(0.3587) Grad: 60765.2148  LR: 0.00001096  \n","Epoch: [2][580/638] Elapsed 1m 28s (remain 0m 8s) Loss: 0.2347(0.3576) Grad: 45312.9453  LR: 0.00001071  \n","Epoch: [2][600/638] Elapsed 1m 31s (remain 0m 5s) Loss: 0.4266(0.3586) Grad: 57125.2617  LR: 0.00001047  \n","Epoch: [2][620/638] Elapsed 1m 34s (remain 0m 2s) Loss: 0.3234(0.3579) Grad: 75955.1016  LR: 0.00001022  \n","Epoch: [2][637/638] Elapsed 1m 36s (remain 0m 0s) Loss: 0.3363(0.3574) Grad: 29246.9707  LR: 0.00001001  \n","EVAL: [0/129] Elapsed 0m 0s (remain 1m 2s) Loss: 0.5167(0.5167) \n","EVAL: [20/129] Elapsed 0m 2s (remain 0m 14s) Loss: 0.4604(0.4816) \n","EVAL: [40/129] Elapsed 0m 4s (remain 0m 9s) Loss: 0.5142(0.4725) \n","EVAL: [60/129] Elapsed 0m 6s (remain 0m 7s) Loss: 0.4608(0.4760) \n","EVAL: [80/129] Elapsed 0m 8s (remain 0m 5s) Loss: 0.5198(0.4743) \n","EVAL: [100/129] Elapsed 0m 10s (remain 0m 2s) Loss: 0.5461(0.4732) \n","EVAL: [120/129] Elapsed 0m 11s (remain 0m 0s) Loss: 0.4831(0.4726) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3574  avg_val_loss: 0.4699  time: 110s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3574  avg_val_loss: 0.4699  time: 110s\n","Epoch 2 - Score: 0.5935  Scores: [0.43652665480696307, 0.7505288294886733]\n","INFO:__main__:Epoch 2 - Score: 0.5935  Scores: [0.43652665480696307, 0.7505288294886733]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Elapsed 0m 12s (remain 0m 0s) Loss: 0.5180(0.4699) \n","Epoch: [3][0/638] Elapsed 0m 0s (remain 3m 55s) Loss: 0.3567(0.3567) Grad: inf  LR: 0.00001000  \n","Epoch: [3][20/638] Elapsed 0m 3s (remain 1m 44s) Loss: 0.2848(0.3111) Grad: inf  LR: 0.00000975  \n","Epoch: [3][40/638] Elapsed 0m 7s (remain 1m 45s) Loss: 0.2912(0.3169) Grad: 58382.3320  LR: 0.00000951  \n","Epoch: [3][60/638] Elapsed 0m 9s (remain 1m 34s) Loss: 0.3140(0.3196) Grad: 46249.4688  LR: 0.00000926  \n","Epoch: [3][80/638] Elapsed 0m 12s (remain 1m 26s) Loss: 0.4328(0.3180) Grad: 70255.2344  LR: 0.00000902  \n","Epoch: [3][100/638] Elapsed 0m 15s (remain 1m 22s) Loss: 0.2617(0.3174) Grad: 55582.2852  LR: 0.00000877  \n","Epoch: [3][120/638] Elapsed 0m 18s (remain 1m 18s) Loss: 0.4246(0.3146) Grad: 85558.2188  LR: 0.00000853  \n","Epoch: [3][140/638] Elapsed 0m 21s (remain 1m 17s) Loss: 0.4293(0.3125) Grad: 70511.3047  LR: 0.00000829  \n","Epoch: [3][160/638] Elapsed 0m 25s (remain 1m 14s) Loss: 0.2553(0.3137) Grad: 60723.4219  LR: 0.00000804  \n","Epoch: [3][180/638] Elapsed 0m 27s (remain 1m 10s) Loss: 0.2281(0.3142) Grad: 76406.7266  LR: 0.00000780  \n","Epoch: [3][200/638] Elapsed 0m 30s (remain 1m 6s) Loss: 0.3395(0.3107) Grad: 49566.6680  LR: 0.00000756  \n","Epoch: [3][220/638] Elapsed 0m 33s (remain 1m 2s) Loss: 0.2526(0.3104) Grad: 81691.9297  LR: 0.00000733  \n","Epoch: [3][240/638] Elapsed 0m 36s (remain 1m 0s) Loss: 0.2740(0.3126) Grad: 62140.8359  LR: 0.00000709  \n","Epoch: [3][260/638] Elapsed 0m 40s (remain 0m 57s) Loss: 0.5014(0.3162) Grad: 45966.0586  LR: 0.00000686  \n","Epoch: [3][280/638] Elapsed 0m 42s (remain 0m 54s) Loss: 0.3632(0.3153) Grad: 53844.4922  LR: 0.00000662  \n","Epoch: [3][300/638] Elapsed 0m 45s (remain 0m 50s) Loss: 0.3754(0.3142) Grad: 62899.9570  LR: 0.00000639  \n","Epoch: [3][320/638] Elapsed 0m 48s (remain 0m 47s) Loss: 0.4951(0.3135) Grad: 60397.4766  LR: 0.00000616  \n","Epoch: [3][340/638] Elapsed 0m 51s (remain 0m 45s) Loss: 0.3287(0.3133) Grad: 36209.8359  LR: 0.00000594  \n","Epoch: [3][360/638] Elapsed 0m 55s (remain 0m 42s) Loss: 0.3038(0.3122) Grad: 43803.8789  LR: 0.00000572  \n","Epoch: [3][380/638] Elapsed 0m 58s (remain 0m 39s) Loss: 0.3480(0.3138) Grad: 52108.3242  LR: 0.00000549  \n","Epoch: [3][400/638] Elapsed 1m 0s (remain 0m 35s) Loss: 0.2296(0.3125) Grad: 39570.3125  LR: 0.00000528  \n","Epoch: [3][420/638] Elapsed 1m 3s (remain 0m 32s) Loss: 0.2721(0.3118) Grad: 36537.3945  LR: 0.00000506  \n","Epoch: [3][440/638] Elapsed 1m 7s (remain 0m 30s) Loss: 0.4765(0.3117) Grad: 77716.0312  LR: 0.00000485  \n","Epoch: [3][460/638] Elapsed 1m 10s (remain 0m 27s) Loss: 0.1839(0.3107) Grad: 63909.6055  LR: 0.00000464  \n","Epoch: [3][480/638] Elapsed 1m 13s (remain 0m 23s) Loss: 0.3001(0.3099) Grad: 30814.8574  LR: 0.00000443  \n","Epoch: [3][500/638] Elapsed 1m 15s (remain 0m 20s) Loss: 0.2702(0.3093) Grad: 44776.4336  LR: 0.00000423  \n","Epoch: [3][520/638] Elapsed 1m 18s (remain 0m 17s) Loss: 0.3270(0.3092) Grad: 55170.3516  LR: 0.00000403  \n","Epoch: [3][540/638] Elapsed 1m 22s (remain 0m 14s) Loss: 0.2404(0.3094) Grad: 64924.4414  LR: 0.00000384  \n","Epoch: [3][560/638] Elapsed 1m 25s (remain 0m 11s) Loss: 0.3773(0.3089) Grad: 34851.4922  LR: 0.00000364  \n","Epoch: [3][580/638] Elapsed 1m 28s (remain 0m 8s) Loss: 0.2985(0.3080) Grad: 46183.7578  LR: 0.00000346  \n","Epoch: [3][600/638] Elapsed 1m 30s (remain 0m 5s) Loss: 0.2724(0.3069) Grad: 49412.8086  LR: 0.00000327  \n","Epoch: [3][620/638] Elapsed 1m 33s (remain 0m 2s) Loss: 0.2590(0.3058) Grad: 101525.5859  LR: 0.00000309  \n","Epoch: [3][637/638] Elapsed 1m 35s (remain 0m 0s) Loss: 0.2641(0.3056) Grad: 60443.6016  LR: 0.00000294  \n","EVAL: [0/129] Elapsed 0m 0s (remain 1m 2s) Loss: 0.3248(0.3248) \n","EVAL: [20/129] Elapsed 0m 2s (remain 0m 14s) Loss: 0.3595(0.3865) \n","EVAL: [40/129] Elapsed 0m 4s (remain 0m 10s) Loss: 0.4381(0.3841) \n","EVAL: [60/129] Elapsed 0m 6s (remain 0m 7s) Loss: 0.3531(0.3852) \n","EVAL: [80/129] Elapsed 0m 8s (remain 0m 5s) Loss: 0.3973(0.3857) \n","EVAL: [100/129] Elapsed 0m 10s (remain 0m 2s) Loss: 0.4866(0.3851) \n","EVAL: [120/129] Elapsed 0m 12s (remain 0m 0s) Loss: 0.3231(0.3854) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3056  avg_val_loss: 0.3830  time: 109s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3056  avg_val_loss: 0.3830  time: 109s\n","Epoch 3 - Score: 0.4969  Scores: [0.43226335132604904, 0.5616051054571688]\n","INFO:__main__:Epoch 3 - Score: 0.4969  Scores: [0.43226335132604904, 0.5616051054571688]\n","Epoch 3 - Save Best Score: 0.4969 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4969 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Elapsed 0m 12s (remain 0m 0s) Loss: 0.3585(0.3830) \n","Epoch: [4][0/638] Elapsed 0m 0s (remain 6m 48s) Loss: 0.2865(0.2865) Grad: inf  LR: 0.00000293  \n","Epoch: [4][20/638] Elapsed 0m 4s (remain 2m 4s) Loss: 0.2531(0.2741) Grad: 163347.5156  LR: 0.00000276  \n","Epoch: [4][40/638] Elapsed 0m 7s (remain 1m 43s) Loss: 0.4168(0.2742) Grad: 109716.1641  LR: 0.00000259  \n","Epoch: [4][60/638] Elapsed 0m 10s (remain 1m 39s) Loss: 0.3674(0.2706) Grad: 53487.7695  LR: 0.00000243  \n","Epoch: [4][80/638] Elapsed 0m 13s (remain 1m 34s) Loss: 0.3385(0.2661) Grad: 35690.5625  LR: 0.00000227  \n","Epoch: [4][100/638] Elapsed 0m 17s (remain 1m 34s) Loss: 0.3454(0.2639) Grad: 89470.2656  LR: 0.00000212  \n","Epoch: [4][120/638] Elapsed 0m 21s (remain 1m 32s) Loss: 0.4037(0.2644) Grad: 37104.2422  LR: 0.00000197  \n","Epoch: [4][140/638] Elapsed 0m 24s (remain 1m 26s) Loss: 0.2952(0.2656) Grad: 59815.5430  LR: 0.00000183  \n","Epoch: [4][160/638] Elapsed 0m 27s (remain 1m 20s) Loss: 0.1767(0.2622) Grad: 44303.7461  LR: 0.00000169  \n","Epoch: [4][180/638] Elapsed 0m 29s (remain 1m 15s) Loss: 0.2719(0.2639) Grad: 78656.8828  LR: 0.00000155  \n","Epoch: [4][200/638] Elapsed 0m 33s (remain 1m 11s) Loss: 0.3577(0.2667) Grad: 61041.5977  LR: 0.00000142  \n","Epoch: [4][220/638] Elapsed 0m 36s (remain 1m 8s) Loss: 0.3176(0.2662) Grad: 61651.1523  LR: 0.00000130  \n","Epoch: [4][240/638] Elapsed 0m 39s (remain 1m 4s) Loss: 0.2696(0.2664) Grad: 56020.6758  LR: 0.00000118  \n","Epoch: [4][260/638] Elapsed 0m 41s (remain 1m 0s) Loss: 0.1594(0.2668) Grad: 61546.0234  LR: 0.00000107  \n","Epoch: [4][280/638] Elapsed 0m 44s (remain 0m 56s) Loss: 0.1440(0.2655) Grad: 76851.0234  LR: 0.00000096  \n","Epoch: [4][300/638] Elapsed 0m 47s (remain 0m 53s) Loss: 0.3812(0.2677) Grad: 69820.6562  LR: 0.00000086  \n","Epoch: [4][320/638] Elapsed 0m 50s (remain 0m 50s) Loss: 0.2008(0.2680) Grad: 41342.7148  LR: 0.00000076  \n","Epoch: [4][340/638] Elapsed 0m 54s (remain 0m 47s) Loss: 0.3388(0.2684) Grad: 60748.1953  LR: 0.00000067  \n","Epoch: [4][360/638] Elapsed 0m 56s (remain 0m 43s) Loss: 0.1272(0.2680) Grad: 53747.5977  LR: 0.00000058  \n","Epoch: [4][380/638] Elapsed 0m 59s (remain 0m 40s) Loss: 0.2351(0.2676) Grad: 42717.6211  LR: 0.00000050  \n","Epoch: [4][400/638] Elapsed 1m 2s (remain 0m 36s) Loss: 0.3171(0.2683) Grad: 43232.2461  LR: 0.00000043  \n","Epoch: [4][420/638] Elapsed 1m 5s (remain 0m 33s) Loss: 0.2708(0.2680) Grad: 63012.3047  LR: 0.00000036  \n","Epoch: [4][440/638] Elapsed 1m 9s (remain 0m 30s) Loss: 0.2208(0.2690) Grad: 66455.0078  LR: 0.00000030  \n","Epoch: [4][460/638] Elapsed 1m 11s (remain 0m 27s) Loss: 0.2552(0.2688) Grad: 41045.2344  LR: 0.00000024  \n","Epoch: [4][480/638] Elapsed 1m 14s (remain 0m 24s) Loss: 0.1645(0.2680) Grad: 55082.8047  LR: 0.00000019  \n","Epoch: [4][500/638] Elapsed 1m 17s (remain 0m 21s) Loss: 0.1961(0.2675) Grad: 49269.1797  LR: 0.00000015  \n","Epoch: [4][520/638] Elapsed 1m 20s (remain 0m 18s) Loss: 0.1389(0.2663) Grad: 75891.0078  LR: 0.00000011  \n","Epoch: [4][540/638] Elapsed 1m 23s (remain 0m 15s) Loss: 0.3184(0.2666) Grad: 107831.3281  LR: 0.00000007  \n","Epoch: [4][560/638] Elapsed 1m 26s (remain 0m 11s) Loss: 0.2593(0.2658) Grad: 35977.8242  LR: 0.00000005  \n","Epoch: [4][580/638] Elapsed 1m 29s (remain 0m 8s) Loss: 0.2522(0.2654) Grad: 51764.8359  LR: 0.00000003  \n","Epoch: [4][600/638] Elapsed 1m 32s (remain 0m 5s) Loss: 0.2873(0.2651) Grad: 34198.4062  LR: 0.00000001  \n","Epoch: [4][620/638] Elapsed 1m 35s (remain 0m 2s) Loss: 0.2292(0.2646) Grad: 69427.0312  LR: 0.00000000  \n","Epoch: [4][637/638] Elapsed 1m 38s (remain 0m 0s) Loss: 0.3116(0.2645) Grad: 40458.2656  LR: 0.00000000  \n","EVAL: [0/129] Elapsed 0m 0s (remain 1m 2s) Loss: 0.3483(0.3483) \n","EVAL: [20/129] Elapsed 0m 2s (remain 0m 12s) Loss: 0.3855(0.4089) \n","EVAL: [40/129] Elapsed 0m 4s (remain 0m 8s) Loss: 0.4578(0.4036) \n","EVAL: [60/129] Elapsed 0m 6s (remain 0m 6s) Loss: 0.3653(0.4054) \n","EVAL: [80/129] Elapsed 0m 8s (remain 0m 4s) Loss: 0.4265(0.4054) \n","EVAL: [100/129] Elapsed 0m 9s (remain 0m 2s) Loss: 0.5047(0.4039) \n","EVAL: [120/129] Elapsed 0m 11s (remain 0m 0s) Loss: 0.3469(0.4036) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2645  avg_val_loss: 0.4013  time: 111s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2645  avg_val_loss: 0.4013  time: 111s\n","Epoch 4 - Score: 0.5139  Scores: [0.4208934722997784, 0.6068384164273498]\n","INFO:__main__:Epoch 4 - Score: 0.5139  Scores: [0.4208934722997784, 0.6068384164273498]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [128/129] Elapsed 0m 12s (remain 0m 0s) Loss: 0.4367(0.4013) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.4969  Scores: [0.43226335132604904, 0.5616051054571688]\n","INFO:__main__:Score: 0.4969  Scores: [0.43226335132604904, 0.5616051054571688]\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["========== prompt_id: ['3b9047'] validation ==========\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/644] Elapsed 0m 0s (remain 4m 26s) Loss: 0.7266(0.7266) Grad: inf  LR: 0.00002000  \n","Epoch: [1][20/644] Elapsed 0m 2s (remain 1m 28s) Loss: 0.7035(0.7771) Grad: 102988.6406  LR: 0.00002000  \n","Epoch: [1][40/644] Elapsed 0m 5s (remain 1m 23s) Loss: 0.6882(0.7053) Grad: 51925.2109  LR: 0.00001999  \n","Epoch: [1][60/644] Elapsed 0m 8s (remain 1m 18s) Loss: 0.4713(0.6745) Grad: 92157.0781  LR: 0.00001997  \n","Epoch: [1][80/644] Elapsed 0m 11s (remain 1m 20s) Loss: 0.4130(0.6401) Grad: 133652.5156  LR: 0.00001995  \n","Epoch: [1][100/644] Elapsed 0m 14s (remain 1m 19s) Loss: 0.6410(0.6097) Grad: 126500.0000  LR: 0.00001992  \n","Epoch: [1][120/644] Elapsed 0m 17s (remain 1m 14s) Loss: 0.3769(0.5821) Grad: 46681.7148  LR: 0.00001989  \n","Epoch: [1][140/644] Elapsed 0m 20s (remain 1m 11s) Loss: 0.6223(0.5733) Grad: 65994.0781  LR: 0.00001985  \n","Epoch: [1][160/644] Elapsed 0m 22s (remain 1m 7s) Loss: 0.3839(0.5559) Grad: 125997.1562  LR: 0.00001981  \n","Epoch: [1][180/644] Elapsed 0m 25s (remain 1m 6s) Loss: 0.3982(0.5479) Grad: 123562.0625  LR: 0.00001976  \n","Epoch: [1][200/644] Elapsed 0m 29s (remain 1m 4s) Loss: 0.6683(0.5375) Grad: 127659.5625  LR: 0.00001970  \n","Epoch: [1][220/644] Elapsed 0m 32s (remain 1m 1s) Loss: 0.4449(0.5322) Grad: 44115.1836  LR: 0.00001964  \n","Epoch: [1][240/644] Elapsed 0m 34s (remain 0m 58s) Loss: 0.3883(0.5258) Grad: 34343.2305  LR: 0.00001957  \n","Epoch: [1][260/644] Elapsed 0m 37s (remain 0m 55s) Loss: 0.5113(0.5206) Grad: 51308.4609  LR: 0.00001950  \n","Epoch: [1][280/644] Elapsed 0m 40s (remain 0m 52s) Loss: 0.3012(0.5133) Grad: 63096.9531  LR: 0.00001942  \n","Epoch: [1][300/644] Elapsed 0m 43s (remain 0m 49s) Loss: 0.4096(0.5086) Grad: 38313.8398  LR: 0.00001933  \n","Epoch: [1][320/644] Elapsed 0m 46s (remain 0m 47s) Loss: 0.3804(0.5049) Grad: 36521.9570  LR: 0.00001924  \n","Epoch: [1][340/644] Elapsed 0m 49s (remain 0m 44s) Loss: 0.5257(0.5030) Grad: 53327.0430  LR: 0.00001915  \n","Epoch: [1][360/644] Elapsed 0m 52s (remain 0m 40s) Loss: 0.2935(0.4981) Grad: 18903.4238  LR: 0.00001905  \n","Epoch: [1][380/644] Elapsed 0m 55s (remain 0m 37s) Loss: 0.4003(0.4927) Grad: 45168.6797  LR: 0.00001894  \n","Epoch: [1][400/644] Elapsed 0m 58s (remain 0m 35s) Loss: 0.3662(0.4877) Grad: 31447.1328  LR: 0.00001883  \n","Epoch: [1][420/644] Elapsed 1m 1s (remain 0m 32s) Loss: 0.3680(0.4846) Grad: 23100.2461  LR: 0.00001871  \n","Epoch: [1][440/644] Elapsed 1m 4s (remain 0m 29s) Loss: 0.4477(0.4802) Grad: 66672.7812  LR: 0.00001859  \n","Epoch: [1][460/644] Elapsed 1m 7s (remain 0m 26s) Loss: 0.2939(0.4763) Grad: 20206.9766  LR: 0.00001846  \n","Epoch: [1][480/644] Elapsed 1m 9s (remain 0m 23s) Loss: 0.4407(0.4761) Grad: 51486.8398  LR: 0.00001833  \n","Epoch: [1][500/644] Elapsed 1m 12s (remain 0m 20s) Loss: 0.3521(0.4741) Grad: 65255.8477  LR: 0.00001819  \n","Epoch: [1][520/644] Elapsed 1m 16s (remain 0m 18s) Loss: 0.4449(0.4720) Grad: 70717.8359  LR: 0.00001805  \n","Epoch: [1][540/644] Elapsed 1m 19s (remain 0m 15s) Loss: 0.3769(0.4668) Grad: 20705.6758  LR: 0.00001790  \n","Epoch: [1][560/644] Elapsed 1m 21s (remain 0m 12s) Loss: 0.2944(0.4627) Grad: 34068.3398  LR: 0.00001775  \n","Epoch: [1][580/644] Elapsed 1m 24s (remain 0m 9s) Loss: 0.2720(0.4593) Grad: 47323.0938  LR: 0.00001760  \n","Epoch: [1][600/644] Elapsed 1m 26s (remain 0m 6s) Loss: 0.3388(0.4565) Grad: 17841.4199  LR: 0.00001744  \n","Epoch: [1][620/644] Elapsed 1m 29s (remain 0m 3s) Loss: 0.4193(0.4535) Grad: 32896.3711  LR: 0.00001727  \n","Epoch: [1][640/644] Elapsed 1m 33s (remain 0m 0s) Loss: 0.3062(0.4501) Grad: 27606.6426  LR: 0.00001710  \n","Epoch: [1][643/644] Elapsed 1m 33s (remain 0m 0s) Loss: 0.3684(0.4499) Grad: 23186.2969  LR: 0.00001708  \n","EVAL: [0/126] Elapsed 0m 0s (remain 0m 54s) Loss: 0.7735(0.7735) \n","EVAL: [20/126] Elapsed 0m 3s (remain 0m 15s) Loss: 0.4918(0.5713) \n","EVAL: [40/126] Elapsed 0m 5s (remain 0m 12s) Loss: 0.5070(0.5589) \n","EVAL: [60/126] Elapsed 0m 8s (remain 0m 9s) Loss: 0.6171(0.5663) \n","EVAL: [80/126] Elapsed 0m 11s (remain 0m 6s) Loss: 0.6869(0.5732) \n","EVAL: [100/126] Elapsed 0m 14s (remain 0m 3s) Loss: 0.5493(0.5749) \n","EVAL: [120/126] Elapsed 0m 16s (remain 0m 0s) Loss: 0.6316(0.5687) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.4499  avg_val_loss: 0.5714  time: 112s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4499  avg_val_loss: 0.5714  time: 112s\n","Epoch 1 - Score: 0.7921  Scores: [0.6359271266387128, 0.9481777627387658]\n","INFO:__main__:Epoch 1 - Score: 0.7921  Scores: [0.6359271266387128, 0.9481777627387658]\n","Epoch 1 - Save Best Score: 0.7921 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7921 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Elapsed 0m 17s (remain 0m 0s) Loss: 0.3431(0.5714) \n","Epoch: [2][0/644] Elapsed 0m 0s (remain 4m 23s) Loss: 0.3543(0.3543) Grad: inf  LR: 0.00001707  \n","Epoch: [2][20/644] Elapsed 0m 3s (remain 1m 29s) Loss: 0.4374(0.3695) Grad: 74666.7812  LR: 0.00001689  \n","Epoch: [2][40/644] Elapsed 0m 6s (remain 1m 30s) Loss: 0.2366(0.3451) Grad: 125345.0938  LR: 0.00001671  \n","Epoch: [2][60/644] Elapsed 0m 10s (remain 1m 37s) Loss: 0.2533(0.3448) Grad: 97387.3438  LR: 0.00001653  \n","Epoch: [2][80/644] Elapsed 0m 13s (remain 1m 32s) Loss: 0.3010(0.3518) Grad: 19264.4961  LR: 0.00001634  \n","Epoch: [2][100/644] Elapsed 0m 16s (remain 1m 27s) Loss: 0.3549(0.3502) Grad: 42013.0195  LR: 0.00001615  \n","Epoch: [2][120/644] Elapsed 0m 19s (remain 1m 23s) Loss: 0.3663(0.3475) Grad: 69500.1719  LR: 0.00001596  \n","Epoch: [2][140/644] Elapsed 0m 23s (remain 1m 22s) Loss: 0.3952(0.3489) Grad: 64708.0625  LR: 0.00001576  \n","Epoch: [2][160/644] Elapsed 0m 26s (remain 1m 19s) Loss: 0.3165(0.3480) Grad: 40740.9297  LR: 0.00001556  \n","Epoch: [2][180/644] Elapsed 0m 28s (remain 1m 13s) Loss: 0.4662(0.3468) Grad: 77856.0156  LR: 0.00001536  \n","Epoch: [2][200/644] Elapsed 0m 31s (remain 1m 9s) Loss: 0.2868(0.3464) Grad: 123184.5859  LR: 0.00001515  \n","Epoch: [2][220/644] Elapsed 0m 33s (remain 1m 4s) Loss: 0.2315(0.3424) Grad: 99135.5156  LR: 0.00001494  \n","Epoch: [2][240/644] Elapsed 0m 36s (remain 1m 1s) Loss: 0.3418(0.3427) Grad: 36672.6172  LR: 0.00001473  \n","Epoch: [2][260/644] Elapsed 0m 40s (remain 0m 59s) Loss: 0.3819(0.3430) Grad: 71477.8984  LR: 0.00001451  \n","Epoch: [2][280/644] Elapsed 0m 43s (remain 0m 56s) Loss: 0.3076(0.3442) Grad: 65088.9531  LR: 0.00001429  \n","Epoch: [2][300/644] Elapsed 0m 46s (remain 0m 52s) Loss: 0.4504(0.3438) Grad: 72700.7266  LR: 0.00001407  \n","Epoch: [2][320/644] Elapsed 0m 48s (remain 0m 49s) Loss: 0.2477(0.3436) Grad: 112422.2969  LR: 0.00001385  \n","Epoch: [2][340/644] Elapsed 0m 51s (remain 0m 45s) Loss: 0.3954(0.3429) Grad: 100880.6328  LR: 0.00001362  \n","Epoch: [2][360/644] Elapsed 0m 54s (remain 0m 42s) Loss: 0.2374(0.3426) Grad: 42917.9727  LR: 0.00001339  \n","Epoch: [2][380/644] Elapsed 0m 57s (remain 0m 39s) Loss: 0.3948(0.3409) Grad: 68016.6094  LR: 0.00001316  \n","Epoch: [2][400/644] Elapsed 1m 0s (remain 0m 36s) Loss: 0.3506(0.3429) Grad: 71388.5156  LR: 0.00001293  \n","Epoch: [2][420/644] Elapsed 1m 3s (remain 0m 33s) Loss: 0.3435(0.3408) Grad: 80005.3984  LR: 0.00001270  \n","Epoch: [2][440/644] Elapsed 1m 5s (remain 0m 30s) Loss: 0.4016(0.3396) Grad: 52552.8672  LR: 0.00001246  \n","Epoch: [2][460/644] Elapsed 1m 8s (remain 0m 27s) Loss: 0.3040(0.3403) Grad: 99096.1484  LR: 0.00001222  \n","Epoch: [2][480/644] Elapsed 1m 12s (remain 0m 24s) Loss: 0.2985(0.3390) Grad: 65906.0000  LR: 0.00001199  \n","Epoch: [2][500/644] Elapsed 1m 15s (remain 0m 21s) Loss: 0.3097(0.3377) Grad: 67327.6328  LR: 0.00001175  \n","Epoch: [2][520/644] Elapsed 1m 17s (remain 0m 18s) Loss: 0.4811(0.3384) Grad: 22104.4844  LR: 0.00001151  \n","Epoch: [2][540/644] Elapsed 1m 20s (remain 0m 15s) Loss: 0.2999(0.3378) Grad: 46772.6133  LR: 0.00001126  \n","Epoch: [2][560/644] Elapsed 1m 22s (remain 0m 12s) Loss: 0.3041(0.3366) Grad: 134705.2812  LR: 0.00001102  \n","Epoch: [2][580/644] Elapsed 1m 25s (remain 0m 9s) Loss: 0.1750(0.3358) Grad: 36124.5820  LR: 0.00001078  \n","Epoch: [2][600/644] Elapsed 1m 29s (remain 0m 6s) Loss: 0.4817(0.3357) Grad: 97975.4375  LR: 0.00001054  \n","Epoch: [2][620/644] Elapsed 1m 31s (remain 0m 3s) Loss: 0.3424(0.3353) Grad: 35860.5664  LR: 0.00001029  \n","Epoch: [2][640/644] Elapsed 1m 34s (remain 0m 0s) Loss: 0.2065(0.3341) Grad: 57305.8359  LR: 0.00001005  \n","Epoch: [2][643/644] Elapsed 1m 34s (remain 0m 0s) Loss: 0.2745(0.3342) Grad: 48390.2734  LR: 0.00001001  \n","EVAL: [0/126] Elapsed 0m 0s (remain 0m 52s) Loss: 0.7153(0.7153) \n","EVAL: [20/126] Elapsed 0m 3s (remain 0m 15s) Loss: 0.4310(0.4715) \n","EVAL: [40/126] Elapsed 0m 6s (remain 0m 12s) Loss: 0.4665(0.4811) \n","EVAL: [60/126] Elapsed 0m 9s (remain 0m 9s) Loss: 0.4512(0.4863) \n","EVAL: [80/126] Elapsed 0m 11s (remain 0m 6s) Loss: 0.5267(0.4906) \n","EVAL: [100/126] Elapsed 0m 14s (remain 0m 3s) Loss: 0.3952(0.4933) \n","EVAL: [120/126] Elapsed 0m 16s (remain 0m 0s) Loss: 0.5415(0.4912) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3342  avg_val_loss: 0.4932  time: 112s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3342  avg_val_loss: 0.4932  time: 112s\n","Epoch 2 - Score: 0.6666  Scores: [0.5256948019892972, 0.8075208567359278]\n","INFO:__main__:Epoch 2 - Score: 0.6666  Scores: [0.5256948019892972, 0.8075208567359278]\n","Epoch 2 - Save Best Score: 0.6666 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.6666 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Elapsed 0m 17s (remain 0m 0s) Loss: 0.2529(0.4932) \n","Epoch: [3][0/644] Elapsed 0m 0s (remain 5m 59s) Loss: 0.2546(0.2546) Grad: inf  LR: 0.00001000  \n","Epoch: [3][20/644] Elapsed 0m 3s (remain 1m 53s) Loss: 0.2801(0.2750) Grad: 53246.0547  LR: 0.00000976  \n","Epoch: [3][40/644] Elapsed 0m 6s (remain 1m 34s) Loss: 0.2094(0.2938) Grad: 74159.5078  LR: 0.00000951  \n","Epoch: [3][60/644] Elapsed 0m 9s (remain 1m 32s) Loss: 0.2950(0.2904) Grad: 43026.9844  LR: 0.00000927  \n","Epoch: [3][80/644] Elapsed 0m 12s (remain 1m 29s) Loss: 0.2340(0.2920) Grad: 41595.8438  LR: 0.00000903  \n","Epoch: [3][100/644] Elapsed 0m 16s (remain 1m 31s) Loss: 0.2817(0.2962) Grad: 56340.9453  LR: 0.00000878  \n","Epoch: [3][120/644] Elapsed 0m 20s (remain 1m 28s) Loss: 0.3069(0.2958) Grad: 85890.6797  LR: 0.00000854  \n","Epoch: [3][140/644] Elapsed 0m 23s (remain 1m 22s) Loss: 0.1372(0.2964) Grad: 94757.4609  LR: 0.00000830  \n","Epoch: [3][160/644] Elapsed 0m 25s (remain 1m 17s) Loss: 0.2618(0.2942) Grad: 112405.7266  LR: 0.00000806  \n","Epoch: [3][180/644] Elapsed 0m 28s (remain 1m 12s) Loss: 0.3771(0.2938) Grad: 98744.7109  LR: 0.00000782  \n","Epoch: [3][200/644] Elapsed 0m 31s (remain 1m 9s) Loss: 0.4475(0.2960) Grad: 69811.1172  LR: 0.00000759  \n","Epoch: [3][220/644] Elapsed 0m 34s (remain 1m 6s) Loss: 0.3798(0.2975) Grad: 55366.4766  LR: 0.00000735  \n","Epoch: [3][240/644] Elapsed 0m 37s (remain 1m 2s) Loss: 0.3018(0.2970) Grad: 75403.5312  LR: 0.00000712  \n","Epoch: [3][260/644] Elapsed 0m 39s (remain 0m 58s) Loss: 0.3190(0.2993) Grad: 98875.7109  LR: 0.00000688  \n","Epoch: [3][280/644] Elapsed 0m 42s (remain 0m 54s) Loss: 0.4052(0.2996) Grad: 75999.2500  LR: 0.00000665  \n","Epoch: [3][300/644] Elapsed 0m 45s (remain 0m 51s) Loss: 0.3219(0.2980) Grad: 68257.2812  LR: 0.00000643  \n","Epoch: [3][320/644] Elapsed 0m 48s (remain 0m 48s) Loss: 0.4304(0.2991) Grad: 56297.5742  LR: 0.00000620  \n","Epoch: [3][340/644] Elapsed 0m 51s (remain 0m 45s) Loss: 0.2740(0.2997) Grad: 37966.5273  LR: 0.00000597  \n","Epoch: [3][360/644] Elapsed 0m 54s (remain 0m 42s) Loss: 0.4231(0.3005) Grad: 55106.4297  LR: 0.00000575  \n","Epoch: [3][380/644] Elapsed 0m 57s (remain 0m 39s) Loss: 0.2543(0.3011) Grad: 60102.3281  LR: 0.00000553  \n","Epoch: [3][400/644] Elapsed 0m 59s (remain 0m 36s) Loss: 0.3662(0.2988) Grad: 47246.1523  LR: 0.00000532  \n","Epoch: [3][420/644] Elapsed 1m 3s (remain 0m 33s) Loss: 0.1806(0.2982) Grad: 40043.7188  LR: 0.00000510  \n","Epoch: [3][440/644] Elapsed 1m 6s (remain 0m 30s) Loss: 0.2396(0.2984) Grad: 116327.4453  LR: 0.00000489  \n","Epoch: [3][460/644] Elapsed 1m 8s (remain 0m 27s) Loss: 0.2011(0.2972) Grad: 74330.4062  LR: 0.00000468  \n","Epoch: [3][480/644] Elapsed 1m 11s (remain 0m 24s) Loss: 0.2040(0.2972) Grad: 83137.4922  LR: 0.00000448  \n","Epoch: [3][500/644] Elapsed 1m 14s (remain 0m 21s) Loss: 0.3652(0.2978) Grad: 54775.2500  LR: 0.00000428  \n","Epoch: [3][520/644] Elapsed 1m 17s (remain 0m 18s) Loss: 0.2461(0.2975) Grad: 65793.3359  LR: 0.00000408  \n","Epoch: [3][540/644] Elapsed 1m 20s (remain 0m 15s) Loss: 0.2993(0.2972) Grad: 83200.7656  LR: 0.00000388  \n","Epoch: [3][560/644] Elapsed 1m 23s (remain 0m 12s) Loss: 0.3797(0.2971) Grad: 58805.0742  LR: 0.00000369  \n","Epoch: [3][580/644] Elapsed 1m 26s (remain 0m 9s) Loss: 0.1681(0.2963) Grad: 66826.7500  LR: 0.00000351  \n","Epoch: [3][600/644] Elapsed 1m 28s (remain 0m 6s) Loss: 0.2939(0.2959) Grad: 83433.8281  LR: 0.00000332  \n","Epoch: [3][620/644] Elapsed 1m 31s (remain 0m 3s) Loss: 0.2519(0.2960) Grad: 50260.0430  LR: 0.00000314  \n","Epoch: [3][640/644] Elapsed 1m 34s (remain 0m 0s) Loss: 0.3035(0.2957) Grad: 89379.9375  LR: 0.00000297  \n","Epoch: [3][643/644] Elapsed 1m 35s (remain 0m 0s) Loss: 0.3678(0.2954) Grad: 55981.9570  LR: 0.00000294  \n","EVAL: [0/126] Elapsed 0m 0s (remain 1m 16s) Loss: 0.7026(0.7026) \n","EVAL: [20/126] Elapsed 0m 3s (remain 0m 16s) Loss: 0.4260(0.4719) \n","EVAL: [40/126] Elapsed 0m 6s (remain 0m 12s) Loss: 0.4569(0.4769) \n","EVAL: [60/126] Elapsed 0m 8s (remain 0m 9s) Loss: 0.4563(0.4822) \n","EVAL: [80/126] Elapsed 0m 11s (remain 0m 6s) Loss: 0.5294(0.4867) \n","EVAL: [100/126] Elapsed 0m 14s (remain 0m 3s) Loss: 0.3928(0.4896) \n","EVAL: [120/126] Elapsed 0m 16s (remain 0m 0s) Loss: 0.5423(0.4874) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2954  avg_val_loss: 0.4902  time: 113s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2954  avg_val_loss: 0.4902  time: 113s\n","Epoch 3 - Score: 0.6684  Scores: [0.5074997130637312, 0.8292296266389012]\n","INFO:__main__:Epoch 3 - Score: 0.6684  Scores: [0.5074997130637312, 0.8292296266389012]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Elapsed 0m 17s (remain 0m 0s) Loss: 0.2662(0.4902) \n","Epoch: [4][0/644] Elapsed 0m 0s (remain 4m 22s) Loss: 0.3388(0.3388) Grad: inf  LR: 0.00000293  \n","Epoch: [4][20/644] Elapsed 0m 2s (remain 1m 28s) Loss: 0.2360(0.2721) Grad: 47440.1445  LR: 0.00000276  \n","Epoch: [4][40/644] Elapsed 0m 5s (remain 1m 23s) Loss: 0.3182(0.2759) Grad: 47658.3672  LR: 0.00000260  \n","Epoch: [4][60/644] Elapsed 0m 8s (remain 1m 18s) Loss: 0.1651(0.2685) Grad: 37061.1523  LR: 0.00000244  \n","Epoch: [4][80/644] Elapsed 0m 11s (remain 1m 17s) Loss: 0.2357(0.2710) Grad: 76534.2031  LR: 0.00000228  \n","Epoch: [4][100/644] Elapsed 0m 14s (remain 1m 18s) Loss: 0.1923(0.2707) Grad: 76096.0938  LR: 0.00000213  \n","Epoch: [4][120/644] Elapsed 0m 17s (remain 1m 16s) Loss: 0.4068(0.2686) Grad: 30362.3105  LR: 0.00000198  \n","Epoch: [4][140/644] Elapsed 0m 20s (remain 1m 12s) Loss: 0.3169(0.2676) Grad: 92112.7422  LR: 0.00000183  \n","Epoch: [4][160/644] Elapsed 0m 22s (remain 1m 8s) Loss: 0.2205(0.2720) Grad: 78136.1016  LR: 0.00000170  \n","Epoch: [4][180/644] Elapsed 0m 25s (remain 1m 5s) Loss: 0.2337(0.2703) Grad: 51049.0508  LR: 0.00000156  \n","Epoch: [4][200/644] Elapsed 0m 28s (remain 1m 3s) Loss: 0.1792(0.2689) Grad: 75902.5156  LR: 0.00000143  \n","Epoch: [4][220/644] Elapsed 0m 32s (remain 1m 1s) Loss: 0.2333(0.2684) Grad: 70089.7734  LR: 0.00000131  \n","Epoch: [4][240/644] Elapsed 0m 34s (remain 0m 58s) Loss: 0.2575(0.2691) Grad: 77233.4922  LR: 0.00000119  \n","Epoch: [4][260/644] Elapsed 0m 37s (remain 0m 55s) Loss: 0.1934(0.2696) Grad: 64256.2656  LR: 0.00000108  \n","Epoch: [4][280/644] Elapsed 0m 39s (remain 0m 51s) Loss: 0.3821(0.2685) Grad: 51788.4844  LR: 0.00000097  \n","Epoch: [4][300/644] Elapsed 0m 42s (remain 0m 48s) Loss: 0.2981(0.2686) Grad: 22756.9316  LR: 0.00000087  \n","Epoch: [4][320/644] Elapsed 0m 46s (remain 0m 46s) Loss: 0.2793(0.2690) Grad: 83992.8516  LR: 0.00000077  \n","Epoch: [4][340/644] Elapsed 0m 49s (remain 0m 43s) Loss: 0.3048(0.2694) Grad: 72371.7969  LR: 0.00000068  \n","Epoch: [4][360/644] Elapsed 0m 51s (remain 0m 40s) Loss: 0.2167(0.2686) Grad: 69820.4609  LR: 0.00000060  \n","Epoch: [4][380/644] Elapsed 0m 54s (remain 0m 37s) Loss: 0.2232(0.2687) Grad: 47889.8789  LR: 0.00000052  \n","Epoch: [4][400/644] Elapsed 0m 57s (remain 0m 34s) Loss: 0.2583(0.2683) Grad: 41890.0898  LR: 0.00000044  \n","Epoch: [4][420/644] Elapsed 1m 0s (remain 0m 32s) Loss: 0.2536(0.2672) Grad: 77444.8828  LR: 0.00000037  \n","Epoch: [4][440/644] Elapsed 1m 3s (remain 0m 29s) Loss: 0.1705(0.2669) Grad: 45327.6484  LR: 0.00000031  \n","Epoch: [4][460/644] Elapsed 1m 6s (remain 0m 26s) Loss: 0.1800(0.2667) Grad: 90009.7109  LR: 0.00000025  \n","Epoch: [4][480/644] Elapsed 1m 9s (remain 0m 23s) Loss: 0.2193(0.2672) Grad: 53815.4844  LR: 0.00000020  \n","Epoch: [4][500/644] Elapsed 1m 11s (remain 0m 20s) Loss: 0.2544(0.2661) Grad: 72507.6016  LR: 0.00000016  \n","Epoch: [4][520/644] Elapsed 1m 14s (remain 0m 17s) Loss: 0.3207(0.2653) Grad: 55171.3438  LR: 0.00000012  \n","Epoch: [4][540/644] Elapsed 1m 18s (remain 0m 14s) Loss: 0.2317(0.2651) Grad: 51853.0664  LR: 0.00000008  \n","Epoch: [4][560/644] Elapsed 1m 20s (remain 0m 11s) Loss: 0.2676(0.2642) Grad: 28973.0352  LR: 0.00000005  \n","Epoch: [4][580/644] Elapsed 1m 23s (remain 0m 9s) Loss: 0.4207(0.2641) Grad: 45811.9961  LR: 0.00000003  \n","Epoch: [4][600/644] Elapsed 1m 25s (remain 0m 6s) Loss: 0.2389(0.2636) Grad: 39818.9258  LR: 0.00000002  \n","Epoch: [4][620/644] Elapsed 1m 28s (remain 0m 3s) Loss: 0.2205(0.2636) Grad: 45428.0156  LR: 0.00000000  \n","Epoch: [4][640/644] Elapsed 1m 31s (remain 0m 0s) Loss: 0.3444(0.2632) Grad: 69523.5078  LR: 0.00000000  \n","Epoch: [4][643/644] Elapsed 1m 32s (remain 0m 0s) Loss: 0.1827(0.2629) Grad: 44793.3125  LR: 0.00000000  \n","EVAL: [0/126] Elapsed 0m 0s (remain 1m 19s) Loss: 0.7029(0.7029) \n","EVAL: [20/126] Elapsed 0m 3s (remain 0m 16s) Loss: 0.4328(0.4678) \n","EVAL: [40/126] Elapsed 0m 6s (remain 0m 12s) Loss: 0.4653(0.4742) \n","EVAL: [60/126] Elapsed 0m 8s (remain 0m 9s) Loss: 0.4403(0.4786) \n","EVAL: [80/126] Elapsed 0m 11s (remain 0m 6s) Loss: 0.5254(0.4824) \n","EVAL: [100/126] Elapsed 0m 14s (remain 0m 3s) Loss: 0.3921(0.4856) \n","EVAL: [120/126] Elapsed 0m 16s (remain 0m 0s) Loss: 0.5355(0.4842) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2629  avg_val_loss: 0.4866  time: 110s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2629  avg_val_loss: 0.4866  time: 110s\n","Epoch 4 - Score: 0.6589  Scores: [0.5119967510087977, 0.8057431101933162]\n","INFO:__main__:Epoch 4 - Score: 0.6589  Scores: [0.5119967510087977, 0.8057431101933162]\n","Epoch 4 - Save Best Score: 0.6589 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.6589 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [125/126] Elapsed 0m 17s (remain 0m 0s) Loss: 0.2531(0.4866) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.6589  Scores: [0.5119967510087977, 0.8057431101933162]\n","INFO:__main__:Score: 0.6589  Scores: [0.5119967510087977, 0.8057431101933162]\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["========== prompt_id: ['ebad26'] validation ==========\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/646] Elapsed 0m 0s (remain 8m 17s) Loss: 0.5198(0.5198) Grad: inf  LR: 0.00002000  \n","Epoch: [1][20/646] Elapsed 0m 4s (remain 2m 6s) Loss: 0.6211(0.7591) Grad: 51621.8359  LR: 0.00002000  \n","Epoch: [1][40/646] Elapsed 0m 7s (remain 1m 49s) Loss: 1.0294(0.6963) Grad: 76483.6250  LR: 0.00001999  \n","Epoch: [1][60/646] Elapsed 0m 10s (remain 1m 43s) Loss: 0.5057(0.6974) Grad: 118909.6641  LR: 0.00001997  \n","Epoch: [1][80/646] Elapsed 0m 13s (remain 1m 36s) Loss: 0.4033(0.6804) Grad: 95096.2266  LR: 0.00001995  \n","Epoch: [1][100/646] Elapsed 0m 17s (remain 1m 34s) Loss: 0.5075(0.6730) Grad: 100814.7500  LR: 0.00001992  \n","Epoch: [1][120/646] Elapsed 0m 20s (remain 1m 27s) Loss: 0.3859(0.6495) Grad: 40030.1680  LR: 0.00001989  \n","Epoch: [1][140/646] Elapsed 0m 22s (remain 1m 21s) Loss: 0.6039(0.6319) Grad: 152518.3438  LR: 0.00001985  \n","Epoch: [1][160/646] Elapsed 0m 25s (remain 1m 16s) Loss: 0.3372(0.6148) Grad: 74472.9609  LR: 0.00001981  \n","Epoch: [1][180/646] Elapsed 0m 28s (remain 1m 13s) Loss: 0.4499(0.6070) Grad: 64860.7500  LR: 0.00001976  \n","Epoch: [1][200/646] Elapsed 0m 31s (remain 1m 10s) Loss: 0.3186(0.5899) Grad: 38262.2656  LR: 0.00001970  \n","Epoch: [1][220/646] Elapsed 0m 34s (remain 1m 7s) Loss: 0.3387(0.5777) Grad: 65216.1211  LR: 0.00001964  \n","Epoch: [1][240/646] Elapsed 0m 37s (remain 1m 3s) Loss: 0.5258(0.5670) Grad: 126042.2812  LR: 0.00001957  \n","Epoch: [1][260/646] Elapsed 0m 40s (remain 0m 59s) Loss: 0.4308(0.5583) Grad: 131209.4688  LR: 0.00001950  \n","Epoch: [1][280/646] Elapsed 0m 42s (remain 0m 55s) Loss: 0.4725(0.5506) Grad: 85666.0391  LR: 0.00001942  \n","Epoch: [1][300/646] Elapsed 0m 46s (remain 0m 53s) Loss: 0.3451(0.5429) Grad: 41141.3789  LR: 0.00001934  \n","Epoch: [1][320/646] Elapsed 0m 49s (remain 0m 50s) Loss: 0.4745(0.5387) Grad: 64846.9258  LR: 0.00001925  \n","Epoch: [1][340/646] Elapsed 0m 52s (remain 0m 46s) Loss: 0.6178(0.5341) Grad: 152749.9688  LR: 0.00001915  \n","Epoch: [1][360/646] Elapsed 0m 54s (remain 0m 43s) Loss: 0.3587(0.5295) Grad: 94793.5000  LR: 0.00001905  \n","Epoch: [1][380/646] Elapsed 0m 57s (remain 0m 40s) Loss: 0.2647(0.5250) Grad: 47731.5469  LR: 0.00001895  \n","Epoch: [1][400/646] Elapsed 1m 0s (remain 0m 37s) Loss: 0.2970(0.5203) Grad: 74863.5000  LR: 0.00001883  \n","Epoch: [1][420/646] Elapsed 1m 4s (remain 0m 34s) Loss: 0.3495(0.5207) Grad: 45872.5352  LR: 0.00001872  \n","Epoch: [1][440/646] Elapsed 1m 6s (remain 0m 31s) Loss: 0.2920(0.5143) Grad: 141359.9844  LR: 0.00001860  \n","Epoch: [1][460/646] Elapsed 1m 9s (remain 0m 27s) Loss: 0.2900(0.5101) Grad: 42475.3438  LR: 0.00001847  \n","Epoch: [1][480/646] Elapsed 1m 12s (remain 0m 24s) Loss: 0.3543(0.5064) Grad: 62331.5820  LR: 0.00001834  \n","Epoch: [1][500/646] Elapsed 1m 15s (remain 0m 21s) Loss: 0.3745(0.5043) Grad: 82056.3672  LR: 0.00001820  \n","Epoch: [1][520/646] Elapsed 1m 18s (remain 0m 18s) Loss: 0.3782(0.5015) Grad: 72802.6094  LR: 0.00001806  \n","Epoch: [1][540/646] Elapsed 1m 21s (remain 0m 15s) Loss: 0.4896(0.5007) Grad: 46836.5820  LR: 0.00001791  \n","Epoch: [1][560/646] Elapsed 1m 24s (remain 0m 12s) Loss: 0.3757(0.4987) Grad: 46187.6953  LR: 0.00001776  \n","Epoch: [1][580/646] Elapsed 1m 27s (remain 0m 9s) Loss: 0.3708(0.4956) Grad: 66675.5078  LR: 0.00001761  \n","Epoch: [1][600/646] Elapsed 1m 29s (remain 0m 6s) Loss: 0.3493(0.4922) Grad: 63685.9492  LR: 0.00001745  \n","Epoch: [1][620/646] Elapsed 1m 33s (remain 0m 3s) Loss: 0.6775(0.4899) Grad: 108813.8359  LR: 0.00001728  \n","Epoch: [1][640/646] Elapsed 1m 36s (remain 0m 0s) Loss: 0.3740(0.4876) Grad: 29104.8809  LR: 0.00001711  \n","Epoch: [1][645/646] Elapsed 1m 37s (remain 0m 0s) Loss: 0.4153(0.4869) Grad: 50233.4375  LR: 0.00001707  \n","EVAL: [0/125] Elapsed 0m 0s (remain 0m 51s) Loss: 0.4462(0.4462) \n","EVAL: [20/125] Elapsed 0m 2s (remain 0m 12s) Loss: 0.4694(0.4150) \n","EVAL: [40/125] Elapsed 0m 5s (remain 0m 10s) Loss: 0.4328(0.4401) \n","EVAL: [60/125] Elapsed 0m 7s (remain 0m 7s) Loss: 0.4699(0.4302) \n","EVAL: [80/125] Elapsed 0m 10s (remain 0m 5s) Loss: 0.3569(0.4240) \n","EVAL: [100/125] Elapsed 0m 12s (remain 0m 3s) Loss: 0.4819(0.4152) \n","EVAL: [120/125] Elapsed 0m 15s (remain 0m 0s) Loss: 0.3681(0.4157) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.4869  avg_val_loss: 0.4145  time: 113s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4869  avg_val_loss: 0.4145  time: 113s\n","Epoch 1 - Score: 0.5439  Scores: [0.4465286209213582, 0.6413217594671915]\n","INFO:__main__:Epoch 1 - Score: 0.5439  Scores: [0.4465286209213582, 0.6413217594671915]\n","Epoch 1 - Save Best Score: 0.5439 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5439 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [124/125] Elapsed 0m 15s (remain 0m 0s) Loss: 0.4173(0.4145) \n","Epoch: [2][0/646] Elapsed 0m 0s (remain 4m 22s) Loss: 0.3073(0.3073) Grad: inf  LR: 0.00001706  \n","Epoch: [2][20/646] Elapsed 0m 3s (remain 1m 32s) Loss: 0.3530(0.3434) Grad: 56915.3633  LR: 0.00001689  \n","Epoch: [2][40/646] Elapsed 0m 5s (remain 1m 25s) Loss: 0.3281(0.3553) Grad: 66585.9609  LR: 0.00001671  \n","Epoch: [2][60/646] Elapsed 0m 9s (remain 1m 32s) Loss: 0.2772(0.3587) Grad: 64220.2070  LR: 0.00001653  \n","Epoch: [2][80/646] Elapsed 0m 13s (remain 1m 33s) Loss: 0.4784(0.3678) Grad: 105434.9922  LR: 0.00001634  \n","Epoch: [2][100/646] Elapsed 0m 16s (remain 1m 29s) Loss: 0.5431(0.3710) Grad: 30956.0586  LR: 0.00001615  \n","Epoch: [2][120/646] Elapsed 0m 19s (remain 1m 25s) Loss: 0.3366(0.3709) Grad: 41415.1172  LR: 0.00001596  \n","Epoch: [2][140/646] Elapsed 0m 23s (remain 1m 22s) Loss: 0.5172(0.3737) Grad: 43909.2773  LR: 0.00001576  \n","Epoch: [2][160/646] Elapsed 0m 26s (remain 1m 20s) Loss: 0.3278(0.3774) Grad: 109551.0938  LR: 0.00001556  \n","Epoch: [2][180/646] Elapsed 0m 29s (remain 1m 15s) Loss: 0.4407(0.3771) Grad: 43494.8086  LR: 0.00001536  \n","Epoch: [2][200/646] Elapsed 0m 32s (remain 1m 11s) Loss: 0.3013(0.3733) Grad: 36676.9766  LR: 0.00001515  \n","Epoch: [2][220/646] Elapsed 0m 34s (remain 1m 7s) Loss: 0.2435(0.3738) Grad: 73199.0078  LR: 0.00001494  \n","Epoch: [2][240/646] Elapsed 0m 37s (remain 1m 3s) Loss: 0.5121(0.3749) Grad: 73072.5234  LR: 0.00001473  \n","Epoch: [2][260/646] Elapsed 0m 41s (remain 1m 1s) Loss: 0.4344(0.3743) Grad: 107545.1797  LR: 0.00001451  \n","Epoch: [2][280/646] Elapsed 0m 44s (remain 0m 57s) Loss: 0.4754(0.3743) Grad: 83736.8125  LR: 0.00001429  \n","Epoch: [2][300/646] Elapsed 0m 46s (remain 0m 53s) Loss: 0.2874(0.3721) Grad: 53292.3164  LR: 0.00001407  \n","Epoch: [2][320/646] Elapsed 0m 49s (remain 0m 50s) Loss: 0.3985(0.3696) Grad: 57419.9609  LR: 0.00001385  \n","Epoch: [2][340/646] Elapsed 0m 52s (remain 0m 46s) Loss: 0.4081(0.3693) Grad: 50960.0000  LR: 0.00001362  \n","Epoch: [2][360/646] Elapsed 0m 55s (remain 0m 43s) Loss: 0.3996(0.3681) Grad: 97719.9141  LR: 0.00001340  \n","Epoch: [2][380/646] Elapsed 0m 59s (remain 0m 41s) Loss: 0.2745(0.3681) Grad: 46885.4102  LR: 0.00001317  \n","Epoch: [2][400/646] Elapsed 1m 1s (remain 0m 37s) Loss: 0.4170(0.3669) Grad: 55328.9062  LR: 0.00001293  \n","Epoch: [2][420/646] Elapsed 1m 4s (remain 0m 34s) Loss: 0.2496(0.3702) Grad: 55328.4297  LR: 0.00001270  \n","Epoch: [2][440/646] Elapsed 1m 7s (remain 0m 31s) Loss: 0.3082(0.3688) Grad: 37469.2266  LR: 0.00001247  \n","Epoch: [2][460/646] Elapsed 1m 10s (remain 0m 28s) Loss: 0.4249(0.3675) Grad: 45849.5508  LR: 0.00001223  \n","Epoch: [2][480/646] Elapsed 1m 13s (remain 0m 25s) Loss: 0.4936(0.3681) Grad: 104363.6016  LR: 0.00001199  \n","Epoch: [2][500/646] Elapsed 1m 16s (remain 0m 22s) Loss: 0.5335(0.3673) Grad: 68763.6094  LR: 0.00001175  \n","Epoch: [2][520/646] Elapsed 1m 19s (remain 0m 19s) Loss: 0.2963(0.3677) Grad: 75982.1719  LR: 0.00001151  \n","Epoch: [2][540/646] Elapsed 1m 22s (remain 0m 15s) Loss: 0.3277(0.3663) Grad: 53293.6914  LR: 0.00001127  \n","Epoch: [2][560/646] Elapsed 1m 24s (remain 0m 12s) Loss: 0.3333(0.3664) Grad: 47635.3086  LR: 0.00001103  \n","Epoch: [2][580/646] Elapsed 1m 28s (remain 0m 9s) Loss: 0.3483(0.3654) Grad: 60718.0664  LR: 0.00001079  \n","Epoch: [2][600/646] Elapsed 1m 31s (remain 0m 6s) Loss: 0.3498(0.3646) Grad: 64800.8320  LR: 0.00001055  \n","Epoch: [2][620/646] Elapsed 1m 34s (remain 0m 3s) Loss: 0.5007(0.3643) Grad: 38139.2461  LR: 0.00001030  \n","Epoch: [2][640/646] Elapsed 1m 37s (remain 0m 0s) Loss: 0.3080(0.3639) Grad: 33972.5664  LR: 0.00001006  \n","Epoch: [2][645/646] Elapsed 1m 37s (remain 0m 0s) Loss: 0.3579(0.3641) Grad: 110933.4922  LR: 0.00001000  \n","EVAL: [0/125] Elapsed 0m 0s (remain 0m 55s) Loss: 0.4338(0.4338) \n","EVAL: [20/125] Elapsed 0m 2s (remain 0m 13s) Loss: 0.4007(0.4012) \n","EVAL: [40/125] Elapsed 0m 5s (remain 0m 11s) Loss: 0.3617(0.4033) \n","EVAL: [60/125] Elapsed 0m 8s (remain 0m 8s) Loss: 0.3893(0.3916) \n","EVAL: [80/125] Elapsed 0m 10s (remain 0m 5s) Loss: 0.3607(0.3929) \n","EVAL: [100/125] Elapsed 0m 12s (remain 0m 3s) Loss: 0.4515(0.3843) \n","EVAL: [120/125] Elapsed 0m 15s (remain 0m 0s) Loss: 0.4254(0.3864) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3641  avg_val_loss: 0.3863  time: 114s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3641  avg_val_loss: 0.3863  time: 114s\n","Epoch 2 - Score: 0.4941  Scores: [0.46006221313106943, 0.5281407594638985]\n","INFO:__main__:Epoch 2 - Score: 0.4941  Scores: [0.46006221313106943, 0.5281407594638985]\n","Epoch 2 - Save Best Score: 0.4941 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4941 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [124/125] Elapsed 0m 15s (remain 0m 0s) Loss: 0.4360(0.3863) \n","Epoch: [3][0/646] Elapsed 0m 0s (remain 6m 25s) Loss: 0.3243(0.3243) Grad: inf  LR: 0.00000999  \n","Epoch: [3][20/646] Elapsed 0m 3s (remain 1m 57s) Loss: 0.2110(0.3501) Grad: 84546.7500  LR: 0.00000974  \n","Epoch: [3][40/646] Elapsed 0m 6s (remain 1m 37s) Loss: 0.3684(0.3475) Grad: 71167.8359  LR: 0.00000950  \n","Epoch: [3][60/646] Elapsed 0m 9s (remain 1m 31s) Loss: 0.2248(0.3408) Grad: 34614.6484  LR: 0.00000926  \n","Epoch: [3][80/646] Elapsed 0m 12s (remain 1m 28s) Loss: 0.3624(0.3320) Grad: 128854.6641  LR: 0.00000902  \n","Epoch: [3][100/646] Elapsed 0m 16s (remain 1m 28s) Loss: 0.3376(0.3306) Grad: 67594.3828  LR: 0.00000878  \n","Epoch: [3][120/646] Elapsed 0m 20s (remain 1m 28s) Loss: 0.2871(0.3258) Grad: 89288.9453  LR: 0.00000853  \n","Epoch: [3][140/646] Elapsed 0m 23s (remain 1m 23s) Loss: 0.3647(0.3251) Grad: 33724.3047  LR: 0.00000829  \n","Epoch: [3][160/646] Elapsed 0m 26s (remain 1m 19s) Loss: 0.3935(0.3226) Grad: 64703.6172  LR: 0.00000806  \n","Epoch: [3][180/646] Elapsed 0m 29s (remain 1m 14s) Loss: 0.2767(0.3227) Grad: 46252.2539  LR: 0.00000782  \n","Epoch: [3][200/646] Elapsed 0m 32s (remain 1m 11s) Loss: 0.2987(0.3239) Grad: 31463.8926  LR: 0.00000758  \n","Epoch: [3][220/646] Elapsed 0m 35s (remain 1m 9s) Loss: 0.3461(0.3227) Grad: 93286.2500  LR: 0.00000735  \n","Epoch: [3][240/646] Elapsed 0m 38s (remain 1m 5s) Loss: 0.3431(0.3214) Grad: 44305.2500  LR: 0.00000711  \n","Epoch: [3][260/646] Elapsed 0m 41s (remain 1m 1s) Loss: 0.4104(0.3205) Grad: 97059.9375  LR: 0.00000688  \n","Epoch: [3][280/646] Elapsed 0m 43s (remain 0m 57s) Loss: 0.3587(0.3199) Grad: 40911.0273  LR: 0.00000665  \n","Epoch: [3][300/646] Elapsed 0m 46s (remain 0m 53s) Loss: 0.2185(0.3194) Grad: 61556.8359  LR: 0.00000642  \n","Epoch: [3][320/646] Elapsed 0m 50s (remain 0m 50s) Loss: 0.2628(0.3191) Grad: 69988.3047  LR: 0.00000620  \n","Epoch: [3][340/646] Elapsed 0m 53s (remain 0m 47s) Loss: 0.2160(0.3188) Grad: 22859.2500  LR: 0.00000597  \n","Epoch: [3][360/646] Elapsed 0m 56s (remain 0m 44s) Loss: 0.4493(0.3190) Grad: 34538.3477  LR: 0.00000575  \n","Epoch: [3][380/646] Elapsed 0m 58s (remain 0m 40s) Loss: 0.2141(0.3200) Grad: 74386.4453  LR: 0.00000553  \n","Epoch: [3][400/646] Elapsed 1m 1s (remain 0m 37s) Loss: 0.2681(0.3186) Grad: 106337.8359  LR: 0.00000532  \n","Epoch: [3][420/646] Elapsed 1m 4s (remain 0m 34s) Loss: 0.2779(0.3166) Grad: 40449.6914  LR: 0.00000510  \n","Epoch: [3][440/646] Elapsed 1m 7s (remain 0m 31s) Loss: 0.3506(0.3149) Grad: 50246.6289  LR: 0.00000489  \n","Epoch: [3][460/646] Elapsed 1m 10s (remain 0m 28s) Loss: 0.3248(0.3145) Grad: 58748.6484  LR: 0.00000468  \n","Epoch: [3][480/646] Elapsed 1m 13s (remain 0m 25s) Loss: 0.3540(0.3133) Grad: 48898.2773  LR: 0.00000448  \n","Epoch: [3][500/646] Elapsed 1m 15s (remain 0m 21s) Loss: 0.4235(0.3132) Grad: 69116.1016  LR: 0.00000428  \n","Epoch: [3][520/646] Elapsed 1m 18s (remain 0m 18s) Loss: 0.2891(0.3130) Grad: 104429.8047  LR: 0.00000408  \n","Epoch: [3][540/646] Elapsed 1m 22s (remain 0m 15s) Loss: 0.3094(0.3132) Grad: 84996.6719  LR: 0.00000389  \n","Epoch: [3][560/646] Elapsed 1m 25s (remain 0m 12s) Loss: 0.3754(0.3136) Grad: 62156.4141  LR: 0.00000370  \n","Epoch: [3][580/646] Elapsed 1m 27s (remain 0m 9s) Loss: 0.3817(0.3139) Grad: 67910.5781  LR: 0.00000351  \n","Epoch: [3][600/646] Elapsed 1m 30s (remain 0m 6s) Loss: 0.2544(0.3129) Grad: 75761.9375  LR: 0.00000333  \n","Epoch: [3][620/646] Elapsed 1m 33s (remain 0m 3s) Loss: 0.3241(0.3126) Grad: 44588.2109  LR: 0.00000315  \n","Epoch: [3][640/646] Elapsed 1m 36s (remain 0m 0s) Loss: 0.3265(0.3117) Grad: 98940.9375  LR: 0.00000297  \n","Epoch: [3][645/646] Elapsed 1m 37s (remain 0m 0s) Loss: 0.3473(0.3115) Grad: 43492.6211  LR: 0.00000293  \n","EVAL: [0/125] Elapsed 0m 0s (remain 1m 15s) Loss: 0.4333(0.4333) \n","EVAL: [20/125] Elapsed 0m 2s (remain 0m 13s) Loss: 0.3814(0.3842) \n","EVAL: [40/125] Elapsed 0m 5s (remain 0m 11s) Loss: 0.3978(0.3947) \n","EVAL: [60/125] Elapsed 0m 7s (remain 0m 7s) Loss: 0.3662(0.3865) \n","EVAL: [80/125] Elapsed 0m 10s (remain 0m 5s) Loss: 0.3412(0.3840) \n","EVAL: [100/125] Elapsed 0m 12s (remain 0m 2s) Loss: 0.4346(0.3750) \n","EVAL: [120/125] Elapsed 0m 15s (remain 0m 0s) Loss: 0.3965(0.3772) \n","EVAL: [124/125] Elapsed 0m 15s (remain 0m 0s) Loss: 0.3862(0.3766) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3115  avg_val_loss: 0.3766  time: 113s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3115  avg_val_loss: 0.3766  time: 113s\n","Epoch 3 - Score: 0.4893  Scores: [0.4382612916737304, 0.540297933624206]\n","INFO:__main__:Epoch 3 - Score: 0.4893  Scores: [0.4382612916737304, 0.540297933624206]\n","Epoch 3 - Save Best Score: 0.4893 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4893 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/646] Elapsed 0m 0s (remain 4m 55s) Loss: 0.3921(0.3921) Grad: inf  LR: 0.00000292  \n","Epoch: [4][20/646] Elapsed 0m 2s (remain 1m 28s) Loss: 0.2513(0.2841) Grad: 103773.9141  LR: 0.00000275  \n","Epoch: [4][40/646] Elapsed 0m 5s (remain 1m 25s) Loss: 0.3152(0.2880) Grad: 67868.6328  LR: 0.00000259  \n","Epoch: [4][60/646] Elapsed 0m 10s (remain 1m 40s) Loss: 0.2501(0.2856) Grad: 39590.5547  LR: 0.00000242  \n","Epoch: [4][80/646] Elapsed 0m 14s (remain 1m 38s) Loss: 0.2226(0.2827) Grad: 31584.4590  LR: 0.00000227  \n","Epoch: [4][100/646] Elapsed 0m 17s (remain 1m 34s) Loss: 0.2113(0.2779) Grad: 70532.0000  LR: 0.00000212  \n","Epoch: [4][120/646] Elapsed 0m 20s (remain 1m 27s) Loss: 0.2695(0.2812) Grad: 93199.8828  LR: 0.00000197  \n","Epoch: [4][140/646] Elapsed 0m 23s (remain 1m 23s) Loss: 0.2882(0.2809) Grad: 60256.7344  LR: 0.00000183  \n","Epoch: [4][160/646] Elapsed 0m 26s (remain 1m 20s) Loss: 0.2480(0.2799) Grad: 48613.7383  LR: 0.00000169  \n","Epoch: [4][180/646] Elapsed 0m 29s (remain 1m 16s) Loss: 0.3161(0.2803) Grad: 62168.0039  LR: 0.00000156  \n","Epoch: [4][200/646] Elapsed 0m 32s (remain 1m 11s) Loss: 0.3226(0.2804) Grad: 45562.2539  LR: 0.00000143  \n","Epoch: [4][220/646] Elapsed 0m 35s (remain 1m 7s) Loss: 0.2200(0.2790) Grad: 95280.3125  LR: 0.00000131  \n","Epoch: [4][240/646] Elapsed 0m 37s (remain 1m 3s) Loss: 0.1659(0.2748) Grad: 75104.1875  LR: 0.00000119  \n","Epoch: [4][260/646] Elapsed 0m 41s (remain 1m 1s) Loss: 0.3673(0.2750) Grad: 76244.7578  LR: 0.00000108  \n","Epoch: [4][280/646] Elapsed 0m 44s (remain 0m 57s) Loss: 0.2644(0.2730) Grad: 47914.4805  LR: 0.00000097  \n","Epoch: [4][300/646] Elapsed 0m 47s (remain 0m 54s) Loss: 0.2375(0.2713) Grad: 50308.5742  LR: 0.00000087  \n","Epoch: [4][320/646] Elapsed 0m 49s (remain 0m 50s) Loss: 0.2821(0.2721) Grad: 57871.9141  LR: 0.00000077  \n","Epoch: [4][340/646] Elapsed 0m 52s (remain 0m 47s) Loss: 0.2335(0.2725) Grad: 49030.6719  LR: 0.00000068  \n","Epoch: [4][360/646] Elapsed 0m 56s (remain 0m 44s) Loss: 0.2180(0.2728) Grad: 40603.2812  LR: 0.00000059  \n","Epoch: [4][380/646] Elapsed 0m 59s (remain 0m 41s) Loss: 0.2334(0.2730) Grad: 44939.5039  LR: 0.00000051  \n","Epoch: [4][400/646] Elapsed 1m 1s (remain 0m 37s) Loss: 0.2287(0.2717) Grad: 50461.7109  LR: 0.00000044  \n","Epoch: [4][420/646] Elapsed 1m 4s (remain 0m 34s) Loss: 0.4543(0.2719) Grad: 58204.7188  LR: 0.00000037  \n","Epoch: [4][440/646] Elapsed 1m 7s (remain 0m 31s) Loss: 0.3075(0.2704) Grad: 66967.3281  LR: 0.00000031  \n","Epoch: [4][460/646] Elapsed 1m 10s (remain 0m 28s) Loss: 0.1655(0.2695) Grad: 81888.3906  LR: 0.00000025  \n","Epoch: [4][480/646] Elapsed 1m 13s (remain 0m 25s) Loss: 0.2464(0.2690) Grad: 69386.9141  LR: 0.00000020  \n","Epoch: [4][500/646] Elapsed 1m 16s (remain 0m 22s) Loss: 0.1627(0.2682) Grad: 64154.9062  LR: 0.00000015  \n","Epoch: [4][520/646] Elapsed 1m 18s (remain 0m 18s) Loss: 0.2549(0.2682) Grad: 51441.6562  LR: 0.00000012  \n","Epoch: [4][540/646] Elapsed 1m 21s (remain 0m 15s) Loss: 0.2626(0.2684) Grad: 67859.4375  LR: 0.00000008  \n","Epoch: [4][560/646] Elapsed 1m 24s (remain 0m 12s) Loss: 0.2193(0.2684) Grad: 51941.3125  LR: 0.00000005  \n","Epoch: [4][580/646] Elapsed 1m 27s (remain 0m 9s) Loss: 0.4033(0.2690) Grad: 50894.7773  LR: 0.00000003  \n","Epoch: [4][600/646] Elapsed 1m 30s (remain 0m 6s) Loss: 0.2343(0.2687) Grad: 71801.6250  LR: 0.00000001  \n","Epoch: [4][620/646] Elapsed 1m 33s (remain 0m 3s) Loss: 0.3098(0.2687) Grad: 50758.5391  LR: 0.00000000  \n","Epoch: [4][640/646] Elapsed 1m 35s (remain 0m 0s) Loss: 0.2341(0.2685) Grad: 41601.0859  LR: 0.00000000  \n","Epoch: [4][645/646] Elapsed 1m 36s (remain 0m 0s) Loss: 0.3189(0.2688) Grad: 44027.8789  LR: 0.00000000  \n","EVAL: [0/125] Elapsed 0m 0s (remain 0m 56s) Loss: 0.4155(0.4155) \n","EVAL: [20/125] Elapsed 0m 2s (remain 0m 12s) Loss: 0.3845(0.3806) \n","EVAL: [40/125] Elapsed 0m 5s (remain 0m 11s) Loss: 0.3767(0.3923) \n","EVAL: [60/125] Elapsed 0m 7s (remain 0m 8s) Loss: 0.3500(0.3834) \n","EVAL: [80/125] Elapsed 0m 10s (remain 0m 5s) Loss: 0.3453(0.3823) \n","EVAL: [100/125] Elapsed 0m 12s (remain 0m 3s) Loss: 0.4423(0.3732) \n","EVAL: [120/125] Elapsed 0m 15s (remain 0m 0s) Loss: 0.3768(0.3761) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2688  avg_val_loss: 0.3755  time: 112s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2688  avg_val_loss: 0.3755  time: 112s\n","Epoch 4 - Score: 0.4887  Scores: [0.4346408853659621, 0.5426880252135402]\n","INFO:__main__:Epoch 4 - Score: 0.4887  Scores: [0.4346408853659621, 0.5426880252135402]\n","Epoch 4 - Save Best Score: 0.4887 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.4887 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [124/125] Elapsed 0m 15s (remain 0m 0s) Loss: 0.3819(0.3755) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.4887  Scores: [0.4346408853659621, 0.5426880252135402]\n","INFO:__main__:Score: 0.4887  Scores: [0.4346408853659621, 0.5426880252135402]\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["========== prompt_id: ['814d6b'] validation ==========\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/757] Elapsed 0m 0s (remain 5m 8s) Loss: 0.9539(0.9539) Grad: inf  LR: 0.00002000  \n","Epoch: [1][20/757] Elapsed 0m 3s (remain 2m 10s) Loss: 0.5220(0.8740) Grad: 83291.8906  LR: 0.00002000  \n","Epoch: [1][40/757] Elapsed 0m 6s (remain 1m 54s) Loss: 0.5022(0.7402) Grad: 73173.4531  LR: 0.00001999  \n","Epoch: [1][60/757] Elapsed 0m 9s (remain 1m 49s) Loss: 0.5342(0.6783) Grad: 108182.3203  LR: 0.00001998  \n","Epoch: [1][80/757] Elapsed 0m 14s (remain 1m 57s) Loss: 0.5708(0.6546) Grad: 94036.2812  LR: 0.00001996  \n","Epoch: [1][100/757] Elapsed 0m 17s (remain 1m 54s) Loss: 0.4723(0.6225) Grad: 45829.6602  LR: 0.00001995  \n","Epoch: [1][120/757] Elapsed 0m 20s (remain 1m 48s) Loss: 0.4976(0.6120) Grad: 60603.8281  LR: 0.00001992  \n","Epoch: [1][140/757] Elapsed 0m 23s (remain 1m 41s) Loss: 0.5753(0.6039) Grad: 105883.1406  LR: 0.00001989  \n","Epoch: [1][160/757] Elapsed 0m 26s (remain 1m 37s) Loss: 0.3379(0.5875) Grad: 38797.7383  LR: 0.00001986  \n","Epoch: [1][180/757] Elapsed 0m 29s (remain 1m 34s) Loss: 0.3723(0.5725) Grad: 116639.6250  LR: 0.00001982  \n","Epoch: [1][200/757] Elapsed 0m 32s (remain 1m 30s) Loss: 0.5282(0.5598) Grad: 54704.7734  LR: 0.00001978  \n","Epoch: [1][220/757] Elapsed 0m 35s (remain 1m 25s) Loss: 0.5190(0.5485) Grad: 59732.9766  LR: 0.00001974  \n","Epoch: [1][240/757] Elapsed 0m 37s (remain 1m 21s) Loss: 0.4395(0.5411) Grad: 67592.8594  LR: 0.00001969  \n","Epoch: [1][260/757] Elapsed 0m 40s (remain 1m 17s) Loss: 0.4956(0.5327) Grad: 67408.4844  LR: 0.00001964  \n","Epoch: [1][280/757] Elapsed 0m 44s (remain 1m 14s) Loss: 0.4561(0.5294) Grad: 76175.0625  LR: 0.00001958  \n","Epoch: [1][300/757] Elapsed 0m 47s (remain 1m 11s) Loss: 0.3403(0.5218) Grad: 79660.4453  LR: 0.00001952  \n","Epoch: [1][320/757] Elapsed 0m 50s (remain 1m 8s) Loss: 0.5826(0.5145) Grad: 68522.9844  LR: 0.00001945  \n","Epoch: [1][340/757] Elapsed 0m 52s (remain 1m 4s) Loss: 0.3335(0.5094) Grad: 63175.1406  LR: 0.00001938  \n","Epoch: [1][360/757] Elapsed 0m 55s (remain 1m 0s) Loss: 0.4571(0.5043) Grad: 120407.4609  LR: 0.00001931  \n","Epoch: [1][380/757] Elapsed 0m 58s (remain 0m 57s) Loss: 0.3576(0.4999) Grad: 35187.6875  LR: 0.00001923  \n","Epoch: [1][400/757] Elapsed 1m 1s (remain 0m 54s) Loss: 0.2449(0.4933) Grad: 56453.0000  LR: 0.00001915  \n","Epoch: [1][420/757] Elapsed 1m 4s (remain 0m 51s) Loss: 0.4856(0.4886) Grad: 68716.9297  LR: 0.00001906  \n","Epoch: [1][440/757] Elapsed 1m 7s (remain 0m 48s) Loss: 0.3913(0.4845) Grad: 48484.4492  LR: 0.00001897  \n","Epoch: [1][460/757] Elapsed 1m 10s (remain 0m 45s) Loss: 0.4508(0.4818) Grad: 36918.4219  LR: 0.00001888  \n","Epoch: [1][480/757] Elapsed 1m 13s (remain 0m 42s) Loss: 0.4325(0.4787) Grad: 95334.7578  LR: 0.00001878  \n","Epoch: [1][500/757] Elapsed 1m 16s (remain 0m 39s) Loss: 0.3227(0.4786) Grad: 57788.5938  LR: 0.00001868  \n","Epoch: [1][520/757] Elapsed 1m 20s (remain 0m 36s) Loss: 0.2697(0.4754) Grad: 71216.2109  LR: 0.00001858  \n","Epoch: [1][540/757] Elapsed 1m 22s (remain 0m 32s) Loss: 0.3631(0.4712) Grad: 64201.1836  LR: 0.00001847  \n","Epoch: [1][560/757] Elapsed 1m 25s (remain 0m 29s) Loss: 0.4209(0.4687) Grad: 106088.4141  LR: 0.00001836  \n","Epoch: [1][580/757] Elapsed 1m 27s (remain 0m 26s) Loss: 0.4158(0.4659) Grad: 67942.1484  LR: 0.00001824  \n","Epoch: [1][600/757] Elapsed 1m 31s (remain 0m 23s) Loss: 0.5462(0.4639) Grad: 140409.2969  LR: 0.00001812  \n","Epoch: [1][620/757] Elapsed 1m 34s (remain 0m 20s) Loss: 0.3903(0.4608) Grad: 76746.6953  LR: 0.00001800  \n","Epoch: [1][640/757] Elapsed 1m 37s (remain 0m 17s) Loss: 0.3824(0.4585) Grad: 84156.0547  LR: 0.00001787  \n","Epoch: [1][660/757] Elapsed 1m 39s (remain 0m 14s) Loss: 0.3023(0.4564) Grad: 81962.5469  LR: 0.00001774  \n","Epoch: [1][680/757] Elapsed 1m 42s (remain 0m 11s) Loss: 0.5092(0.4542) Grad: 83273.9531  LR: 0.00001761  \n","Epoch: [1][700/757] Elapsed 1m 45s (remain 0m 8s) Loss: 0.3400(0.4523) Grad: 89287.2969  LR: 0.00001747  \n","Epoch: [1][720/757] Elapsed 1m 49s (remain 0m 5s) Loss: 0.2676(0.4512) Grad: 109291.1562  LR: 0.00001734  \n","Epoch: [1][740/757] Elapsed 1m 51s (remain 0m 2s) Loss: 0.3679(0.4491) Grad: 74247.8203  LR: 0.00001719  \n","Epoch: [1][756/757] Elapsed 1m 54s (remain 0m 0s) Loss: 0.5126(0.4484) Grad: 48337.2930  LR: 0.00001708  \n","EVAL: [0/69] Elapsed 0m 0s (remain 0m 28s) Loss: 0.6324(0.6324) \n","EVAL: [20/69] Elapsed 0m 2s (remain 0m 4s) Loss: 0.4315(0.4601) \n","EVAL: [40/69] Elapsed 0m 4s (remain 0m 2s) Loss: 0.4571(0.4588) \n","EVAL: [60/69] Elapsed 0m 6s (remain 0m 0s) Loss: 0.3741(0.4599) \n","EVAL: [68/69] Elapsed 0m 7s (remain 0m 0s) Loss: 0.5972(0.4637) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.4484  avg_val_loss: 0.4637  time: 121s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4484  avg_val_loss: 0.4637  time: 121s\n","Epoch 1 - Score: 0.6171  Scores: [0.5259867316357357, 0.7081533520930183]\n","INFO:__main__:Epoch 1 - Score: 0.6171  Scores: [0.5259867316357357, 0.7081533520930183]\n","Epoch 1 - Save Best Score: 0.6171 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.6171 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/757] Elapsed 0m 0s (remain 6m 35s) Loss: 0.3636(0.3636) Grad: inf  LR: 0.00001707  \n","Epoch: [2][20/757] Elapsed 0m 3s (remain 1m 49s) Loss: 0.2929(0.3716) Grad: 68157.5469  LR: 0.00001692  \n","Epoch: [2][40/757] Elapsed 0m 6s (remain 1m 45s) Loss: 0.3403(0.3679) Grad: 52149.8320  LR: 0.00001677  \n","Epoch: [2][60/757] Elapsed 0m 9s (remain 1m 46s) Loss: 0.3824(0.3532) Grad: 73868.0078  LR: 0.00001662  \n","Epoch: [2][80/757] Elapsed 0m 13s (remain 1m 51s) Loss: 0.2514(0.3482) Grad: 29947.9473  LR: 0.00001646  \n","Epoch: [2][100/757] Elapsed 0m 17s (remain 1m 51s) Loss: 0.4355(0.3511) Grad: 47176.4219  LR: 0.00001630  \n","Epoch: [2][120/757] Elapsed 0m 20s (remain 1m 47s) Loss: 0.3975(0.3482) Grad: 96243.2500  LR: 0.00001614  \n","Epoch: [2][140/757] Elapsed 0m 23s (remain 1m 41s) Loss: 0.4703(0.3494) Grad: 59501.0117  LR: 0.00001597  \n","Epoch: [2][160/757] Elapsed 0m 26s (remain 1m 36s) Loss: 0.4240(0.3507) Grad: 24360.5762  LR: 0.00001580  \n","Epoch: [2][180/757] Elapsed 0m 29s (remain 1m 33s) Loss: 0.3315(0.3480) Grad: 86005.6328  LR: 0.00001563  \n","Epoch: [2][200/757] Elapsed 0m 32s (remain 1m 29s) Loss: 0.3374(0.3485) Grad: 85870.5781  LR: 0.00001546  \n","Epoch: [2][220/757] Elapsed 0m 35s (remain 1m 25s) Loss: 0.1736(0.3479) Grad: 54763.9648  LR: 0.00001529  \n","Epoch: [2][240/757] Elapsed 0m 37s (remain 1m 20s) Loss: 0.4449(0.3483) Grad: 72627.5000  LR: 0.00001511  \n","Epoch: [2][260/757] Elapsed 0m 40s (remain 1m 16s) Loss: 0.4159(0.3482) Grad: 58840.9102  LR: 0.00001493  \n","Epoch: [2][280/757] Elapsed 0m 43s (remain 1m 14s) Loss: 0.2869(0.3478) Grad: 44753.7734  LR: 0.00001475  \n","Epoch: [2][300/757] Elapsed 0m 47s (remain 1m 11s) Loss: 0.2579(0.3461) Grad: 84444.2266  LR: 0.00001457  \n","Epoch: [2][320/757] Elapsed 0m 50s (remain 1m 8s) Loss: 0.4454(0.3503) Grad: 168747.7500  LR: 0.00001438  \n","Epoch: [2][340/757] Elapsed 0m 52s (remain 1m 4s) Loss: 0.4551(0.3506) Grad: 40179.9102  LR: 0.00001419  \n","Epoch: [2][360/757] Elapsed 0m 55s (remain 1m 0s) Loss: 0.3055(0.3492) Grad: 85202.4375  LR: 0.00001400  \n","Epoch: [2][380/757] Elapsed 0m 58s (remain 0m 57s) Loss: 0.3753(0.3494) Grad: 63991.4922  LR: 0.00001381  \n","Epoch: [2][400/757] Elapsed 1m 1s (remain 0m 54s) Loss: 0.3508(0.3490) Grad: 83491.1641  LR: 0.00001362  \n","Epoch: [2][420/757] Elapsed 1m 4s (remain 0m 51s) Loss: 0.4037(0.3489) Grad: 84573.1875  LR: 0.00001343  \n","Epoch: [2][440/757] Elapsed 1m 7s (remain 0m 48s) Loss: 0.2666(0.3484) Grad: 56925.9102  LR: 0.00001323  \n","Epoch: [2][460/757] Elapsed 1m 9s (remain 0m 44s) Loss: 0.2922(0.3486) Grad: 106386.7969  LR: 0.00001303  \n","Epoch: [2][480/757] Elapsed 1m 13s (remain 0m 41s) Loss: 0.3906(0.3486) Grad: 64629.0938  LR: 0.00001284  \n","Epoch: [2][500/757] Elapsed 1m 16s (remain 0m 39s) Loss: 0.3621(0.3481) Grad: 35957.4883  LR: 0.00001264  \n","Epoch: [2][520/757] Elapsed 1m 19s (remain 0m 35s) Loss: 0.2664(0.3473) Grad: 88755.5703  LR: 0.00001244  \n","Epoch: [2][540/757] Elapsed 1m 21s (remain 0m 32s) Loss: 0.3442(0.3471) Grad: 82561.2344  LR: 0.00001224  \n","Epoch: [2][560/757] Elapsed 1m 24s (remain 0m 29s) Loss: 0.2999(0.3467) Grad: 65878.2031  LR: 0.00001203  \n","Epoch: [2][580/757] Elapsed 1m 27s (remain 0m 26s) Loss: 0.5074(0.3475) Grad: 46457.4609  LR: 0.00001183  \n","Epoch: [2][600/757] Elapsed 1m 30s (remain 0m 23s) Loss: 0.3037(0.3470) Grad: 47037.3477  LR: 0.00001163  \n","Epoch: [2][620/757] Elapsed 1m 33s (remain 0m 20s) Loss: 0.2559(0.3468) Grad: 81157.9531  LR: 0.00001142  \n","Epoch: [2][640/757] Elapsed 1m 36s (remain 0m 17s) Loss: 0.3452(0.3475) Grad: 106787.1953  LR: 0.00001121  \n","Epoch: [2][660/757] Elapsed 1m 39s (remain 0m 14s) Loss: 0.3116(0.3480) Grad: 105051.2891  LR: 0.00001101  \n","Epoch: [2][680/757] Elapsed 1m 41s (remain 0m 11s) Loss: 0.3664(0.3486) Grad: 55588.9102  LR: 0.00001080  \n","Epoch: [2][700/757] Elapsed 1m 45s (remain 0m 8s) Loss: 0.2498(0.3492) Grad: 67538.4297  LR: 0.00001060  \n","Epoch: [2][720/757] Elapsed 1m 48s (remain 0m 5s) Loss: 0.2889(0.3494) Grad: 58890.7266  LR: 0.00001039  \n","Epoch: [2][740/757] Elapsed 1m 51s (remain 0m 2s) Loss: 0.3509(0.3492) Grad: 73999.5703  LR: 0.00001018  \n","Epoch: [2][756/757] Elapsed 1m 53s (remain 0m 0s) Loss: 0.3369(0.3486) Grad: 50320.5898  LR: 0.00001002  \n","EVAL: [0/69] Elapsed 0m 0s (remain 0m 27s) Loss: 0.6034(0.6034) \n","EVAL: [20/69] Elapsed 0m 2s (remain 0m 4s) Loss: 0.4102(0.4506) \n","EVAL: [40/69] Elapsed 0m 4s (remain 0m 2s) Loss: 0.4595(0.4427) \n","EVAL: [60/69] Elapsed 0m 6s (remain 0m 0s) Loss: 0.3504(0.4416) \n","EVAL: [68/69] Elapsed 0m 7s (remain 0m 0s) Loss: 0.5969(0.4452) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3486  avg_val_loss: 0.4452  time: 121s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3486  avg_val_loss: 0.4452  time: 121s\n","Epoch 2 - Score: 0.6021  Scores: [0.5145460976373987, 0.6895539269120516]\n","INFO:__main__:Epoch 2 - Score: 0.6021  Scores: [0.5145460976373987, 0.6895539269120516]\n","Epoch 2 - Save Best Score: 0.6021 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.6021 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/757] Elapsed 0m 0s (remain 5m 24s) Loss: 0.2707(0.2707) Grad: inf  LR: 0.00001001  \n","Epoch: [3][20/757] Elapsed 0m 3s (remain 1m 54s) Loss: 0.2694(0.3238) Grad: 63399.6133  LR: 0.00000980  \n","Epoch: [3][40/757] Elapsed 0m 5s (remain 1m 41s) Loss: 0.2238(0.3146) Grad: 21971.7656  LR: 0.00000959  \n","Epoch: [3][60/757] Elapsed 0m 9s (remain 1m 48s) Loss: 0.1961(0.3059) Grad: 86342.3828  LR: 0.00000938  \n","Epoch: [3][80/757] Elapsed 0m 13s (remain 1m 55s) Loss: 0.2703(0.3005) Grad: 60897.2539  LR: 0.00000918  \n","Epoch: [3][100/757] Elapsed 0m 17s (remain 1m 53s) Loss: 0.4327(0.2967) Grad: 62268.2109  LR: 0.00000897  \n","Epoch: [3][120/757] Elapsed 0m 20s (remain 1m 47s) Loss: 0.2753(0.2954) Grad: 68757.1172  LR: 0.00000876  \n","Epoch: [3][140/757] Elapsed 0m 23s (remain 1m 42s) Loss: 0.2410(0.3008) Grad: 34306.0508  LR: 0.00000856  \n","Epoch: [3][160/757] Elapsed 0m 26s (remain 1m 38s) Loss: 0.2841(0.3046) Grad: 120269.5234  LR: 0.00000835  \n","Epoch: [3][180/757] Elapsed 0m 30s (remain 1m 36s) Loss: 0.4003(0.3044) Grad: 28546.5527  LR: 0.00000815  \n","Epoch: [3][200/757] Elapsed 0m 32s (remain 1m 31s) Loss: 0.3750(0.3016) Grad: 108351.8594  LR: 0.00000795  \n","Epoch: [3][220/757] Elapsed 0m 35s (remain 1m 26s) Loss: 0.2512(0.3002) Grad: 83030.3672  LR: 0.00000774  \n","Epoch: [3][240/757] Elapsed 0m 38s (remain 1m 21s) Loss: 0.2333(0.2981) Grad: 69096.7109  LR: 0.00000754  \n","Epoch: [3][260/757] Elapsed 0m 41s (remain 1m 18s) Loss: 0.4989(0.2995) Grad: 82002.6016  LR: 0.00000734  \n","Epoch: [3][280/757] Elapsed 0m 44s (remain 1m 15s) Loss: 0.2564(0.2988) Grad: 55431.4023  LR: 0.00000714  \n","Epoch: [3][300/757] Elapsed 0m 47s (remain 1m 12s) Loss: 0.2755(0.2993) Grad: 38960.5039  LR: 0.00000695  \n","Epoch: [3][320/757] Elapsed 0m 50s (remain 1m 8s) Loss: 0.2858(0.2976) Grad: 58851.2656  LR: 0.00000675  \n","Epoch: [3][340/757] Elapsed 0m 53s (remain 1m 4s) Loss: 0.4413(0.2982) Grad: 49286.5469  LR: 0.00000655  \n","Epoch: [3][360/757] Elapsed 0m 55s (remain 1m 1s) Loss: 0.4157(0.2983) Grad: 54865.8125  LR: 0.00000636  \n","Epoch: [3][380/757] Elapsed 0m 59s (remain 0m 58s) Loss: 0.3911(0.2983) Grad: 101544.2344  LR: 0.00000617  \n","Epoch: [3][400/757] Elapsed 1m 2s (remain 0m 55s) Loss: 0.3035(0.2989) Grad: 62883.5938  LR: 0.00000598  \n","Epoch: [3][420/757] Elapsed 1m 5s (remain 0m 52s) Loss: 0.2804(0.2979) Grad: 62553.5195  LR: 0.00000579  \n","Epoch: [3][440/757] Elapsed 1m 7s (remain 0m 48s) Loss: 0.3643(0.2991) Grad: 86730.8828  LR: 0.00000560  \n","Epoch: [3][460/757] Elapsed 1m 10s (remain 0m 45s) Loss: 0.4286(0.2983) Grad: 64063.4805  LR: 0.00000542  \n","Epoch: [3][480/757] Elapsed 1m 13s (remain 0m 42s) Loss: 0.3542(0.2979) Grad: 58992.1680  LR: 0.00000523  \n","Epoch: [3][500/757] Elapsed 1m 17s (remain 0m 39s) Loss: 0.3986(0.2981) Grad: 92480.3984  LR: 0.00000505  \n","Epoch: [3][520/757] Elapsed 1m 20s (remain 0m 36s) Loss: 0.2607(0.2980) Grad: 70099.0938  LR: 0.00000487  \n","Epoch: [3][540/757] Elapsed 1m 22s (remain 0m 33s) Loss: 0.3470(0.2986) Grad: 104543.7031  LR: 0.00000470  \n","Epoch: [3][560/757] Elapsed 1m 25s (remain 0m 29s) Loss: 0.3379(0.2983) Grad: 85590.4141  LR: 0.00000452  \n","Epoch: [3][580/757] Elapsed 1m 28s (remain 0m 26s) Loss: 0.2620(0.2979) Grad: 34473.3633  LR: 0.00000435  \n","Epoch: [3][600/757] Elapsed 1m 32s (remain 0m 24s) Loss: 0.3283(0.2981) Grad: 92250.6562  LR: 0.00000418  \n","Epoch: [3][620/757] Elapsed 1m 35s (remain 0m 20s) Loss: 0.2989(0.2983) Grad: 123530.2891  LR: 0.00000401  \n","Epoch: [3][640/757] Elapsed 1m 37s (remain 0m 17s) Loss: 0.2876(0.2976) Grad: 40849.1055  LR: 0.00000385  \n","Epoch: [3][660/757] Elapsed 1m 40s (remain 0m 14s) Loss: 0.3224(0.2989) Grad: 33609.2891  LR: 0.00000368  \n","Epoch: [3][680/757] Elapsed 1m 43s (remain 0m 11s) Loss: 0.3106(0.2989) Grad: 52700.4414  LR: 0.00000353  \n","Epoch: [3][700/757] Elapsed 1m 47s (remain 0m 8s) Loss: 0.3427(0.2988) Grad: 50076.8672  LR: 0.00000337  \n","Epoch: [3][720/757] Elapsed 1m 50s (remain 0m 5s) Loss: 0.3803(0.2987) Grad: 56753.3555  LR: 0.00000321  \n","Epoch: [3][740/757] Elapsed 1m 52s (remain 0m 2s) Loss: 0.2223(0.2979) Grad: 60334.9102  LR: 0.00000306  \n","Epoch: [3][756/757] Elapsed 1m 54s (remain 0m 0s) Loss: 0.2686(0.2976) Grad: 62613.6719  LR: 0.00000295  \n","EVAL: [0/69] Elapsed 0m 0s (remain 0m 26s) Loss: 0.6317(0.6317) \n","EVAL: [20/69] Elapsed 0m 2s (remain 0m 4s) Loss: 0.4378(0.4983) \n","EVAL: [40/69] Elapsed 0m 4s (remain 0m 2s) Loss: 0.4987(0.4942) \n","EVAL: [60/69] Elapsed 0m 6s (remain 0m 0s) Loss: 0.3476(0.4893) \n","EVAL: [68/69] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6293(0.4933) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2976  avg_val_loss: 0.4933  time: 123s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2976  avg_val_loss: 0.4933  time: 123s\n","Epoch 3 - Score: 0.6566  Scores: [0.5716195355823235, 0.7414901577494691]\n","INFO:__main__:Epoch 3 - Score: 0.6566  Scores: [0.5716195355823235, 0.7414901577494691]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/757] Elapsed 0m 0s (remain 7m 32s) Loss: 0.1616(0.1616) Grad: inf  LR: 0.00000294  \n","Epoch: [4][20/757] Elapsed 0m 3s (remain 2m 9s) Loss: 0.5199(0.2857) Grad: 146416.6719  LR: 0.00000279  \n","Epoch: [4][40/757] Elapsed 0m 6s (remain 1m 54s) Loss: 0.2749(0.2751) Grad: 27535.4121  LR: 0.00000265  \n","Epoch: [4][60/757] Elapsed 0m 9s (remain 1m 45s) Loss: 0.3937(0.2830) Grad: 64988.4883  LR: 0.00000251  \n","Epoch: [4][80/757] Elapsed 0m 12s (remain 1m 40s) Loss: 0.2893(0.2756) Grad: 45759.1016  LR: 0.00000238  \n","Epoch: [4][100/757] Elapsed 0m 15s (remain 1m 40s) Loss: 0.2371(0.2750) Grad: 47191.4609  LR: 0.00000224  \n","Epoch: [4][120/757] Elapsed 0m 18s (remain 1m 37s) Loss: 0.3578(0.2752) Grad: 90891.1406  LR: 0.00000211  \n","Epoch: [4][140/757] Elapsed 0m 21s (remain 1m 32s) Loss: 0.3273(0.2723) Grad: 66231.0156  LR: 0.00000199  \n","Epoch: [4][160/757] Elapsed 0m 23s (remain 1m 28s) Loss: 0.2653(0.2702) Grad: 34325.6992  LR: 0.00000187  \n","Epoch: [4][180/757] Elapsed 0m 26s (remain 1m 24s) Loss: 0.2958(0.2676) Grad: 36612.6445  LR: 0.00000175  \n","Epoch: [4][200/757] Elapsed 0m 29s (remain 1m 21s) Loss: 0.3605(0.2672) Grad: 42621.7891  LR: 0.00000163  \n","Epoch: [4][220/757] Elapsed 0m 33s (remain 1m 20s) Loss: 0.2093(0.2657) Grad: 43749.9062  LR: 0.00000152  \n","Epoch: [4][240/757] Elapsed 0m 35s (remain 1m 16s) Loss: 0.3450(0.2654) Grad: 23768.4961  LR: 0.00000141  \n","Epoch: [4][260/757] Elapsed 0m 38s (remain 1m 13s) Loss: 0.2411(0.2661) Grad: 44692.8164  LR: 0.00000131  \n","Epoch: [4][280/757] Elapsed 0m 41s (remain 1m 9s) Loss: 0.3503(0.2663) Grad: 65949.0234  LR: 0.00000121  \n","Epoch: [4][300/757] Elapsed 0m 44s (remain 1m 7s) Loss: 0.2082(0.2664) Grad: 60708.8438  LR: 0.00000111  \n","Epoch: [4][320/757] Elapsed 0m 47s (remain 1m 4s) Loss: 0.2514(0.2665) Grad: 72911.6484  LR: 0.00000102  \n","Epoch: [4][340/757] Elapsed 0m 50s (remain 1m 1s) Loss: 0.2486(0.2668) Grad: 45972.1562  LR: 0.00000093  \n","Epoch: [4][360/757] Elapsed 0m 53s (remain 0m 58s) Loss: 0.3509(0.2674) Grad: 46527.2266  LR: 0.00000084  \n","Epoch: [4][380/757] Elapsed 0m 55s (remain 0m 55s) Loss: 0.3701(0.2670) Grad: 65597.9062  LR: 0.00000076  \n","Epoch: [4][400/757] Elapsed 0m 58s (remain 0m 51s) Loss: 0.2595(0.2664) Grad: 70456.3594  LR: 0.00000068  \n","Epoch: [4][420/757] Elapsed 1m 1s (remain 0m 49s) Loss: 0.2958(0.2660) Grad: 103155.9766  LR: 0.00000061  \n","Epoch: [4][440/757] Elapsed 1m 5s (remain 0m 46s) Loss: 0.1926(0.2647) Grad: 86119.1562  LR: 0.00000054  \n","Epoch: [4][460/757] Elapsed 1m 7s (remain 0m 43s) Loss: 0.2534(0.2646) Grad: 61579.3125  LR: 0.00000048  \n","Epoch: [4][480/757] Elapsed 1m 10s (remain 0m 40s) Loss: 0.2971(0.2648) Grad: 82283.9375  LR: 0.00000042  \n","Epoch: [4][500/757] Elapsed 1m 13s (remain 0m 37s) Loss: 0.2613(0.2655) Grad: 48052.5039  LR: 0.00000036  \n","Epoch: [4][520/757] Elapsed 1m 16s (remain 0m 34s) Loss: 0.2190(0.2645) Grad: 106042.7344  LR: 0.00000031  \n","Epoch: [4][540/757] Elapsed 1m 20s (remain 0m 32s) Loss: 0.1998(0.2641) Grad: 49683.2109  LR: 0.00000026  \n","Epoch: [4][560/757] Elapsed 1m 22s (remain 0m 28s) Loss: 0.1915(0.2634) Grad: 64334.9805  LR: 0.00000021  \n","Epoch: [4][580/757] Elapsed 1m 25s (remain 0m 25s) Loss: 0.2549(0.2630) Grad: 46563.6211  LR: 0.00000017  \n","Epoch: [4][600/757] Elapsed 1m 28s (remain 0m 22s) Loss: 0.3933(0.2626) Grad: 46975.6016  LR: 0.00000014  \n","Epoch: [4][620/757] Elapsed 1m 31s (remain 0m 20s) Loss: 0.2885(0.2622) Grad: 56648.1133  LR: 0.00000010  \n","Epoch: [4][640/757] Elapsed 1m 35s (remain 0m 17s) Loss: 0.2275(0.2619) Grad: 52441.1797  LR: 0.00000008  \n","Epoch: [4][660/757] Elapsed 1m 37s (remain 0m 14s) Loss: 0.1604(0.2616) Grad: 61053.4062  LR: 0.00000005  \n","Epoch: [4][680/757] Elapsed 1m 40s (remain 0m 11s) Loss: 0.2516(0.2613) Grad: 17858.2500  LR: 0.00000003  \n","Epoch: [4][700/757] Elapsed 1m 43s (remain 0m 8s) Loss: 0.2633(0.2612) Grad: 47245.1406  LR: 0.00000002  \n","Epoch: [4][720/757] Elapsed 1m 46s (remain 0m 5s) Loss: 0.2988(0.2611) Grad: 37797.0859  LR: 0.00000001  \n","Epoch: [4][740/757] Elapsed 1m 49s (remain 0m 2s) Loss: 0.2257(0.2605) Grad: 69886.7734  LR: 0.00000000  \n","Epoch: [4][756/757] Elapsed 1m 52s (remain 0m 0s) Loss: 0.2861(0.2602) Grad: 89963.2266  LR: 0.00000000  \n","EVAL: [0/69] Elapsed 0m 0s (remain 0m 28s) Loss: 0.6368(0.6368) \n","EVAL: [20/69] Elapsed 0m 2s (remain 0m 4s) Loss: 0.4146(0.4794) \n","EVAL: [40/69] Elapsed 0m 4s (remain 0m 2s) Loss: 0.4785(0.4725) \n","EVAL: [60/69] Elapsed 0m 6s (remain 0m 0s) Loss: 0.3435(0.4684) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2602  avg_val_loss: 0.4721  time: 119s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2602  avg_val_loss: 0.4721  time: 119s\n","Epoch 4 - Score: 0.6354  Scores: [0.5732736873591963, 0.6974843745052304]\n","INFO:__main__:Epoch 4 - Score: 0.6354  Scores: [0.5732736873591963, 0.6974843745052304]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [68/69] Elapsed 0m 6s (remain 0m 0s) Loss: 0.6024(0.4721) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 3 result ==========\n"]}]},{"cell_type":"code","source":["runtime.unassign()"],"metadata":{"id":"Hyij14sOkLv8"},"execution_count":null,"outputs":[]}]}