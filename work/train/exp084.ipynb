{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyOWbpMlpP8kGF/WwiM8uDiv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rr85FWn_hyin","executionInfo":{"status":"ok","timestamp":1696874345319,"user_tz":-540,"elapsed":3009,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"333b305d-7d32-487f-db0f-bcd0578c15da"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install datasets\n","!pip install sentencepiece\n","!pip install transformers==4.21.2\n","!pip install tokenizers==0.12.1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ELMmTK3h2by","executionInfo":{"status":"ok","timestamp":1696874363119,"user_tz":-540,"elapsed":17804,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"f15ba93e-53fd-47d8-ee81-169675adc208"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n","Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Requirement already satisfied: transformers==4.21.2 in /usr/local/lib/python3.10/dist-packages (4.21.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (3.12.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (0.17.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (2.31.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (0.12.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.21.2) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.2) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.2) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.21.2) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.21.2) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.21.2) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.21.2) (2023.7.22)\n","Requirement already satisfied: tokenizers==0.12.1 in /usr/local/lib/python3.10/dist-packages (0.12.1)\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mHhBDONhh4Aa","executionInfo":{"status":"ok","timestamp":1696874363119,"user_tz":-540,"elapsed":13,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"2e649920-aa03-444f-811c-ca010821480c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Oct  9 17:59:23 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    45W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    apex=True\n","    print_freq=20\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-large\"\n","    gradient_checkpointing=False\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=4\n","    encoder_lr=5e-6\n","    decoder_lr=5e-6\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=4\n","    max_len=1024\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    target_size=2\n","    fc_dropout=0.2\n","    target_cols=['content','wording']\n","    seed=2023\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    train=True\n","    freezing=False\n","    freeze_layer=True\n","    n_freeze_layer=4\n","\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]"],"metadata":{"id":"1DXnDEPnh58g","executionInfo":{"status":"ok","timestamp":1696874363120,"user_tz":-540,"elapsed":10,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","DIR = '/content/drive/MyDrive/Competitions/Kaggle/Commonlit'\n","INPUT_DIR = os.path.join(DIR,'input')\n","OUTPUT_DIR = os.path.join(DIR,'output')\n","OUTPUT_MODEL_DIR = DIR + '/output/EXP084/'\n","if not os.path.exists(OUTPUT_MODEL_DIR):\n","    os.makedirs(OUTPUT_MODEL_DIR)"],"metadata":{"id":"n8DPRxxZiMQ5","executionInfo":{"status":"ok","timestamp":1696874363120,"user_tz":-540,"elapsed":9,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Library\n","# ====================================================\n","from google.colab import runtime\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","from text_unidecode import unidecode\n","from typing import Dict, List, Tuple\n","import codecs\n","\n","\n","import torch\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW, Optimizer\n","from torch.utils.data import DataLoader, Dataset\n","from torch.autograd.function import InplaceFunction\n","import torch.nn.init as init\n","\n","#os.system('pip uninstall -y transformers')\n","#os.system('pip uninstall -y tokenizers')\n","#os.system('python -m pip install --no-index --find-links=/content/drive/MyDrive/Competitions/Kaggle/FeedBack3/pip_wheel.ipynb transformers')\n","#os.system('python -m pip install --no-index --find-links=/content/drive/MyDrive/Competitions/Kaggle/FeedBack3/pip_wheel.ipynb tokenizers')\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup,get_polynomial_decay_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oeXsVFCtiTfX","executionInfo":{"status":"ok","timestamp":1696874368156,"user_tz":-540,"elapsed":5044,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"9ac38605-25a0-4675-dee7-6511ebfe9be6"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tokenizers.__version__: 0.12.1\n","transformers.__version__: 4.21.2\n","env: TOKENIZERS_PARALLELISM=true\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# Utils\n","# ====================================================\n","def MCRMSE(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]\n","        y_pred = y_preds[:,i]\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n","\n","\n","def get_score(y_trues, y_preds):\n","    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n","    return mcrmse_score, scores\n","\n","\n","def get_logger(filename=OUTPUT_MODEL_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(seed=CFG.seed)"],"metadata":{"id":"T-pk0LlXiX24","executionInfo":{"status":"ok","timestamp":1696874368157,"user_tz":-540,"elapsed":26,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","\n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","\n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","\n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","\n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","\n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","\n","        if hasattr(embeddings_path, attr_name):\n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"XJzsTvmkigu5","executionInfo":{"status":"ok","timestamp":1696874368157,"user_tz":-540,"elapsed":25,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["prompts_train = pd.read_csv(os.path.join(INPUT_DIR,'prompts_train.csv'))\n","summary_train = pd.read_csv(os.path.join(INPUT_DIR,'summaries_train.csv'))\n","\n","print(f\"Prompt Train.shape: {prompts_train.shape}\")\n","display(prompts_train.head())\n","print(f\"Summary Train.shape: {summary_train.shape}\")\n","display(summary_train.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":400},"id":"qoiequW3ikcn","executionInfo":{"status":"ok","timestamp":1696874368157,"user_tz":-540,"elapsed":24,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"ba4ed6bb-28ed-4b0d-ada5-fc60f49d5e80"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Prompt Train.shape: (4, 4)\n"]},{"output_type":"display_data","data":{"text/plain":["  prompt_id                                    prompt_question               prompt_title                                        prompt_text\n","0    39c16e  Summarize at least 3 elements of an ideal trag...                 On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...\n","1    3b9047  In complete sentences, summarize the structure...  Egyptian Social Structure  Egyptian society was structured like a pyramid...\n","2    814d6b  Summarize how the Third Wave developed over su...             The Third Wave  Background \\r\\nThe Third Wave experiment took ...\n","3    ebad26  Summarize the various ways the factory would u...    Excerpt from The Jungle  With one member trimming beef in a cannery, an..."],"text/html":["\n","  <div id=\"df-dcea79ea-d60c-4b49-8b0a-cdc647ce0ec5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt_id</th>\n","      <th>prompt_question</th>\n","      <th>prompt_title</th>\n","      <th>prompt_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3b9047</td>\n","      <td>In complete sentences, summarize the structure...</td>\n","      <td>Egyptian Social Structure</td>\n","      <td>Egyptian society was structured like a pyramid...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>814d6b</td>\n","      <td>Summarize how the Third Wave developed over su...</td>\n","      <td>The Third Wave</td>\n","      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ebad26</td>\n","      <td>Summarize the various ways the factory would u...</td>\n","      <td>Excerpt from The Jungle</td>\n","      <td>With one member trimming beef in a cannery, an...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcea79ea-d60c-4b49-8b0a-cdc647ce0ec5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-dcea79ea-d60c-4b49-8b0a-cdc647ce0ec5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-dcea79ea-d60c-4b49-8b0a-cdc647ce0ec5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-8d6a35c1-8954-4202-b582-9df5fbfa5467\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d6a35c1-8954-4202-b582-9df5fbfa5467')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-8d6a35c1-8954-4202-b582-9df5fbfa5467 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Summary Train.shape: (7165, 5)\n"]},{"output_type":"display_data","data":{"text/plain":["     student_id prompt_id                                               text   content   wording\n","0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...  0.205683  0.380538\n","1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme... -0.548304  0.506755\n","2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...  3.128928  4.231226\n","3  005ab0199905    3b9047  The highest class was Pharaohs these people we... -0.210614 -0.471415\n","4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...  3.272894  3.219757"],"text/html":["\n","  <div id=\"df-2667f786-37b0-41d1-9993-9581c9f18ec2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>prompt_id</th>\n","      <th>text</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000e8c3c7ddb</td>\n","      <td>814d6b</td>\n","      <td>The third wave was an experimentto see how peo...</td>\n","      <td>0.205683</td>\n","      <td>0.380538</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0020ae56ffbf</td>\n","      <td>ebad26</td>\n","      <td>They would rub it up with soda to make the sme...</td>\n","      <td>-0.548304</td>\n","      <td>0.506755</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>004e978e639e</td>\n","      <td>3b9047</td>\n","      <td>In Egypt, there were many occupations and soci...</td>\n","      <td>3.128928</td>\n","      <td>4.231226</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>005ab0199905</td>\n","      <td>3b9047</td>\n","      <td>The highest class was Pharaohs these people we...</td>\n","      <td>-0.210614</td>\n","      <td>-0.471415</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0070c9e7af47</td>\n","      <td>814d6b</td>\n","      <td>The Third Wave developed  rapidly because the ...</td>\n","      <td>3.272894</td>\n","      <td>3.219757</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2667f786-37b0-41d1-9993-9581c9f18ec2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2667f786-37b0-41d1-9993-9581c9f18ec2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2667f786-37b0-41d1-9993-9581c9f18ec2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4a1b3cec-6da5-4010-9413-d181e6d674b1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a1b3cec-6da5-4010-9413-d181e6d674b1')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4a1b3cec-6da5-4010-9413-d181e6d674b1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}}]},{"cell_type":"code","source":["train = prompts_train.merge(summary_train, on=\"prompt_id\")\n","display(train.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":293},"id":"emiPv2lpi1wX","executionInfo":{"status":"ok","timestamp":1696874368158,"user_tz":-540,"elapsed":20,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"3759b079-f416-478a-a817-b139cf3e3dcd"},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":["  prompt_id                                    prompt_question prompt_title                                        prompt_text    student_id                                               text   content   wording\n","0    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...  00791789cc1f  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415\n","1    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...  0086ef22de8f  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058\n","2    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...  0094589c7a22  Aristotle states that an ideal tragedy should ... -0.387791 -0.584181\n","3    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...  00cd5736026a  One element of an Ideal tragedy is having a co...  0.088882 -0.594710\n","4    39c16e  Summarize at least 3 elements of an ideal trag...   On Tragedy  Chapter 13 \\r\\nAs the sequel to what has alrea...  00d98b8ff756  The 3 ideal of tragedy is how complex you need... -0.687288 -0.460886"],"text/html":["\n","  <div id=\"df-f3063618-ed4b-467a-a558-e4305e664a5a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prompt_id</th>\n","      <th>prompt_question</th>\n","      <th>prompt_title</th>\n","      <th>prompt_text</th>\n","      <th>student_id</th>\n","      <th>text</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>00791789cc1f</td>\n","      <td>1 element of an ideal tragedy is that it shoul...</td>\n","      <td>-0.210614</td>\n","      <td>-0.471415</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>0086ef22de8f</td>\n","      <td>The three elements of an ideal tragedy are:  H...</td>\n","      <td>-0.970237</td>\n","      <td>-0.417058</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>0094589c7a22</td>\n","      <td>Aristotle states that an ideal tragedy should ...</td>\n","      <td>-0.387791</td>\n","      <td>-0.584181</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>00cd5736026a</td>\n","      <td>One element of an Ideal tragedy is having a co...</td>\n","      <td>0.088882</td>\n","      <td>-0.594710</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>39c16e</td>\n","      <td>Summarize at least 3 elements of an ideal trag...</td>\n","      <td>On Tragedy</td>\n","      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n","      <td>00d98b8ff756</td>\n","      <td>The 3 ideal of tragedy is how complex you need...</td>\n","      <td>-0.687288</td>\n","      <td>-0.460886</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3063618-ed4b-467a-a558-e4305e664a5a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f3063618-ed4b-467a-a558-e4305e664a5a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f3063618-ed4b-467a-a558-e4305e664a5a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-01556443-11ac-4bdc-85d9-9b8ce9e096b9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-01556443-11ac-4bdc-85d9-9b8ce9e096b9')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-01556443-11ac-4bdc-85d9-9b8ce9e096b9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}}]},{"cell_type":"code","source":["# ====================================================\n","# CV split\n","# ====================================================\n","Fold = GroupKFold(n_splits=CFG.n_fold)\n","for n, (train_index, val_index) in enumerate(Fold.split(train, groups=train[\"prompt_id\"])):\n","    train.loc[val_index, 'fold'] = int(n)\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"id":"2oEQGucXi-TM","executionInfo":{"status":"ok","timestamp":1696874368158,"user_tz":-540,"elapsed":18,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"ddf070ee-626c-4036-91aa-f018f48ec700"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["fold\n","0    2057\n","1    2009\n","2    1996\n","3    1103\n","dtype: int64"]},"metadata":{}}]},{"cell_type":"code","source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"],"metadata":{"id":"hPNdK-w2jAJb","executionInfo":{"status":"ok","timestamp":1696874368159,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_MODEL_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CNt6YdwtjCHR","executionInfo":{"status":"ok","timestamp":1696874372936,"user_tz":-540,"elapsed":4793,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"200aeb02-e722-47a3-8b73-19d6f6041c17"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["def len2text(x:str):\n","    if len(x)<200: return 'Quite short'\n","    if len(x)<300: return 'Short'\n","    if len(x)<500: return 'Middle'\n","    else:\n","        return 'Long'"],"metadata":{"id":"4-LeEcCMxp0r","executionInfo":{"status":"ok","timestamp":1696874372936,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["train[\"text_length\"] = train['text'].apply(lambda x: len2text(x))\n","SEP = tokenizer.sep_token\n","train['full_text'] = train['text'] + \" \" + train['prompt_question'] + \" \" + train[\"prompt_text\"]"],"metadata":{"id":"4URMsa8ZjZbe","executionInfo":{"status":"ok","timestamp":1696874372936,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer.encode_plus(\n","        text,\n","        return_tensors=None,\n","        add_special_tokens=True,\n","        max_length=CFG.max_len,\n","        pad_to_max_length=True,\n","        truncation=True\n","    )\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['full_text'].values\n","        self.labels = df[cfg.target_cols].values\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs"],"metadata":{"id":"dn-zNJVbja5k","executionInfo":{"status":"ok","timestamp":1696874372937,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        if cfg.freeze_layer:\n","            for k, param in self.model.base_model.encoder.layer.named_parameters():\n","                l = int(k.split(\".\")[0])\n","                if l < cfg.n_freeze_layer:\n","                    param.requires_grad = False\n","\n","        #self.pool = MeanPooling()\n","        self.output = nn.Sequential(\n","            nn.LayerNorm(self.config.hidden_size),\n","            nn.Linear(self.config.hidden_size, self.cfg.target_size)\n","        )\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        feature = outputs[0][:, 0, :]\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.output(feature)\n","        return output"],"metadata":{"id":"KIb1arzTjdRR","executionInfo":{"status":"ok","timestamp":1696874372937,"user_tz":-540,"elapsed":15,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Loss\n","# ====================================================\n","class RMSELoss(nn.Module):\n","    def __init__(self, reduction='mean', eps=1e-9):\n","        super().__init__()\n","        self.mse = nn.MSELoss(reduction='none')\n","        self.reduction = reduction\n","        self.eps = eps\n","\n","    def forward(self, y_pred, y_true):\n","        loss = torch.sqrt(self.mse(y_pred, y_true) + self.eps)\n","        if self.reduction == 'none':\n","            loss = loss\n","        elif self.reduction == 'sum':\n","            loss = loss.sum()\n","        elif self.reduction == 'mean':\n","            loss = loss.mean()\n","        return loss"],"metadata":{"id":"fxIJL4WojfSl","executionInfo":{"status":"ok","timestamp":1696874372937,"user_tz":-540,"elapsed":14,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        #if scaler is not None:\n","        #    scaler.unscale_(optimizer)\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader),\n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    return losses.avg, predictions"],"metadata":{"id":"JSU1PJNIjhKu","executionInfo":{"status":"ok","timestamp":1696874372937,"user_tz":-540,"elapsed":14,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","\n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target_cols].values\n","\n","    print(f\"========== prompt_id: {valid_folds.prompt_id.unique()} validation ==========\")\n","\n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size * 2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_MODEL_DIR+'config.pth')\n","    model.to(device)\n","\n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","\n","        group1=['layer.0.','layer.1.','layer.2.','layer.3.','layer.4.','layer.5.','layer.6.','layer.7.']\n","        group2=['layer.8.','layer.9.','layer.10.','layer.11.','layer.12.','layer.13.','layer.14.','layer.15.']\n","        group3=['layer.16.','layer.17.','layer.18.','layer.19.','layer.20.','layer.21.','layer.22.','layer.23.']\n","        group_all=['layer.0.','layer.1.','layer.2.','layer.3.','layer.4.','layer.5.','layer.6.','layer.7.','layer.8.','layer.9.','layer.10.','layer.11.',\n","                  'layer.12.','layer.13.','layer.14.','layer.15.','layer.16.','layer.17.','layer.18.','layer.19.','layer.20.','layer.21.','layer.22.','layer.23.']\n","\n","\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","\n","        optimizer_parameters2 = [\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': weight_decay, 'lr': encoder_lr/2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': weight_decay, 'lr': encoder_lr},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': weight_decay, 'lr': encoder_lr*2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': 0.0},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': 0.0, 'lr': encoder_lr/2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': 0.0, 'lr': encoder_lr},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': 0.0, 'lr': encoder_lr*2.6},\n","        {'params': [p for n, p in model.named_parameters() if \"model\" not in n], 'lr':decoder_lr, \"momentum\" : 0.99},\n","    ]\n","        return optimizer_parameters2\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr,\n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","\n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","\n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = RMSELoss(reduction=\"mean\")   # nn.SmoothL1Loss(reduction='mean')\n","\n","    best_score = np.inf\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","\n","        # scoring\n","        score, scores = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n","\n","        if best_score > score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_MODEL_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return valid_folds"],"metadata":{"id":"5_npZ5IWjle3","executionInfo":{"status":"ok","timestamp":1696874372939,"user_tz":-540,"elapsed":15,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","\n","    def get_result(oof_df):\n","        labels = oof_df[CFG.target_cols].values\n","        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n","        score, scores = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')\n","\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_MODEL_DIR+'oof_df.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oN9JEc3yj-x1","outputId":"1cca8849-aa6d-4197-a0bc-477854abcceb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["========== prompt_id: ['39c16e'] validation ==========\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1277] Elapsed 0m 4s (remain 94m 1s) Loss: 0.6580(0.6580) Grad: inf  LR: 0.00000500  \n","Epoch: [1][20/1277] Elapsed 0m 13s (remain 13m 45s) Loss: 0.6825(0.9607) Grad: 40766.1484  LR: 0.00000500  \n","Epoch: [1][40/1277] Elapsed 0m 22s (remain 11m 15s) Loss: 1.2675(0.8782) Grad: 995562.0000  LR: 0.00000500  \n","Epoch: [1][60/1277] Elapsed 0m 31s (remain 10m 32s) Loss: 0.6851(0.8690) Grad: 372304.5938  LR: 0.00000500  \n","Epoch: [1][80/1277] Elapsed 0m 40s (remain 9m 59s) Loss: 0.6759(0.8431) Grad: 1124714.5000  LR: 0.00000500  \n","Epoch: [1][100/1277] Elapsed 0m 49s (remain 9m 36s) Loss: 0.3372(0.8080) Grad: 290683.3750  LR: 0.00000500  \n","Epoch: [1][120/1277] Elapsed 0m 58s (remain 9m 20s) Loss: 0.5940(0.7758) Grad: 4706861.5000  LR: 0.00000499  \n","Epoch: [1][140/1277] Elapsed 1m 7s (remain 9m 7s) Loss: 1.0393(0.7600) Grad: 484556.4375  LR: 0.00000499  \n","Epoch: [1][160/1277] Elapsed 1m 16s (remain 8m 53s) Loss: 0.8851(0.7332) Grad: 3070884.2500  LR: 0.00000499  \n","Epoch: [1][180/1277] Elapsed 1m 26s (remain 8m 40s) Loss: 0.4424(0.7202) Grad: 494442.2500  LR: 0.00000498  \n","Epoch: [1][200/1277] Elapsed 1m 35s (remain 8m 29s) Loss: 0.5539(0.7006) Grad: 1221826.5000  LR: 0.00000498  \n","Epoch: [1][220/1277] Elapsed 1m 43s (remain 8m 15s) Loss: 0.4066(0.6856) Grad: 417843.4688  LR: 0.00000498  \n","Epoch: [1][240/1277] Elapsed 1m 52s (remain 8m 4s) Loss: 0.1961(0.6741) Grad: 617399.8750  LR: 0.00000497  \n","Epoch: [1][260/1277] Elapsed 2m 1s (remain 7m 53s) Loss: 0.8200(0.6635) Grad: 978920.0000  LR: 0.00000497  \n","Epoch: [1][280/1277] Elapsed 2m 10s (remain 7m 42s) Loss: 0.4906(0.6478) Grad: 968309.8125  LR: 0.00000496  \n","Epoch: [1][300/1277] Elapsed 2m 19s (remain 7m 32s) Loss: 0.5216(0.6383) Grad: 230470.8750  LR: 0.00000496  \n","Epoch: [1][320/1277] Elapsed 2m 28s (remain 7m 21s) Loss: 0.8308(0.6370) Grad: 691445.5000  LR: 0.00000495  \n","Epoch: [1][340/1277] Elapsed 2m 37s (remain 7m 11s) Loss: 0.3546(0.6280) Grad: 170326.0781  LR: 0.00000495  \n","Epoch: [1][360/1277] Elapsed 2m 46s (remain 7m 1s) Loss: 0.4629(0.6263) Grad: 910796.5625  LR: 0.00000494  \n","Epoch: [1][380/1277] Elapsed 2m 55s (remain 6m 52s) Loss: 0.6851(0.6185) Grad: 410003.2500  LR: 0.00000493  \n","Epoch: [1][400/1277] Elapsed 3m 4s (remain 6m 42s) Loss: 0.3640(0.6139) Grad: 171170.9531  LR: 0.00000492  \n","Epoch: [1][420/1277] Elapsed 3m 13s (remain 6m 33s) Loss: 0.4019(0.6098) Grad: 456844.0938  LR: 0.00000492  \n","Epoch: [1][440/1277] Elapsed 3m 22s (remain 6m 24s) Loss: 0.3456(0.6039) Grad: 258793.7656  LR: 0.00000491  \n","Epoch: [1][460/1277] Elapsed 3m 31s (remain 6m 14s) Loss: 0.4303(0.5989) Grad: 309147.7188  LR: 0.00000490  \n","Epoch: [1][480/1277] Elapsed 3m 40s (remain 6m 4s) Loss: 0.3888(0.5910) Grad: 518540.7188  LR: 0.00000489  \n","Epoch: [1][500/1277] Elapsed 3m 49s (remain 5m 55s) Loss: 0.4969(0.5851) Grad: 168230.0469  LR: 0.00000488  \n","Epoch: [1][520/1277] Elapsed 3m 58s (remain 5m 46s) Loss: 0.6119(0.5800) Grad: 254861.4219  LR: 0.00000487  \n","Epoch: [1][540/1277] Elapsed 4m 8s (remain 5m 37s) Loss: 0.5092(0.5733) Grad: 162822.9375  LR: 0.00000486  \n","Epoch: [1][560/1277] Elapsed 4m 17s (remain 5m 28s) Loss: 0.2176(0.5690) Grad: 95543.9766  LR: 0.00000485  \n","Epoch: [1][580/1277] Elapsed 4m 26s (remain 5m 19s) Loss: 0.4803(0.5645) Grad: 316269.3125  LR: 0.00000484  \n","Epoch: [1][600/1277] Elapsed 4m 35s (remain 5m 10s) Loss: 0.3398(0.5610) Grad: 143906.5469  LR: 0.00000483  \n","Epoch: [1][620/1277] Elapsed 4m 44s (remain 5m 0s) Loss: 0.3181(0.5568) Grad: 310046.5312  LR: 0.00000482  \n","Epoch: [1][640/1277] Elapsed 4m 53s (remain 4m 51s) Loss: 0.3651(0.5525) Grad: 356080.5938  LR: 0.00000481  \n","Epoch: [1][660/1277] Elapsed 5m 3s (remain 4m 42s) Loss: 0.2717(0.5483) Grad: 170563.7656  LR: 0.00000480  \n","Epoch: [1][680/1277] Elapsed 5m 12s (remain 4m 33s) Loss: 0.7714(0.5459) Grad: 213894.3750  LR: 0.00000478  \n","Epoch: [1][700/1277] Elapsed 5m 21s (remain 4m 24s) Loss: 0.4240(0.5415) Grad: 229907.3125  LR: 0.00000477  \n","Epoch: [1][720/1277] Elapsed 5m 30s (remain 4m 14s) Loss: 0.3115(0.5376) Grad: 207771.6250  LR: 0.00000476  \n","Epoch: [1][740/1277] Elapsed 5m 39s (remain 4m 5s) Loss: 0.2404(0.5357) Grad: 120056.8203  LR: 0.00000474  \n","Epoch: [1][760/1277] Elapsed 5m 48s (remain 3m 56s) Loss: 0.3991(0.5327) Grad: 193423.4375  LR: 0.00000473  \n","Epoch: [1][780/1277] Elapsed 5m 57s (remain 3m 46s) Loss: 0.4704(0.5292) Grad: 111269.7500  LR: 0.00000472  \n","Epoch: [1][800/1277] Elapsed 6m 6s (remain 3m 37s) Loss: 0.2783(0.5262) Grad: 311323.4062  LR: 0.00000470  \n","Epoch: [1][820/1277] Elapsed 6m 15s (remain 3m 28s) Loss: 0.3407(0.5232) Grad: 74084.0938  LR: 0.00000469  \n","Epoch: [1][840/1277] Elapsed 6m 24s (remain 3m 19s) Loss: 0.7256(0.5207) Grad: 154776.0781  LR: 0.00000467  \n","Epoch: [1][860/1277] Elapsed 6m 33s (remain 3m 10s) Loss: 0.2612(0.5183) Grad: 149643.2031  LR: 0.00000466  \n","Epoch: [1][880/1277] Elapsed 6m 43s (remain 3m 1s) Loss: 0.2511(0.5170) Grad: 150264.6406  LR: 0.00000464  \n","Epoch: [1][900/1277] Elapsed 6m 51s (remain 2m 51s) Loss: 0.2684(0.5135) Grad: 137176.7500  LR: 0.00000463  \n","Epoch: [1][920/1277] Elapsed 7m 1s (remain 2m 42s) Loss: 0.3190(0.5109) Grad: 177025.0312  LR: 0.00000461  \n","Epoch: [1][940/1277] Elapsed 7m 10s (remain 2m 33s) Loss: 0.5662(0.5090) Grad: 146771.5000  LR: 0.00000459  \n","Epoch: [1][960/1277] Elapsed 7m 19s (remain 2m 24s) Loss: 0.4789(0.5078) Grad: 249421.7344  LR: 0.00000458  \n","Epoch: [1][980/1277] Elapsed 7m 28s (remain 2m 15s) Loss: 0.4286(0.5061) Grad: 124828.1719  LR: 0.00000456  \n","Epoch: [1][1000/1277] Elapsed 7m 37s (remain 2m 6s) Loss: 0.2381(0.5039) Grad: 306700.7812  LR: 0.00000454  \n","Epoch: [1][1020/1277] Elapsed 7m 46s (remain 1m 57s) Loss: 0.3670(0.5024) Grad: 166316.5625  LR: 0.00000452  \n","Epoch: [1][1040/1277] Elapsed 7m 56s (remain 1m 47s) Loss: 0.2579(0.5014) Grad: 221998.2188  LR: 0.00000450  \n","Epoch: [1][1060/1277] Elapsed 8m 5s (remain 1m 38s) Loss: 0.2609(0.4997) Grad: 153457.4531  LR: 0.00000449  \n","Epoch: [1][1080/1277] Elapsed 8m 14s (remain 1m 29s) Loss: 0.2690(0.4978) Grad: 139343.7656  LR: 0.00000447  \n","Epoch: [1][1100/1277] Elapsed 8m 23s (remain 1m 20s) Loss: 0.4652(0.4965) Grad: 110511.8359  LR: 0.00000445  \n","Epoch: [1][1120/1277] Elapsed 8m 32s (remain 1m 11s) Loss: 0.3755(0.4950) Grad: 134822.7812  LR: 0.00000443  \n","Epoch: [1][1140/1277] Elapsed 8m 41s (remain 1m 2s) Loss: 0.6098(0.4936) Grad: 324343.5312  LR: 0.00000441  \n","Epoch: [1][1160/1277] Elapsed 8m 49s (remain 0m 52s) Loss: 0.3207(0.4928) Grad: 131782.6562  LR: 0.00000439  \n","Epoch: [1][1180/1277] Elapsed 8m 58s (remain 0m 43s) Loss: 0.4404(0.4915) Grad: 133752.9844  LR: 0.00000437  \n","Epoch: [1][1200/1277] Elapsed 9m 8s (remain 0m 34s) Loss: 0.1696(0.4903) Grad: 164801.0625  LR: 0.00000435  \n","Epoch: [1][1220/1277] Elapsed 9m 17s (remain 0m 25s) Loss: 0.3042(0.4892) Grad: 150947.0625  LR: 0.00000433  \n","Epoch: [1][1240/1277] Elapsed 9m 26s (remain 0m 16s) Loss: 0.5141(0.4880) Grad: 165308.2812  LR: 0.00000431  \n","Epoch: [1][1260/1277] Elapsed 9m 35s (remain 0m 7s) Loss: 0.3052(0.4853) Grad: 80420.8594  LR: 0.00000429  \n","Epoch: [1][1276/1277] Elapsed 9m 42s (remain 0m 0s) Loss: 0.6108(0.4842) Grad: 173282.8125  LR: 0.00000427  \n","EVAL: [0/258] Elapsed 0m 0s (remain 3m 27s) Loss: 0.2785(0.2785) \n","EVAL: [20/258] Elapsed 0m 12s (remain 2m 24s) Loss: 0.6037(0.3852) \n","EVAL: [40/258] Elapsed 0m 25s (remain 2m 13s) Loss: 0.3310(0.3856) \n","EVAL: [60/258] Elapsed 0m 37s (remain 1m 59s) Loss: 0.2978(0.3767) \n","EVAL: [80/258] Elapsed 0m 48s (remain 1m 46s) Loss: 0.4143(0.3765) \n","EVAL: [100/258] Elapsed 1m 0s (remain 1m 33s) Loss: 0.4605(0.3739) \n","EVAL: [120/258] Elapsed 1m 12s (remain 1m 22s) Loss: 0.3751(0.3757) \n","EVAL: [140/258] Elapsed 1m 24s (remain 1m 10s) Loss: 0.2644(0.3733) \n","EVAL: [160/258] Elapsed 1m 36s (remain 0m 58s) Loss: 0.3001(0.3745) \n","EVAL: [180/258] Elapsed 1m 47s (remain 0m 45s) Loss: 0.2579(0.3726) \n","EVAL: [200/258] Elapsed 1m 59s (remain 0m 33s) Loss: 0.3170(0.3715) \n","EVAL: [220/258] Elapsed 2m 11s (remain 0m 22s) Loss: 0.2604(0.3710) \n","EVAL: [240/258] Elapsed 2m 23s (remain 0m 10s) Loss: 0.3491(0.3699) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.4842  avg_val_loss: 0.3688  time: 736s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4842  avg_val_loss: 0.3688  time: 736s\n","Epoch 1 - Score: 0.4861  Scores: [0.40158530407392656, 0.5705234313062326]\n","INFO:__main__:Epoch 1 - Score: 0.4861  Scores: [0.40158530407392656, 0.5705234313062326]\n","Epoch 1 - Save Best Score: 0.4861 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4861 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [257/258] Elapsed 2m 33s (remain 0m 0s) Loss: 0.4076(0.3688) \n","Epoch: [2][0/1277] Elapsed 0m 0s (remain 14m 55s) Loss: 0.3051(0.3051) Grad: inf  LR: 0.00000427  \n","Epoch: [2][20/1277] Elapsed 0m 9s (remain 9m 42s) Loss: 0.1914(0.3454) Grad: 471787.6875  LR: 0.00000424  \n","Epoch: [2][40/1277] Elapsed 0m 18s (remain 9m 26s) Loss: 0.2059(0.3700) Grad: 231979.1094  LR: 0.00000422  \n","Epoch: [2][60/1277] Elapsed 0m 27s (remain 9m 7s) Loss: 0.2380(0.3614) Grad: 285488.0312  LR: 0.00000420  \n","Epoch: [2][80/1277] Elapsed 0m 36s (remain 8m 58s) Loss: 0.4108(0.3601) Grad: 272785.6875  LR: 0.00000418  \n","Epoch: [2][100/1277] Elapsed 0m 45s (remain 8m 45s) Loss: 0.3133(0.3529) Grad: 175668.1250  LR: 0.00000415  \n","Epoch: [2][120/1277] Elapsed 0m 54s (remain 8m 35s) Loss: 0.4037(0.3619) Grad: 478581.1875  LR: 0.00000413  \n","Epoch: [2][140/1277] Elapsed 1m 3s (remain 8m 29s) Loss: 0.4172(0.3589) Grad: 248789.6875  LR: 0.00000411  \n","Epoch: [2][160/1277] Elapsed 1m 12s (remain 8m 23s) Loss: 0.3941(0.3563) Grad: 325697.7500  LR: 0.00000408  \n","Epoch: [2][180/1277] Elapsed 1m 21s (remain 8m 15s) Loss: 0.2918(0.3537) Grad: 161720.0469  LR: 0.00000406  \n","Epoch: [2][200/1277] Elapsed 1m 30s (remain 8m 6s) Loss: 0.3806(0.3548) Grad: 117276.7500  LR: 0.00000404  \n","Epoch: [2][220/1277] Elapsed 1m 40s (remain 7m 58s) Loss: 0.6274(0.3554) Grad: 398114.9062  LR: 0.00000401  \n","Epoch: [2][240/1277] Elapsed 1m 48s (remain 7m 47s) Loss: 0.3354(0.3526) Grad: 213972.1250  LR: 0.00000399  \n","Epoch: [2][260/1277] Elapsed 1m 57s (remain 7m 37s) Loss: 0.2952(0.3537) Grad: 369037.5000  LR: 0.00000396  \n","Epoch: [2][280/1277] Elapsed 2m 6s (remain 7m 28s) Loss: 0.4933(0.3539) Grad: 351404.3438  LR: 0.00000394  \n","Epoch: [2][300/1277] Elapsed 2m 15s (remain 7m 20s) Loss: 0.2811(0.3533) Grad: 125672.8203  LR: 0.00000391  \n","Epoch: [2][320/1277] Elapsed 2m 24s (remain 7m 11s) Loss: 0.2725(0.3503) Grad: 493004.3438  LR: 0.00000389  \n","Epoch: [2][340/1277] Elapsed 2m 34s (remain 7m 2s) Loss: 0.2140(0.3529) Grad: 208908.8281  LR: 0.00000386  \n","Epoch: [2][360/1277] Elapsed 2m 43s (remain 6m 54s) Loss: 0.6604(0.3536) Grad: 316080.4688  LR: 0.00000384  \n","Epoch: [2][380/1277] Elapsed 2m 52s (remain 6m 45s) Loss: 0.2259(0.3526) Grad: 222715.3438  LR: 0.00000381  \n","Epoch: [2][400/1277] Elapsed 3m 1s (remain 6m 36s) Loss: 0.3017(0.3537) Grad: 189089.6875  LR: 0.00000378  \n","Epoch: [2][420/1277] Elapsed 3m 10s (remain 6m 27s) Loss: 0.3003(0.3536) Grad: 136921.0625  LR: 0.00000376  \n","Epoch: [2][440/1277] Elapsed 3m 19s (remain 6m 18s) Loss: 0.1873(0.3538) Grad: 309070.2188  LR: 0.00000373  \n","Epoch: [2][460/1277] Elapsed 3m 28s (remain 6m 9s) Loss: 0.2085(0.3529) Grad: 174187.9688  LR: 0.00000370  \n","Epoch: [2][480/1277] Elapsed 3m 37s (remain 6m 0s) Loss: 0.2828(0.3534) Grad: 360482.0938  LR: 0.00000368  \n","Epoch: [2][500/1277] Elapsed 3m 46s (remain 5m 50s) Loss: 0.4859(0.3526) Grad: 250354.0781  LR: 0.00000365  \n","Epoch: [2][520/1277] Elapsed 3m 55s (remain 5m 41s) Loss: 0.1347(0.3512) Grad: 248617.5781  LR: 0.00000362  \n","Epoch: [2][540/1277] Elapsed 4m 4s (remain 5m 32s) Loss: 0.4621(0.3516) Grad: 225146.5625  LR: 0.00000359  \n","Epoch: [2][560/1277] Elapsed 4m 13s (remain 5m 23s) Loss: 0.4119(0.3517) Grad: 233673.0938  LR: 0.00000357  \n","Epoch: [2][580/1277] Elapsed 4m 22s (remain 5m 14s) Loss: 0.4522(0.3531) Grad: 183102.2031  LR: 0.00000354  \n","Epoch: [2][600/1277] Elapsed 4m 31s (remain 5m 5s) Loss: 0.3464(0.3528) Grad: 183466.8594  LR: 0.00000351  \n","Epoch: [2][620/1277] Elapsed 4m 40s (remain 4m 56s) Loss: 0.2147(0.3548) Grad: 248867.5312  LR: 0.00000348  \n","Epoch: [2][640/1277] Elapsed 4m 50s (remain 4m 47s) Loss: 0.4451(0.3559) Grad: 561273.8750  LR: 0.00000345  \n","Epoch: [2][660/1277] Elapsed 4m 59s (remain 4m 38s) Loss: 0.3789(0.3554) Grad: 148484.4062  LR: 0.00000342  \n","Epoch: [2][680/1277] Elapsed 5m 8s (remain 4m 29s) Loss: 0.3974(0.3550) Grad: 334144.3750  LR: 0.00000340  \n","Epoch: [2][700/1277] Elapsed 5m 17s (remain 4m 20s) Loss: 0.2597(0.3545) Grad: 186868.7188  LR: 0.00000337  \n","Epoch: [2][720/1277] Elapsed 5m 26s (remain 4m 11s) Loss: 0.3626(0.3534) Grad: 351409.8125  LR: 0.00000334  \n","Epoch: [2][740/1277] Elapsed 5m 35s (remain 4m 2s) Loss: 0.3557(0.3528) Grad: 464966.9688  LR: 0.00000331  \n","Epoch: [2][760/1277] Elapsed 5m 44s (remain 3m 53s) Loss: 0.2982(0.3513) Grad: 174778.8750  LR: 0.00000328  \n","Epoch: [2][780/1277] Elapsed 5m 53s (remain 3m 44s) Loss: 0.2441(0.3496) Grad: 328256.4062  LR: 0.00000325  \n","Epoch: [2][800/1277] Elapsed 6m 2s (remain 3m 35s) Loss: 0.2207(0.3501) Grad: 140165.2969  LR: 0.00000322  \n","Epoch: [2][820/1277] Elapsed 6m 11s (remain 3m 26s) Loss: 0.4963(0.3495) Grad: 263937.1562  LR: 0.00000319  \n","Epoch: [2][840/1277] Elapsed 6m 20s (remain 3m 17s) Loss: 0.4216(0.3490) Grad: 298571.4062  LR: 0.00000316  \n","Epoch: [2][860/1277] Elapsed 6m 29s (remain 3m 8s) Loss: 0.6005(0.3497) Grad: 156285.3594  LR: 0.00000313  \n","Epoch: [2][880/1277] Elapsed 6m 39s (remain 2m 59s) Loss: 0.2920(0.3511) Grad: 168151.4531  LR: 0.00000310  \n","Epoch: [2][900/1277] Elapsed 6m 48s (remain 2m 50s) Loss: 0.5209(0.3508) Grad: 533869.4375  LR: 0.00000307  \n","Epoch: [2][920/1277] Elapsed 6m 57s (remain 2m 41s) Loss: 0.1438(0.3505) Grad: 217875.7656  LR: 0.00000304  \n","Epoch: [2][940/1277] Elapsed 7m 6s (remain 2m 32s) Loss: 0.2319(0.3511) Grad: 408596.0312  LR: 0.00000301  \n","Epoch: [2][960/1277] Elapsed 7m 15s (remain 2m 23s) Loss: 0.5250(0.3513) Grad: 137887.5000  LR: 0.00000298  \n","Epoch: [2][980/1277] Elapsed 7m 24s (remain 2m 13s) Loss: 0.2049(0.3508) Grad: 192208.4062  LR: 0.00000295  \n","Epoch: [2][1000/1277] Elapsed 7m 33s (remain 2m 4s) Loss: 0.5189(0.3505) Grad: 377169.3125  LR: 0.00000292  \n","Epoch: [2][1020/1277] Elapsed 7m 42s (remain 1m 55s) Loss: 0.3455(0.3508) Grad: 286336.2812  LR: 0.00000289  \n","Epoch: [2][1040/1277] Elapsed 7m 51s (remain 1m 46s) Loss: 0.2953(0.3509) Grad: 555122.5000  LR: 0.00000286  \n","Epoch: [2][1060/1277] Elapsed 8m 0s (remain 1m 37s) Loss: 0.2960(0.3503) Grad: 372803.9375  LR: 0.00000283  \n","Epoch: [2][1080/1277] Elapsed 8m 9s (remain 1m 28s) Loss: 0.3104(0.3500) Grad: 183592.7656  LR: 0.00000280  \n","Epoch: [2][1100/1277] Elapsed 8m 18s (remain 1m 19s) Loss: 0.7883(0.3499) Grad: 475147.2188  LR: 0.00000277  \n","Epoch: [2][1120/1277] Elapsed 8m 27s (remain 1m 10s) Loss: 0.3289(0.3497) Grad: 167844.9531  LR: 0.00000274  \n","Epoch: [2][1140/1277] Elapsed 8m 37s (remain 1m 1s) Loss: 0.3008(0.3488) Grad: 204196.2344  LR: 0.00000271  \n","Epoch: [2][1160/1277] Elapsed 8m 46s (remain 0m 52s) Loss: 0.5510(0.3486) Grad: 219569.7656  LR: 0.00000268  \n","Epoch: [2][1180/1277] Elapsed 8m 55s (remain 0m 43s) Loss: 0.3308(0.3480) Grad: 176374.5781  LR: 0.00000265  \n","Epoch: [2][1200/1277] Elapsed 9m 4s (remain 0m 34s) Loss: 0.3739(0.3482) Grad: 233984.5156  LR: 0.00000262  \n","Epoch: [2][1220/1277] Elapsed 9m 13s (remain 0m 25s) Loss: 0.5212(0.3487) Grad: 410158.5312  LR: 0.00000259  \n","Epoch: [2][1240/1277] Elapsed 9m 22s (remain 0m 16s) Loss: 0.3553(0.3485) Grad: 152682.9531  LR: 0.00000256  \n","Epoch: [2][1260/1277] Elapsed 9m 31s (remain 0m 7s) Loss: 0.3346(0.3493) Grad: 125481.2500  LR: 0.00000252  \n","Epoch: [2][1276/1277] Elapsed 9m 38s (remain 0m 0s) Loss: 0.4952(0.3500) Grad: 403591.0312  LR: 0.00000250  \n","EVAL: [0/258] Elapsed 0m 0s (remain 3m 26s) Loss: 0.2842(0.2842) \n","EVAL: [20/258] Elapsed 0m 12s (remain 2m 24s) Loss: 0.5310(0.3914) \n","EVAL: [40/258] Elapsed 0m 25s (remain 2m 12s) Loss: 0.3235(0.3900) \n","EVAL: [60/258] Elapsed 0m 37s (remain 1m 59s) Loss: 0.3279(0.3774) \n","EVAL: [80/258] Elapsed 0m 48s (remain 1m 46s) Loss: 0.3973(0.3770) \n","EVAL: [100/258] Elapsed 1m 0s (remain 1m 33s) Loss: 0.4023(0.3766) \n","EVAL: [120/258] Elapsed 1m 12s (remain 1m 22s) Loss: 0.4228(0.3809) \n","EVAL: [140/258] Elapsed 1m 24s (remain 1m 10s) Loss: 0.3225(0.3791) \n","EVAL: [160/258] Elapsed 1m 36s (remain 0m 58s) Loss: 0.3507(0.3803) \n","EVAL: [180/258] Elapsed 1m 47s (remain 0m 45s) Loss: 0.2502(0.3794) \n","EVAL: [200/258] Elapsed 1m 59s (remain 0m 33s) Loss: 0.3317(0.3768) \n","EVAL: [220/258] Elapsed 2m 11s (remain 0m 22s) Loss: 0.2394(0.3769) \n","EVAL: [240/258] Elapsed 2m 23s (remain 0m 10s) Loss: 0.4286(0.3756) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3500  avg_val_loss: 0.3747  time: 732s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3500  avg_val_loss: 0.3747  time: 732s\n","Epoch 2 - Score: 0.4732  Scores: [0.3819285111659583, 0.5645677608753279]\n","INFO:__main__:Epoch 2 - Score: 0.4732  Scores: [0.3819285111659583, 0.5645677608753279]\n","Epoch 2 - Save Best Score: 0.4732 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4732 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [257/258] Elapsed 2m 33s (remain 0m 0s) Loss: 0.2684(0.3747) \n","Epoch: [3][0/1277] Elapsed 0m 0s (remain 14m 46s) Loss: 0.3547(0.3547) Grad: inf  LR: 0.00000250  \n","Epoch: [3][20/1277] Elapsed 0m 9s (remain 9m 41s) Loss: 0.1641(0.3202) Grad: 281191.5000  LR: 0.00000247  \n","Epoch: [3][40/1277] Elapsed 0m 18s (remain 9m 22s) Loss: 0.4670(0.3349) Grad: 147281.6250  LR: 0.00000244  \n","Epoch: [3][60/1277] Elapsed 0m 27s (remain 9m 15s) Loss: 0.2758(0.3318) Grad: 218765.3281  LR: 0.00000241  \n","Epoch: [3][80/1277] Elapsed 0m 37s (remain 9m 10s) Loss: 0.2955(0.3196) Grad: 150487.1562  LR: 0.00000238  \n","Epoch: [3][100/1277] Elapsed 0m 46s (remain 9m 1s) Loss: 0.2305(0.3162) Grad: 233996.8750  LR: 0.00000234  \n","Epoch: [3][120/1277] Elapsed 0m 55s (remain 8m 52s) Loss: 0.2462(0.3188) Grad: 266854.9062  LR: 0.00000231  \n","Epoch: [3][140/1277] Elapsed 1m 5s (remain 8m 43s) Loss: 0.5905(0.3201) Grad: 177492.4531  LR: 0.00000228  \n","Epoch: [3][160/1277] Elapsed 1m 14s (remain 8m 34s) Loss: 0.5291(0.3251) Grad: 391706.9688  LR: 0.00000225  \n","Epoch: [3][180/1277] Elapsed 1m 23s (remain 8m 24s) Loss: 0.3952(0.3215) Grad: 259008.7344  LR: 0.00000222  \n","Epoch: [3][200/1277] Elapsed 1m 32s (remain 8m 14s) Loss: 0.1869(0.3226) Grad: 362382.4062  LR: 0.00000219  \n","Epoch: [3][220/1277] Elapsed 1m 41s (remain 8m 2s) Loss: 0.2034(0.3184) Grad: 234301.8281  LR: 0.00000216  \n","Epoch: [3][240/1277] Elapsed 1m 50s (remain 7m 53s) Loss: 0.2483(0.3197) Grad: 182061.2031  LR: 0.00000213  \n","Epoch: [3][260/1277] Elapsed 1m 59s (remain 7m 44s) Loss: 0.4266(0.3197) Grad: 195272.0938  LR: 0.00000210  \n","Epoch: [3][280/1277] Elapsed 2m 8s (remain 7m 35s) Loss: 0.3383(0.3184) Grad: 198538.0000  LR: 0.00000207  \n","Epoch: [3][300/1277] Elapsed 2m 17s (remain 7m 26s) Loss: 0.2527(0.3147) Grad: 193918.5156  LR: 0.00000204  \n","Epoch: [3][320/1277] Elapsed 2m 26s (remain 7m 16s) Loss: 0.2930(0.3135) Grad: 268049.7812  LR: 0.00000201  \n","Epoch: [3][340/1277] Elapsed 2m 35s (remain 7m 8s) Loss: 0.3897(0.3145) Grad: 383825.7188  LR: 0.00000198  \n","Epoch: [3][360/1277] Elapsed 2m 44s (remain 6m 58s) Loss: 0.3598(0.3143) Grad: 163116.5781  LR: 0.00000195  \n","Epoch: [3][380/1277] Elapsed 2m 53s (remain 6m 48s) Loss: 0.3087(0.3157) Grad: 180348.1406  LR: 0.00000192  \n","Epoch: [3][400/1277] Elapsed 3m 2s (remain 6m 39s) Loss: 0.3880(0.3172) Grad: 444630.7812  LR: 0.00000189  \n","Epoch: [3][420/1277] Elapsed 3m 11s (remain 6m 29s) Loss: 0.1729(0.3172) Grad: 218857.4531  LR: 0.00000186  \n","Epoch: [3][440/1277] Elapsed 3m 20s (remain 6m 20s) Loss: 0.2269(0.3147) Grad: 287491.7812  LR: 0.00000183  \n","Epoch: [3][460/1277] Elapsed 3m 30s (remain 6m 12s) Loss: 0.2054(0.3126) Grad: 317861.6250  LR: 0.00000180  \n","Epoch: [3][480/1277] Elapsed 3m 39s (remain 6m 3s) Loss: 0.3514(0.3124) Grad: 288924.6562  LR: 0.00000177  \n","Epoch: [3][500/1277] Elapsed 3m 48s (remain 5m 54s) Loss: 0.4061(0.3133) Grad: 211539.7656  LR: 0.00000174  \n","Epoch: [3][520/1277] Elapsed 3m 58s (remain 5m 45s) Loss: 0.3554(0.3125) Grad: 274256.5938  LR: 0.00000171  \n","Epoch: [3][540/1277] Elapsed 4m 7s (remain 5m 36s) Loss: 0.2996(0.3130) Grad: 192513.2500  LR: 0.00000168  \n","Epoch: [3][560/1277] Elapsed 4m 16s (remain 5m 27s) Loss: 0.2574(0.3107) Grad: 267623.9375  LR: 0.00000165  \n","Epoch: [3][580/1277] Elapsed 4m 25s (remain 5m 17s) Loss: 0.0977(0.3098) Grad: 247554.8750  LR: 0.00000163  \n","Epoch: [3][600/1277] Elapsed 4m 34s (remain 5m 8s) Loss: 0.2403(0.3101) Grad: 194434.5000  LR: 0.00000160  \n","Epoch: [3][620/1277] Elapsed 4m 43s (remain 4m 59s) Loss: 0.1239(0.3093) Grad: 359382.9062  LR: 0.00000157  \n","Epoch: [3][640/1277] Elapsed 4m 52s (remain 4m 50s) Loss: 0.4381(0.3096) Grad: 235665.0469  LR: 0.00000154  \n","Epoch: [3][660/1277] Elapsed 5m 1s (remain 4m 41s) Loss: 0.3785(0.3094) Grad: 191696.0625  LR: 0.00000151  \n","Epoch: [3][680/1277] Elapsed 5m 10s (remain 4m 31s) Loss: 0.2351(0.3088) Grad: 140906.1875  LR: 0.00000148  \n","Epoch: [3][700/1277] Elapsed 5m 19s (remain 4m 22s) Loss: 0.2086(0.3087) Grad: 231183.1719  LR: 0.00000146  \n","Epoch: [3][720/1277] Elapsed 5m 28s (remain 4m 13s) Loss: 0.2014(0.3079) Grad: 219606.4062  LR: 0.00000143  \n","Epoch: [3][740/1277] Elapsed 5m 38s (remain 4m 4s) Loss: 0.1458(0.3069) Grad: 126610.4453  LR: 0.00000140  \n","Epoch: [3][760/1277] Elapsed 5m 47s (remain 3m 55s) Loss: 0.2786(0.3067) Grad: 323557.1875  LR: 0.00000137  \n","Epoch: [3][780/1277] Elapsed 5m 56s (remain 3m 46s) Loss: 0.2866(0.3076) Grad: 308733.5312  LR: 0.00000134  \n","Epoch: [3][800/1277] Elapsed 6m 4s (remain 3m 36s) Loss: 0.2541(0.3076) Grad: 362870.0625  LR: 0.00000132  \n","Epoch: [3][820/1277] Elapsed 6m 14s (remain 3m 27s) Loss: 0.1065(0.3082) Grad: 183398.4375  LR: 0.00000129  \n","Epoch: [3][840/1277] Elapsed 6m 22s (remain 3m 18s) Loss: 0.3927(0.3085) Grad: 184656.3438  LR: 0.00000126  \n","Epoch: [3][860/1277] Elapsed 6m 31s (remain 3m 9s) Loss: 0.1884(0.3078) Grad: 168103.3438  LR: 0.00000124  \n","Epoch: [3][880/1277] Elapsed 6m 40s (remain 2m 59s) Loss: 0.2716(0.3085) Grad: 173721.3125  LR: 0.00000121  \n","Epoch: [3][900/1277] Elapsed 6m 49s (remain 2m 50s) Loss: 0.2157(0.3082) Grad: 126675.3750  LR: 0.00000118  \n","Epoch: [3][920/1277] Elapsed 6m 58s (remain 2m 41s) Loss: 0.2099(0.3081) Grad: 399318.9375  LR: 0.00000116  \n","Epoch: [3][940/1277] Elapsed 7m 7s (remain 2m 32s) Loss: 0.3587(0.3093) Grad: 138390.5938  LR: 0.00000113  \n","Epoch: [3][960/1277] Elapsed 7m 16s (remain 2m 23s) Loss: 0.2261(0.3095) Grad: 128158.3359  LR: 0.00000111  \n","Epoch: [3][980/1277] Elapsed 7m 25s (remain 2m 14s) Loss: 0.3466(0.3098) Grad: 275330.4062  LR: 0.00000108  \n","Epoch: [3][1000/1277] Elapsed 7m 34s (remain 2m 5s) Loss: 0.3022(0.3103) Grad: 208628.2969  LR: 0.00000106  \n","Epoch: [3][1020/1277] Elapsed 7m 43s (remain 1m 56s) Loss: 0.2999(0.3095) Grad: 317949.7188  LR: 0.00000103  \n","Epoch: [3][1040/1277] Elapsed 7m 52s (remain 1m 47s) Loss: 0.3367(0.3097) Grad: 289345.8125  LR: 0.00000101  \n","Epoch: [3][1060/1277] Elapsed 8m 1s (remain 1m 38s) Loss: 0.2905(0.3094) Grad: 297974.2188  LR: 0.00000098  \n","Epoch: [3][1080/1277] Elapsed 8m 11s (remain 1m 29s) Loss: 0.4467(0.3093) Grad: 331255.3125  LR: 0.00000096  \n","Epoch: [3][1100/1277] Elapsed 8m 19s (remain 1m 19s) Loss: 0.1660(0.3086) Grad: 233930.6562  LR: 0.00000093  \n","Epoch: [3][1120/1277] Elapsed 8m 28s (remain 1m 10s) Loss: 0.3649(0.3090) Grad: 230854.4531  LR: 0.00000091  \n","Epoch: [3][1140/1277] Elapsed 8m 37s (remain 1m 1s) Loss: 0.3880(0.3088) Grad: 231544.3125  LR: 0.00000089  \n","Epoch: [3][1160/1277] Elapsed 8m 47s (remain 0m 52s) Loss: 0.2419(0.3083) Grad: 284179.2812  LR: 0.00000086  \n","Epoch: [3][1180/1277] Elapsed 8m 56s (remain 0m 43s) Loss: 0.2183(0.3077) Grad: 155362.9375  LR: 0.00000084  \n","Epoch: [3][1200/1277] Elapsed 9m 5s (remain 0m 34s) Loss: 0.1451(0.3080) Grad: 478854.5938  LR: 0.00000082  \n","Epoch: [3][1220/1277] Elapsed 9m 14s (remain 0m 25s) Loss: 0.3282(0.3083) Grad: 307757.2500  LR: 0.00000079  \n","Epoch: [3][1240/1277] Elapsed 9m 23s (remain 0m 16s) Loss: 0.2266(0.3082) Grad: 153740.5156  LR: 0.00000077  \n","Epoch: [3][1260/1277] Elapsed 9m 32s (remain 0m 7s) Loss: 0.1945(0.3080) Grad: 332692.1875  LR: 0.00000075  \n","Epoch: [3][1276/1277] Elapsed 9m 39s (remain 0m 0s) Loss: 0.3464(0.3085) Grad: 801323.0000  LR: 0.00000073  \n","EVAL: [0/258] Elapsed 0m 0s (remain 3m 31s) Loss: 0.2737(0.2737) \n","EVAL: [20/258] Elapsed 0m 12s (remain 2m 24s) Loss: 0.4559(0.3773) \n","EVAL: [40/258] Elapsed 0m 25s (remain 2m 12s) Loss: 0.3317(0.3782) \n","EVAL: [60/258] Elapsed 0m 37s (remain 1m 59s) Loss: 0.3299(0.3668) \n","EVAL: [80/258] Elapsed 0m 48s (remain 1m 46s) Loss: 0.4094(0.3676) \n","EVAL: [100/258] Elapsed 1m 0s (remain 1m 33s) Loss: 0.3404(0.3663) \n","EVAL: [120/258] Elapsed 1m 12s (remain 1m 22s) Loss: 0.4002(0.3697) \n","EVAL: [140/258] Elapsed 1m 24s (remain 1m 10s) Loss: 0.2813(0.3676) \n","EVAL: [160/258] Elapsed 1m 36s (remain 0m 58s) Loss: 0.3205(0.3685) \n","EVAL: [180/258] Elapsed 1m 47s (remain 0m 45s) Loss: 0.3373(0.3685) \n","EVAL: [200/258] Elapsed 1m 59s (remain 0m 33s) Loss: 0.2969(0.3654) \n","EVAL: [220/258] Elapsed 2m 11s (remain 0m 22s) Loss: 0.2400(0.3654) \n","EVAL: [240/258] Elapsed 2m 23s (remain 0m 10s) Loss: 0.3464(0.3637) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3085  avg_val_loss: 0.3618  time: 733s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3085  avg_val_loss: 0.3618  time: 733s\n","Epoch 3 - Score: 0.4632  Scores: [0.3758891248605638, 0.5504858324502362]\n","INFO:__main__:Epoch 3 - Score: 0.4632  Scores: [0.3758891248605638, 0.5504858324502362]\n","Epoch 3 - Save Best Score: 0.4632 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4632 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [257/258] Elapsed 2m 33s (remain 0m 0s) Loss: 0.2853(0.3618) \n","Epoch: [4][0/1277] Elapsed 0m 0s (remain 14m 47s) Loss: 0.2650(0.2650) Grad: inf  LR: 0.00000073  \n","Epoch: [4][20/1277] Elapsed 0m 9s (remain 9m 37s) Loss: 0.2176(0.3126) Grad: 520009.7188  LR: 0.00000071  \n","Epoch: [4][40/1277] Elapsed 0m 18s (remain 9m 24s) Loss: 0.1551(0.2799) Grad: 208722.3906  LR: 0.00000069  \n","Epoch: [4][60/1277] Elapsed 0m 27s (remain 9m 9s) Loss: 0.2049(0.2650) Grad: 306526.9062  LR: 0.00000067  \n","Epoch: [4][80/1277] Elapsed 0m 36s (remain 8m 57s) Loss: 0.2483(0.2699) Grad: 254686.7344  LR: 0.00000065  \n","Epoch: [4][100/1277] Elapsed 0m 45s (remain 8m 52s) Loss: 0.2115(0.2845) Grad: 212900.7656  LR: 0.00000063  \n","Epoch: [4][120/1277] Elapsed 0m 54s (remain 8m 44s) Loss: 0.3910(0.2815) Grad: 248575.9219  LR: 0.00000061  \n","Epoch: [4][140/1277] Elapsed 1m 4s (remain 8m 36s) Loss: 0.1880(0.2786) Grad: 139865.3594  LR: 0.00000059  \n","Epoch: [4][160/1277] Elapsed 1m 13s (remain 8m 27s) Loss: 0.1616(0.2827) Grad: 300131.3750  LR: 0.00000057  \n","Epoch: [4][180/1277] Elapsed 1m 22s (remain 8m 18s) Loss: 0.1015(0.2824) Grad: 229336.1719  LR: 0.00000055  \n","Epoch: [4][200/1277] Elapsed 1m 31s (remain 8m 8s) Loss: 0.3733(0.2830) Grad: 179609.1406  LR: 0.00000053  \n","Epoch: [4][220/1277] Elapsed 1m 40s (remain 8m 0s) Loss: 0.1526(0.2814) Grad: 327998.2812  LR: 0.00000051  \n","Epoch: [4][240/1277] Elapsed 1m 49s (remain 7m 51s) Loss: 0.3457(0.2812) Grad: 211139.3125  LR: 0.00000049  \n","Epoch: [4][260/1277] Elapsed 1m 58s (remain 7m 40s) Loss: 0.3485(0.2798) Grad: 191255.3906  LR: 0.00000047  \n","Epoch: [4][280/1277] Elapsed 2m 7s (remain 7m 32s) Loss: 0.1299(0.2791) Grad: 239175.6562  LR: 0.00000045  \n","Epoch: [4][300/1277] Elapsed 2m 17s (remain 7m 24s) Loss: 0.3553(0.2782) Grad: 213201.7188  LR: 0.00000044  \n","Epoch: [4][320/1277] Elapsed 2m 26s (remain 7m 15s) Loss: 0.1761(0.2802) Grad: 128336.4375  LR: 0.00000042  \n","Epoch: [4][340/1277] Elapsed 2m 35s (remain 7m 6s) Loss: 0.2288(0.2798) Grad: 172910.4219  LR: 0.00000040  \n","Epoch: [4][360/1277] Elapsed 2m 44s (remain 6m 56s) Loss: 0.1185(0.2771) Grad: 183846.4844  LR: 0.00000039  \n","Epoch: [4][380/1277] Elapsed 2m 53s (remain 6m 47s) Loss: 0.2291(0.2747) Grad: 215102.4531  LR: 0.00000037  \n","Epoch: [4][400/1277] Elapsed 3m 2s (remain 6m 38s) Loss: 0.2806(0.2742) Grad: 250414.7188  LR: 0.00000035  \n","Epoch: [4][420/1277] Elapsed 3m 11s (remain 6m 30s) Loss: 0.4599(0.2743) Grad: 218010.0000  LR: 0.00000034  \n","Epoch: [4][440/1277] Elapsed 3m 20s (remain 6m 20s) Loss: 0.2820(0.2746) Grad: 361853.9688  LR: 0.00000032  \n","Epoch: [4][460/1277] Elapsed 3m 30s (remain 6m 11s) Loss: 0.1924(0.2758) Grad: 398526.1875  LR: 0.00000031  \n","Epoch: [4][480/1277] Elapsed 3m 39s (remain 6m 3s) Loss: 0.1677(0.2751) Grad: 394980.1250  LR: 0.00000029  \n","Epoch: [4][500/1277] Elapsed 3m 48s (remain 5m 54s) Loss: 0.1393(0.2741) Grad: 197965.0625  LR: 0.00000028  \n","Epoch: [4][520/1277] Elapsed 3m 57s (remain 5m 44s) Loss: 0.2549(0.2746) Grad: 236569.4688  LR: 0.00000027  \n","Epoch: [4][540/1277] Elapsed 4m 6s (remain 5m 35s) Loss: 0.3771(0.2737) Grad: 389917.4062  LR: 0.00000025  \n","Epoch: [4][560/1277] Elapsed 4m 15s (remain 5m 26s) Loss: 0.2374(0.2732) Grad: 151757.0312  LR: 0.00000024  \n","Epoch: [4][580/1277] Elapsed 4m 24s (remain 5m 16s) Loss: 0.1644(0.2725) Grad: 346834.1875  LR: 0.00000023  \n","Epoch: [4][600/1277] Elapsed 4m 33s (remain 5m 7s) Loss: 0.1119(0.2722) Grad: 326735.8750  LR: 0.00000021  \n","Epoch: [4][620/1277] Elapsed 4m 42s (remain 4m 58s) Loss: 0.3450(0.2722) Grad: 142740.5156  LR: 0.00000020  \n","Epoch: [4][640/1277] Elapsed 4m 51s (remain 4m 49s) Loss: 0.2993(0.2719) Grad: 336054.0000  LR: 0.00000019  \n","Epoch: [4][660/1277] Elapsed 5m 1s (remain 4m 40s) Loss: 0.1518(0.2728) Grad: 208757.7812  LR: 0.00000018  \n","Epoch: [4][680/1277] Elapsed 5m 10s (remain 4m 31s) Loss: 0.4922(0.2728) Grad: 364915.2812  LR: 0.00000017  \n","Epoch: [4][700/1277] Elapsed 5m 19s (remain 4m 22s) Loss: 0.2584(0.2726) Grad: 250064.5625  LR: 0.00000016  \n","Epoch: [4][720/1277] Elapsed 5m 28s (remain 4m 13s) Loss: 0.2630(0.2718) Grad: 226489.3906  LR: 0.00000014  \n","Epoch: [4][740/1277] Elapsed 5m 37s (remain 4m 4s) Loss: 0.2563(0.2709) Grad: 276178.7188  LR: 0.00000013  \n","Epoch: [4][760/1277] Elapsed 5m 46s (remain 3m 54s) Loss: 0.1927(0.2711) Grad: 432413.3125  LR: 0.00000012  \n","Epoch: [4][780/1277] Elapsed 5m 55s (remain 3m 45s) Loss: 0.2776(0.2717) Grad: 201069.7969  LR: 0.00000012  \n","Epoch: [4][800/1277] Elapsed 6m 4s (remain 3m 36s) Loss: 0.1501(0.2717) Grad: 263664.9062  LR: 0.00000011  \n","Epoch: [4][820/1277] Elapsed 6m 13s (remain 3m 27s) Loss: 0.2633(0.2717) Grad: 560699.9375  LR: 0.00000010  \n","Epoch: [4][840/1277] Elapsed 6m 22s (remain 3m 18s) Loss: 0.2360(0.2715) Grad: 360719.8438  LR: 0.00000009  \n","Epoch: [4][860/1277] Elapsed 6m 31s (remain 3m 9s) Loss: 0.1853(0.2712) Grad: 129758.0938  LR: 0.00000008  \n","Epoch: [4][880/1277] Elapsed 6m 40s (remain 3m 0s) Loss: 0.2877(0.2714) Grad: 217413.0625  LR: 0.00000007  \n","Epoch: [4][900/1277] Elapsed 6m 49s (remain 2m 50s) Loss: 0.4616(0.2713) Grad: 123646.0469  LR: 0.00000007  \n","Epoch: [4][920/1277] Elapsed 6m 59s (remain 2m 41s) Loss: 0.3305(0.2717) Grad: 220986.8594  LR: 0.00000006  \n","Epoch: [4][940/1277] Elapsed 7m 7s (remain 2m 32s) Loss: 0.2269(0.2718) Grad: 334773.7500  LR: 0.00000005  \n","Epoch: [4][960/1277] Elapsed 7m 16s (remain 2m 23s) Loss: 0.3445(0.2719) Grad: 220926.7656  LR: 0.00000005  \n","Epoch: [4][980/1277] Elapsed 7m 25s (remain 2m 14s) Loss: 0.2085(0.2709) Grad: 204783.5781  LR: 0.00000004  \n","Epoch: [4][1000/1277] Elapsed 7m 34s (remain 2m 5s) Loss: 0.2511(0.2712) Grad: 220146.1562  LR: 0.00000004  \n","Epoch: [4][1020/1277] Elapsed 7m 42s (remain 1m 56s) Loss: 0.3519(0.2711) Grad: 261634.7656  LR: 0.00000003  \n","Epoch: [4][1040/1277] Elapsed 7m 51s (remain 1m 46s) Loss: 0.2165(0.2710) Grad: 208149.4844  LR: 0.00000003  \n","Epoch: [4][1060/1277] Elapsed 8m 1s (remain 1m 37s) Loss: 0.2752(0.2703) Grad: 283134.3438  LR: 0.00000002  \n","Epoch: [4][1080/1277] Elapsed 8m 10s (remain 1m 28s) Loss: 0.1208(0.2703) Grad: 195586.8594  LR: 0.00000002  \n","Epoch: [4][1100/1277] Elapsed 8m 19s (remain 1m 19s) Loss: 0.1678(0.2713) Grad: 84662.7344  LR: 0.00000001  \n","Epoch: [4][1120/1277] Elapsed 8m 28s (remain 1m 10s) Loss: 0.2939(0.2711) Grad: 122338.0469  LR: 0.00000001  \n","Epoch: [4][1140/1277] Elapsed 8m 37s (remain 1m 1s) Loss: 0.2177(0.2706) Grad: 169156.8125  LR: 0.00000001  \n","Epoch: [4][1160/1277] Elapsed 8m 46s (remain 0m 52s) Loss: 0.3177(0.2708) Grad: 359422.6562  LR: 0.00000001  \n","Epoch: [4][1180/1277] Elapsed 8m 55s (remain 0m 43s) Loss: 0.3493(0.2706) Grad: 234840.9531  LR: 0.00000000  \n","Epoch: [4][1200/1277] Elapsed 9m 5s (remain 0m 34s) Loss: 0.2618(0.2699) Grad: 174002.3281  LR: 0.00000000  \n","Epoch: [4][1220/1277] Elapsed 9m 14s (remain 0m 25s) Loss: 0.6760(0.2703) Grad: 365356.0312  LR: 0.00000000  \n","Epoch: [4][1240/1277] Elapsed 9m 23s (remain 0m 16s) Loss: 0.1763(0.2705) Grad: 171774.0938  LR: 0.00000000  \n","Epoch: [4][1260/1277] Elapsed 9m 32s (remain 0m 7s) Loss: 0.1796(0.2710) Grad: 173396.0312  LR: 0.00000000  \n","Epoch: [4][1276/1277] Elapsed 9m 39s (remain 0m 0s) Loss: 0.2014(0.2708) Grad: 329501.4375  LR: 0.00000000  \n","EVAL: [0/258] Elapsed 0m 0s (remain 3m 24s) Loss: 0.2589(0.2589) \n","EVAL: [20/258] Elapsed 0m 12s (remain 2m 24s) Loss: 0.5085(0.3696) \n","EVAL: [40/258] Elapsed 0m 25s (remain 2m 12s) Loss: 0.2827(0.3684) \n","EVAL: [60/258] Elapsed 0m 37s (remain 1m 59s) Loss: 0.2747(0.3558) \n","EVAL: [80/258] Elapsed 0m 48s (remain 1m 46s) Loss: 0.3894(0.3556) \n","EVAL: [100/258] Elapsed 1m 0s (remain 1m 33s) Loss: 0.3628(0.3541) \n","EVAL: [120/258] Elapsed 1m 12s (remain 1m 22s) Loss: 0.4118(0.3581) \n","EVAL: [140/258] Elapsed 1m 24s (remain 1m 9s) Loss: 0.2520(0.3564) \n","EVAL: [160/258] Elapsed 1m 36s (remain 0m 58s) Loss: 0.3161(0.3568) \n","EVAL: [180/258] Elapsed 1m 47s (remain 0m 45s) Loss: 0.2530(0.3562) \n","EVAL: [200/258] Elapsed 1m 59s (remain 0m 33s) Loss: 0.3151(0.3538) \n","EVAL: [220/258] Elapsed 2m 11s (remain 0m 22s) Loss: 0.2113(0.3534) \n","EVAL: [240/258] Elapsed 2m 23s (remain 0m 10s) Loss: 0.3414(0.3526) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2708  avg_val_loss: 0.3513  time: 733s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2708  avg_val_loss: 0.3513  time: 733s\n","Epoch 4 - Score: 0.4540  Scores: [0.37266360336853455, 0.535394213823385]\n","INFO:__main__:Epoch 4 - Score: 0.4540  Scores: [0.37266360336853455, 0.535394213823385]\n","Epoch 4 - Save Best Score: 0.4540 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.4540 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [257/258] Elapsed 2m 33s (remain 0m 0s) Loss: 0.2680(0.3513) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.4540  Scores: [0.37266360336853455, 0.535394213823385]\n","INFO:__main__:Score: 0.4540  Scores: [0.37266360336853455, 0.535394213823385]\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["========== prompt_id: ['3b9047'] validation ==========\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1289] Elapsed 0m 0s (remain 16m 11s) Loss: 1.2376(1.2376) Grad: nan  LR: 0.00000500  \n","Epoch: [1][20/1289] Elapsed 0m 9s (remain 9m 56s) Loss: 1.6091(0.9318) Grad: 266850.5000  LR: 0.00000500  \n","Epoch: [1][40/1289] Elapsed 0m 19s (remain 9m 41s) Loss: 0.5609(0.9295) Grad: 124631.8203  LR: 0.00000500  \n","Epoch: [1][60/1289] Elapsed 0m 28s (remain 9m 24s) Loss: 0.7300(0.8919) Grad: 401838.5312  LR: 0.00000500  \n","Epoch: [1][80/1289] Elapsed 0m 37s (remain 9m 11s) Loss: 0.4442(0.8588) Grad: 171857.3438  LR: 0.00000500  \n","Epoch: [1][100/1289] Elapsed 0m 46s (remain 9m 1s) Loss: 0.3721(0.8082) Grad: 170999.4844  LR: 0.00000500  \n","Epoch: [1][120/1289] Elapsed 0m 54s (remain 8m 50s) Loss: 0.6139(0.7650) Grad: 142920.8125  LR: 0.00000499  \n","Epoch: [1][140/1289] Elapsed 1m 4s (remain 8m 42s) Loss: 0.5772(0.7407) Grad: 236507.6094  LR: 0.00000499  \n","Epoch: [1][160/1289] Elapsed 1m 13s (remain 8m 33s) Loss: 0.7997(0.7087) Grad: 385758.9062  LR: 0.00000499  \n","Epoch: [1][180/1289] Elapsed 1m 22s (remain 8m 24s) Loss: 0.9469(0.6909) Grad: 542057.2500  LR: 0.00000498  \n","Epoch: [1][200/1289] Elapsed 1m 31s (remain 8m 15s) Loss: 0.9700(0.6798) Grad: 230194.2344  LR: 0.00000498  \n","Epoch: [1][220/1289] Elapsed 1m 40s (remain 8m 6s) Loss: 0.5551(0.6668) Grad: 157655.7188  LR: 0.00000498  \n","Epoch: [1][240/1289] Elapsed 1m 49s (remain 7m 56s) Loss: 0.2740(0.6470) Grad: 509346.4688  LR: 0.00000497  \n","Epoch: [1][260/1289] Elapsed 1m 58s (remain 7m 47s) Loss: 0.6503(0.6327) Grad: 470296.0625  LR: 0.00000497  \n","Epoch: [1][280/1289] Elapsed 2m 7s (remain 7m 38s) Loss: 0.5090(0.6238) Grad: 61241.4336  LR: 0.00000496  \n","Epoch: [1][300/1289] Elapsed 2m 16s (remain 7m 29s) Loss: 0.4635(0.6137) Grad: 153574.5469  LR: 0.00000496  \n","Epoch: [1][320/1289] Elapsed 2m 25s (remain 7m 20s) Loss: 0.3802(0.6030) Grad: 415974.0625  LR: 0.00000495  \n","Epoch: [1][340/1289] Elapsed 2m 34s (remain 7m 10s) Loss: 0.1862(0.5976) Grad: 203778.5156  LR: 0.00000495  \n","Epoch: [1][360/1289] Elapsed 2m 44s (remain 7m 1s) Loss: 0.4262(0.5892) Grad: 219371.8906  LR: 0.00000494  \n","Epoch: [1][380/1289] Elapsed 2m 53s (remain 6m 52s) Loss: 0.3064(0.5823) Grad: 194725.8906  LR: 0.00000493  \n","Epoch: [1][400/1289] Elapsed 3m 2s (remain 6m 43s) Loss: 0.6873(0.5727) Grad: 172876.9531  LR: 0.00000493  \n","Epoch: [1][420/1289] Elapsed 3m 10s (remain 6m 33s) Loss: 0.4460(0.5653) Grad: 352750.0000  LR: 0.00000492  \n","Epoch: [1][440/1289] Elapsed 3m 19s (remain 6m 24s) Loss: 0.6209(0.5605) Grad: 150348.4062  LR: 0.00000491  \n","Epoch: [1][460/1289] Elapsed 3m 28s (remain 6m 14s) Loss: 0.2319(0.5528) Grad: 107079.2266  LR: 0.00000490  \n","Epoch: [1][480/1289] Elapsed 3m 37s (remain 6m 5s) Loss: 0.2271(0.5479) Grad: 155766.5000  LR: 0.00000489  \n","Epoch: [1][500/1289] Elapsed 3m 46s (remain 5m 56s) Loss: 0.2717(0.5424) Grad: 107152.2891  LR: 0.00000488  \n","Epoch: [1][520/1289] Elapsed 3m 56s (remain 5m 47s) Loss: 0.3352(0.5397) Grad: 464631.4688  LR: 0.00000488  \n","Epoch: [1][540/1289] Elapsed 4m 5s (remain 5m 39s) Loss: 0.6099(0.5357) Grad: 137578.9219  LR: 0.00000487  \n","Epoch: [1][560/1289] Elapsed 4m 14s (remain 5m 30s) Loss: 0.2468(0.5323) Grad: 255320.2812  LR: 0.00000486  \n","Epoch: [1][580/1289] Elapsed 4m 23s (remain 5m 21s) Loss: 0.3168(0.5294) Grad: 168419.5625  LR: 0.00000484  \n","Epoch: [1][600/1289] Elapsed 4m 32s (remain 5m 11s) Loss: 0.4262(0.5270) Grad: 72958.8203  LR: 0.00000483  \n","Epoch: [1][620/1289] Elapsed 4m 41s (remain 5m 2s) Loss: 0.3804(0.5249) Grad: 125219.1562  LR: 0.00000482  \n","Epoch: [1][640/1289] Elapsed 4m 50s (remain 4m 53s) Loss: 0.3731(0.5216) Grad: 99119.5312  LR: 0.00000481  \n","Epoch: [1][660/1289] Elapsed 4m 59s (remain 4m 44s) Loss: 0.3327(0.5182) Grad: 175386.5625  LR: 0.00000480  \n","Epoch: [1][680/1289] Elapsed 5m 8s (remain 4m 35s) Loss: 0.6905(0.5139) Grad: 217465.5781  LR: 0.00000479  \n","Epoch: [1][700/1289] Elapsed 5m 17s (remain 4m 26s) Loss: 0.2457(0.5100) Grad: 133248.2969  LR: 0.00000478  \n","Epoch: [1][720/1289] Elapsed 5m 26s (remain 4m 17s) Loss: 0.4936(0.5068) Grad: 387119.8750  LR: 0.00000476  \n","Epoch: [1][740/1289] Elapsed 5m 35s (remain 4m 8s) Loss: 0.2979(0.5043) Grad: 183265.4844  LR: 0.00000475  \n","Epoch: [1][760/1289] Elapsed 5m 44s (remain 3m 59s) Loss: 0.4014(0.5011) Grad: 200216.6875  LR: 0.00000474  \n","Epoch: [1][780/1289] Elapsed 5m 53s (remain 3m 50s) Loss: 0.4027(0.4995) Grad: 185674.7500  LR: 0.00000472  \n","Epoch: [1][800/1289] Elapsed 6m 2s (remain 3m 40s) Loss: 0.4219(0.4975) Grad: 213027.9062  LR: 0.00000471  \n","Epoch: [1][820/1289] Elapsed 6m 11s (remain 3m 31s) Loss: 0.3288(0.4947) Grad: 87437.0312  LR: 0.00000469  \n","Epoch: [1][840/1289] Elapsed 6m 20s (remain 3m 22s) Loss: 0.5525(0.4917) Grad: 180395.7344  LR: 0.00000468  \n","Epoch: [1][860/1289] Elapsed 6m 30s (remain 3m 13s) Loss: 0.2866(0.4892) Grad: 99928.9375  LR: 0.00000466  \n","Epoch: [1][880/1289] Elapsed 6m 38s (remain 3m 4s) Loss: 0.3429(0.4870) Grad: 105211.6719  LR: 0.00000465  \n","Epoch: [1][900/1289] Elapsed 6m 48s (remain 2m 55s) Loss: 0.3310(0.4848) Grad: 132391.4219  LR: 0.00000463  \n","Epoch: [1][920/1289] Elapsed 6m 57s (remain 2m 46s) Loss: 0.2989(0.4822) Grad: 61761.6094  LR: 0.00000462  \n","Epoch: [1][940/1289] Elapsed 7m 6s (remain 2m 37s) Loss: 0.4422(0.4791) Grad: 75694.2734  LR: 0.00000460  \n","Epoch: [1][960/1289] Elapsed 7m 15s (remain 2m 28s) Loss: 0.3341(0.4774) Grad: 113814.1484  LR: 0.00000458  \n","Epoch: [1][980/1289] Elapsed 7m 24s (remain 2m 19s) Loss: 0.2322(0.4754) Grad: 101599.7969  LR: 0.00000457  \n","Epoch: [1][1000/1289] Elapsed 7m 33s (remain 2m 10s) Loss: 0.9001(0.4741) Grad: 214629.0312  LR: 0.00000455  \n","Epoch: [1][1020/1289] Elapsed 7m 41s (remain 2m 1s) Loss: 0.3002(0.4728) Grad: 297833.9062  LR: 0.00000453  \n","Epoch: [1][1040/1289] Elapsed 7m 50s (remain 1m 52s) Loss: 0.3364(0.4712) Grad: 101602.1250  LR: 0.00000451  \n","Epoch: [1][1060/1289] Elapsed 7m 59s (remain 1m 43s) Loss: 0.4021(0.4699) Grad: 146400.8594  LR: 0.00000450  \n","Epoch: [1][1080/1289] Elapsed 8m 8s (remain 1m 34s) Loss: 0.3230(0.4690) Grad: 193596.6406  LR: 0.00000448  \n","Epoch: [1][1100/1289] Elapsed 8m 17s (remain 1m 25s) Loss: 0.2912(0.4673) Grad: 78886.7031  LR: 0.00000446  \n","Epoch: [1][1120/1289] Elapsed 8m 26s (remain 1m 15s) Loss: 0.2286(0.4659) Grad: 250252.1875  LR: 0.00000444  \n","Epoch: [1][1140/1289] Elapsed 8m 36s (remain 1m 6s) Loss: 0.1804(0.4641) Grad: 51437.3047  LR: 0.00000442  \n","Epoch: [1][1160/1289] Elapsed 8m 44s (remain 0m 57s) Loss: 0.4030(0.4623) Grad: 106376.3594  LR: 0.00000440  \n","Epoch: [1][1180/1289] Elapsed 8m 54s (remain 0m 48s) Loss: 0.3408(0.4612) Grad: 180478.7812  LR: 0.00000438  \n","Epoch: [1][1200/1289] Elapsed 9m 3s (remain 0m 39s) Loss: 0.3651(0.4604) Grad: 161546.8281  LR: 0.00000436  \n","Epoch: [1][1220/1289] Elapsed 9m 11s (remain 0m 30s) Loss: 0.3736(0.4589) Grad: 115149.2344  LR: 0.00000434  \n","Epoch: [1][1240/1289] Elapsed 9m 20s (remain 0m 21s) Loss: 0.5385(0.4576) Grad: 123336.1094  LR: 0.00000432  \n","Epoch: [1][1260/1289] Elapsed 9m 29s (remain 0m 12s) Loss: 0.2628(0.4558) Grad: 115603.8984  LR: 0.00000430  \n","Epoch: [1][1280/1289] Elapsed 9m 38s (remain 0m 3s) Loss: 0.1386(0.4546) Grad: 82828.0391  LR: 0.00000428  \n","Epoch: [1][1288/1289] Elapsed 9m 41s (remain 0m 0s) Loss: 0.3609(0.4541) Grad: 111592.7500  LR: 0.00000427  \n","EVAL: [0/252] Elapsed 0m 0s (remain 3m 45s) Loss: 0.5672(0.5672) \n","EVAL: [20/252] Elapsed 0m 13s (remain 2m 27s) Loss: 0.3975(0.4520) \n","EVAL: [40/252] Elapsed 0m 25s (remain 2m 11s) Loss: 0.3200(0.4340) \n","EVAL: [60/252] Elapsed 0m 37s (remain 1m 57s) Loss: 0.4803(0.4528) \n","EVAL: [80/252] Elapsed 0m 49s (remain 1m 45s) Loss: 0.5909(0.4569) \n","EVAL: [100/252] Elapsed 1m 2s (remain 1m 32s) Loss: 0.3471(0.4569) \n","EVAL: [120/252] Elapsed 1m 14s (remain 1m 20s) Loss: 0.4773(0.4557) \n","EVAL: [140/252] Elapsed 1m 26s (remain 1m 8s) Loss: 0.2946(0.4586) \n","EVAL: [160/252] Elapsed 1m 38s (remain 0m 55s) Loss: 0.3939(0.4586) \n","EVAL: [180/252] Elapsed 1m 50s (remain 0m 43s) Loss: 0.4178(0.4557) \n","EVAL: [200/252] Elapsed 2m 2s (remain 0m 31s) Loss: 0.4145(0.4572) \n","EVAL: [220/252] Elapsed 2m 15s (remain 0m 18s) Loss: 0.6378(0.4618) \n","EVAL: [240/252] Elapsed 2m 26s (remain 0m 6s) Loss: 0.5444(0.4594) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.4541  avg_val_loss: 0.4596  time: 735s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4541  avg_val_loss: 0.4596  time: 735s\n","Epoch 1 - Score: 0.5944  Scores: [0.5877207411216726, 0.6010909329187237]\n","INFO:__main__:Epoch 1 - Score: 0.5944  Scores: [0.5877207411216726, 0.6010909329187237]\n","Epoch 1 - Save Best Score: 0.5944 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5944 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [251/252] Elapsed 2m 33s (remain 0m 0s) Loss: 0.3364(0.4596) \n","Epoch: [2][0/1289] Elapsed 0m 0s (remain 11m 43s) Loss: 0.5294(0.5294) Grad: inf  LR: 0.00000427  \n","Epoch: [2][20/1289] Elapsed 0m 9s (remain 9m 24s) Loss: 0.3933(0.3454) Grad: 313166.7188  LR: 0.00000425  \n","Epoch: [2][40/1289] Elapsed 0m 18s (remain 9m 17s) Loss: 0.4341(0.3620) Grad: 134612.7656  LR: 0.00000422  \n","Epoch: [2][60/1289] Elapsed 0m 27s (remain 9m 10s) Loss: 0.3282(0.3630) Grad: 161250.8594  LR: 0.00000420  \n","Epoch: [2][80/1289] Elapsed 0m 36s (remain 9m 2s) Loss: 0.3609(0.3581) Grad: 130250.9922  LR: 0.00000418  \n","Epoch: [2][100/1289] Elapsed 0m 45s (remain 8m 53s) Loss: 0.4451(0.3677) Grad: 217578.7031  LR: 0.00000416  \n","Epoch: [2][120/1289] Elapsed 0m 54s (remain 8m 44s) Loss: 0.3396(0.3667) Grad: 302873.7188  LR: 0.00000413  \n","Epoch: [2][140/1289] Elapsed 1m 3s (remain 8m 36s) Loss: 0.3137(0.3632) Grad: 185114.5938  LR: 0.00000411  \n","Epoch: [2][160/1289] Elapsed 1m 12s (remain 8m 27s) Loss: 0.3047(0.3622) Grad: 173369.1719  LR: 0.00000409  \n","Epoch: [2][180/1289] Elapsed 1m 21s (remain 8m 18s) Loss: 0.6222(0.3637) Grad: 165681.5469  LR: 0.00000406  \n","Epoch: [2][200/1289] Elapsed 1m 30s (remain 8m 9s) Loss: 0.3188(0.3636) Grad: 169375.4688  LR: 0.00000404  \n","Epoch: [2][220/1289] Elapsed 1m 39s (remain 7m 59s) Loss: 0.3896(0.3600) Grad: 167378.3438  LR: 0.00000401  \n","Epoch: [2][240/1289] Elapsed 1m 48s (remain 7m 50s) Loss: 0.1788(0.3556) Grad: 189024.6719  LR: 0.00000399  \n","Epoch: [2][260/1289] Elapsed 1m 57s (remain 7m 41s) Loss: 0.4447(0.3526) Grad: 222291.7656  LR: 0.00000397  \n","Epoch: [2][280/1289] Elapsed 2m 6s (remain 7m 32s) Loss: 0.2212(0.3524) Grad: 321159.5938  LR: 0.00000394  \n","Epoch: [2][300/1289] Elapsed 2m 15s (remain 7m 24s) Loss: 0.3368(0.3525) Grad: 121121.4609  LR: 0.00000392  \n","Epoch: [2][320/1289] Elapsed 2m 24s (remain 7m 14s) Loss: 0.4560(0.3521) Grad: 329019.8125  LR: 0.00000389  \n","Epoch: [2][340/1289] Elapsed 2m 33s (remain 7m 5s) Loss: 0.3532(0.3524) Grad: 327642.6875  LR: 0.00000387  \n","Epoch: [2][360/1289] Elapsed 2m 42s (remain 6m 57s) Loss: 0.5526(0.3532) Grad: 167743.7812  LR: 0.00000384  \n","Epoch: [2][380/1289] Elapsed 2m 51s (remain 6m 49s) Loss: 0.1941(0.3514) Grad: 236289.5625  LR: 0.00000381  \n","Epoch: [2][400/1289] Elapsed 3m 0s (remain 6m 39s) Loss: 0.5757(0.3515) Grad: 194827.8906  LR: 0.00000379  \n","Epoch: [2][420/1289] Elapsed 3m 9s (remain 6m 31s) Loss: 0.3319(0.3526) Grad: 133045.5938  LR: 0.00000376  \n","Epoch: [2][440/1289] Elapsed 3m 18s (remain 6m 21s) Loss: 0.1092(0.3521) Grad: 331183.3125  LR: 0.00000374  \n","Epoch: [2][480/1289] Elapsed 3m 36s (remain 6m 3s) Loss: 0.2864(0.3517) Grad: 192344.1875  LR: 0.00000368  \n","Epoch: [2][500/1289] Elapsed 3m 45s (remain 5m 54s) Loss: 0.3648(0.3517) Grad: 253645.8750  LR: 0.00000365  \n","Epoch: [2][520/1289] Elapsed 3m 54s (remain 5m 45s) Loss: 0.0928(0.3499) Grad: 171514.5469  LR: 0.00000363  \n","Epoch: [2][540/1289] Elapsed 4m 3s (remain 5m 36s) Loss: 0.1556(0.3486) Grad: 295291.7500  LR: 0.00000360  \n","Epoch: [2][560/1289] Elapsed 4m 12s (remain 5m 27s) Loss: 0.5888(0.3479) Grad: 243469.2969  LR: 0.00000357  \n","Epoch: [2][580/1289] Elapsed 4m 21s (remain 5m 18s) Loss: 0.4371(0.3484) Grad: 65147.8906  LR: 0.00000355  \n","Epoch: [2][600/1289] Elapsed 4m 30s (remain 5m 9s) Loss: 0.2603(0.3475) Grad: 433813.5625  LR: 0.00000352  \n","Epoch: [2][620/1289] Elapsed 4m 39s (remain 5m 0s) Loss: 0.3298(0.3472) Grad: 182434.5469  LR: 0.00000349  \n","Epoch: [2][640/1289] Elapsed 4m 48s (remain 4m 51s) Loss: 0.3125(0.3465) Grad: 309640.9062  LR: 0.00000346  \n","Epoch: [2][660/1289] Elapsed 4m 57s (remain 4m 42s) Loss: 0.2220(0.3452) Grad: 90559.7031  LR: 0.00000343  \n","Epoch: [2][680/1289] Elapsed 5m 6s (remain 4m 33s) Loss: 0.2075(0.3456) Grad: 146343.6719  LR: 0.00000341  \n","Epoch: [2][700/1289] Elapsed 5m 15s (remain 4m 24s) Loss: 0.2209(0.3464) Grad: 133063.4531  LR: 0.00000338  \n","Epoch: [2][720/1289] Elapsed 5m 24s (remain 4m 15s) Loss: 0.1837(0.3457) Grad: 301026.4375  LR: 0.00000335  \n","Epoch: [2][740/1289] Elapsed 5m 33s (remain 4m 6s) Loss: 0.4556(0.3468) Grad: 140437.2812  LR: 0.00000332  \n","Epoch: [2][760/1289] Elapsed 5m 42s (remain 3m 57s) Loss: 0.5852(0.3467) Grad: 335923.7188  LR: 0.00000329  \n","Epoch: [2][780/1289] Elapsed 5m 51s (remain 3m 48s) Loss: 0.3566(0.3457) Grad: 188685.4844  LR: 0.00000326  \n","Epoch: [2][800/1289] Elapsed 6m 0s (remain 3m 39s) Loss: 0.1608(0.3447) Grad: 151028.3594  LR: 0.00000323  \n","Epoch: [2][820/1289] Elapsed 6m 9s (remain 3m 30s) Loss: 0.5204(0.3446) Grad: 418115.7500  LR: 0.00000320  \n","Epoch: [2][840/1289] Elapsed 6m 18s (remain 3m 21s) Loss: 0.4596(0.3437) Grad: 327449.2188  LR: 0.00000317  \n","Epoch: [2][860/1289] Elapsed 6m 27s (remain 3m 12s) Loss: 0.2900(0.3430) Grad: 237628.1406  LR: 0.00000314  \n","Epoch: [2][880/1289] Elapsed 6m 36s (remain 3m 3s) Loss: 0.2865(0.3423) Grad: 188769.7031  LR: 0.00000312  \n","Epoch: [2][900/1289] Elapsed 6m 45s (remain 2m 54s) Loss: 0.3258(0.3420) Grad: 124603.7344  LR: 0.00000309  \n","Epoch: [2][920/1289] Elapsed 6m 54s (remain 2m 45s) Loss: 0.5737(0.3417) Grad: 401650.3125  LR: 0.00000306  \n","Epoch: [2][940/1289] Elapsed 7m 3s (remain 2m 36s) Loss: 0.4105(0.3413) Grad: 130171.0391  LR: 0.00000303  \n","Epoch: [2][960/1289] Elapsed 7m 12s (remain 2m 27s) Loss: 0.4395(0.3416) Grad: 263243.0625  LR: 0.00000300  \n","Epoch: [2][980/1289] Elapsed 7m 21s (remain 2m 18s) Loss: 0.2761(0.3412) Grad: 156122.1406  LR: 0.00000297  \n","Epoch: [2][1000/1289] Elapsed 7m 30s (remain 2m 9s) Loss: 0.2613(0.3406) Grad: 144479.3594  LR: 0.00000294  \n","Epoch: [2][1020/1289] Elapsed 7m 39s (remain 2m 0s) Loss: 0.4085(0.3406) Grad: 157775.7969  LR: 0.00000291  \n","Epoch: [2][1040/1289] Elapsed 7m 48s (remain 1m 51s) Loss: 0.4830(0.3409) Grad: 406713.0000  LR: 0.00000288  \n","Epoch: [2][1060/1289] Elapsed 7m 57s (remain 1m 42s) Loss: 0.3052(0.3407) Grad: 211545.8594  LR: 0.00000285  \n","Epoch: [2][1080/1289] Elapsed 8m 5s (remain 1m 33s) Loss: 0.3579(0.3406) Grad: 132133.7969  LR: 0.00000282  \n","Epoch: [2][1100/1289] Elapsed 8m 15s (remain 1m 24s) Loss: 0.1980(0.3395) Grad: 213022.5312  LR: 0.00000279  \n","Epoch: [2][1120/1289] Elapsed 8m 23s (remain 1m 15s) Loss: 0.4298(0.3390) Grad: 159525.4844  LR: 0.00000276  \n","Epoch: [2][1140/1289] Elapsed 8m 32s (remain 1m 6s) Loss: 0.4343(0.3387) Grad: 222881.8594  LR: 0.00000273  \n","Epoch: [2][1160/1289] Elapsed 8m 41s (remain 0m 57s) Loss: 0.2245(0.3377) Grad: 235828.4375  LR: 0.00000269  \n","Epoch: [2][1180/1289] Elapsed 8m 50s (remain 0m 48s) Loss: 0.8425(0.3385) Grad: 240299.3438  LR: 0.00000266  \n","Epoch: [2][1200/1289] Elapsed 8m 59s (remain 0m 39s) Loss: 0.3642(0.3380) Grad: 187280.6562  LR: 0.00000263  \n","Epoch: [2][1220/1289] Elapsed 9m 8s (remain 0m 30s) Loss: 0.5326(0.3383) Grad: 196432.5625  LR: 0.00000260  \n","Epoch: [2][1240/1289] Elapsed 9m 17s (remain 0m 21s) Loss: 0.6028(0.3379) Grad: 412835.7500  LR: 0.00000257  \n","Epoch: [2][1260/1289] Elapsed 9m 26s (remain 0m 12s) Loss: 0.3720(0.3378) Grad: 369893.5312  LR: 0.00000254  \n","Epoch: [2][1280/1289] Elapsed 9m 35s (remain 0m 3s) Loss: 0.4886(0.3382) Grad: 274516.1875  LR: 0.00000251  \n","Epoch: [2][1288/1289] Elapsed 9m 38s (remain 0m 0s) Loss: 0.2406(0.3382) Grad: 161483.5781  LR: 0.00000250  \n","EVAL: [0/252] Elapsed 0m 0s (remain 3m 40s) Loss: 0.4621(0.4621) \n","EVAL: [20/252] Elapsed 0m 13s (remain 2m 27s) Loss: 0.4073(0.4101) \n","EVAL: [40/252] Elapsed 0m 25s (remain 2m 10s) Loss: 0.3729(0.4044) \n","EVAL: [60/252] Elapsed 0m 37s (remain 1m 57s) Loss: 0.3917(0.4046) \n","EVAL: [80/252] Elapsed 0m 49s (remain 1m 45s) Loss: 0.4164(0.3997) \n","EVAL: [100/252] Elapsed 1m 1s (remain 1m 32s) Loss: 0.2961(0.3991) \n","EVAL: [120/252] Elapsed 1m 14s (remain 1m 20s) Loss: 0.3834(0.3972) \n","EVAL: [140/252] Elapsed 1m 26s (remain 1m 8s) Loss: 0.3945(0.3988) \n","EVAL: [160/252] Elapsed 1m 38s (remain 0m 55s) Loss: 0.5444(0.3967) \n","EVAL: [180/252] Elapsed 1m 49s (remain 0m 43s) Loss: 0.4354(0.3929) \n","EVAL: [200/252] Elapsed 2m 2s (remain 0m 31s) Loss: 0.3999(0.3949) \n","EVAL: [220/252] Elapsed 2m 15s (remain 0m 18s) Loss: 0.5268(0.3973) \n","EVAL: [240/252] Elapsed 2m 26s (remain 0m 6s) Loss: 0.5141(0.3948) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3382  avg_val_loss: 0.3954  time: 732s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3382  avg_val_loss: 0.3954  time: 732s\n","Epoch 2 - Score: 0.5176  Scores: [0.44339610022764575, 0.5918968850541536]\n","INFO:__main__:Epoch 2 - Score: 0.5176  Scores: [0.44339610022764575, 0.5918968850541536]\n","Epoch 2 - Save Best Score: 0.5176 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5176 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [251/252] Elapsed 2m 33s (remain 0m 0s) Loss: 0.3151(0.3954) \n","Epoch: [3][0/1289] Elapsed 0m 0s (remain 11m 42s) Loss: 0.3037(0.3037) Grad: inf  LR: 0.00000250  \n","Epoch: [3][20/1289] Elapsed 0m 9s (remain 9m 15s) Loss: 0.1733(0.3169) Grad: 210608.2188  LR: 0.00000247  \n","Epoch: [3][40/1289] Elapsed 0m 18s (remain 9m 12s) Loss: 0.3073(0.3092) Grad: 206460.2500  LR: 0.00000244  \n","Epoch: [3][60/1289] Elapsed 0m 27s (remain 9m 8s) Loss: 0.2219(0.2955) Grad: 277439.6250  LR: 0.00000241  \n","Epoch: [3][80/1289] Elapsed 0m 36s (remain 9m 1s) Loss: 0.4229(0.2967) Grad: 303381.6562  LR: 0.00000238  \n","Epoch: [3][100/1289] Elapsed 0m 45s (remain 8m 52s) Loss: 0.4359(0.3030) Grad: 249671.7812  LR: 0.00000235  \n","Epoch: [3][120/1289] Elapsed 0m 54s (remain 8m 42s) Loss: 0.2834(0.2998) Grad: 299375.6250  LR: 0.00000232  \n","Epoch: [3][140/1289] Elapsed 1m 3s (remain 8m 33s) Loss: 0.2361(0.3034) Grad: 211761.5000  LR: 0.00000229  \n","Epoch: [3][160/1289] Elapsed 1m 11s (remain 8m 24s) Loss: 0.1736(0.3023) Grad: 58681.0078  LR: 0.00000226  \n","Epoch: [3][180/1289] Elapsed 1m 20s (remain 8m 15s) Loss: 0.2708(0.3092) Grad: 193073.1406  LR: 0.00000222  \n","Epoch: [3][200/1289] Elapsed 1m 30s (remain 8m 7s) Loss: 0.1886(0.3079) Grad: 173131.2969  LR: 0.00000219  \n","Epoch: [3][220/1289] Elapsed 1m 38s (remain 7m 58s) Loss: 0.2131(0.3072) Grad: 107321.1875  LR: 0.00000216  \n","Epoch: [3][240/1289] Elapsed 1m 47s (remain 7m 48s) Loss: 0.1602(0.3039) Grad: 184210.6719  LR: 0.00000213  \n","Epoch: [3][260/1289] Elapsed 1m 56s (remain 7m 39s) Loss: 0.4610(0.3063) Grad: 226435.0000  LR: 0.00000210  \n","Epoch: [3][280/1289] Elapsed 2m 5s (remain 7m 31s) Loss: 0.5337(0.3076) Grad: 480817.3750  LR: 0.00000207  \n","Epoch: [3][300/1289] Elapsed 2m 14s (remain 7m 22s) Loss: 0.4629(0.3073) Grad: 543931.6875  LR: 0.00000204  \n","Epoch: [3][320/1289] Elapsed 2m 23s (remain 7m 13s) Loss: 0.3850(0.3059) Grad: 219039.0781  LR: 0.00000201  \n","Epoch: [3][340/1289] Elapsed 2m 32s (remain 7m 4s) Loss: 0.1916(0.3079) Grad: 120176.6719  LR: 0.00000198  \n","Epoch: [3][360/1289] Elapsed 2m 41s (remain 6m 55s) Loss: 0.2923(0.3084) Grad: 177037.6094  LR: 0.00000195  \n","Epoch: [3][380/1289] Elapsed 2m 50s (remain 6m 46s) Loss: 0.0877(0.3059) Grad: 285175.0938  LR: 0.00000192  \n","Epoch: [3][400/1289] Elapsed 2m 59s (remain 6m 37s) Loss: 0.2624(0.3055) Grad: 211380.0156  LR: 0.00000190  \n","Epoch: [3][420/1289] Elapsed 3m 8s (remain 6m 28s) Loss: 0.2840(0.3031) Grad: 210541.4844  LR: 0.00000187  \n","Epoch: [3][440/1289] Elapsed 3m 17s (remain 6m 19s) Loss: 0.3230(0.3040) Grad: 266830.2500  LR: 0.00000184  \n","Epoch: [3][460/1289] Elapsed 3m 26s (remain 6m 11s) Loss: 0.2837(0.3034) Grad: 267118.7812  LR: 0.00000181  \n","Epoch: [3][480/1289] Elapsed 3m 35s (remain 6m 1s) Loss: 0.3074(0.3032) Grad: 197829.1719  LR: 0.00000178  \n","Epoch: [3][500/1289] Elapsed 3m 44s (remain 5m 52s) Loss: 0.2752(0.3021) Grad: 158204.2500  LR: 0.00000175  \n","Epoch: [3][520/1289] Elapsed 3m 53s (remain 5m 44s) Loss: 0.2710(0.3014) Grad: 256874.4219  LR: 0.00000172  \n","Epoch: [3][540/1289] Elapsed 4m 2s (remain 5m 35s) Loss: 0.2875(0.3009) Grad: 181190.5938  LR: 0.00000169  \n","Epoch: [3][560/1289] Elapsed 4m 10s (remain 5m 25s) Loss: 0.2487(0.3014) Grad: 170760.1094  LR: 0.00000166  \n","Epoch: [3][580/1289] Elapsed 4m 19s (remain 5m 16s) Loss: 0.2675(0.3006) Grad: 124246.8203  LR: 0.00000163  \n","Epoch: [3][600/1289] Elapsed 4m 29s (remain 5m 8s) Loss: 0.3820(0.3012) Grad: 369616.7188  LR: 0.00000160  \n","Epoch: [3][620/1289] Elapsed 4m 37s (remain 4m 58s) Loss: 0.2440(0.2998) Grad: 152311.6875  LR: 0.00000158  \n","Epoch: [3][640/1289] Elapsed 4m 46s (remain 4m 49s) Loss: 0.4699(0.2995) Grad: 163843.3906  LR: 0.00000155  \n","Epoch: [3][660/1289] Elapsed 4m 55s (remain 4m 40s) Loss: 0.3692(0.2997) Grad: 179091.5000  LR: 0.00000152  \n","Epoch: [3][680/1289] Elapsed 5m 4s (remain 4m 31s) Loss: 0.2995(0.3005) Grad: 215925.2031  LR: 0.00000149  \n","Epoch: [3][700/1289] Elapsed 5m 13s (remain 4m 23s) Loss: 0.1763(0.2992) Grad: 147233.8125  LR: 0.00000146  \n","Epoch: [3][720/1289] Elapsed 5m 22s (remain 4m 14s) Loss: 0.2916(0.2983) Grad: 230940.5000  LR: 0.00000144  \n","Epoch: [3][740/1289] Elapsed 5m 31s (remain 4m 5s) Loss: 0.2579(0.2977) Grad: 178129.4219  LR: 0.00000141  \n","Epoch: [3][760/1289] Elapsed 5m 40s (remain 3m 56s) Loss: 0.3015(0.2982) Grad: 285133.4688  LR: 0.00000138  \n","Epoch: [3][780/1289] Elapsed 5m 49s (remain 3m 47s) Loss: 0.2224(0.2993) Grad: 232190.1875  LR: 0.00000135  \n","Epoch: [3][800/1289] Elapsed 5m 58s (remain 3m 38s) Loss: 0.2933(0.2988) Grad: 151977.7344  LR: 0.00000133  \n","Epoch: [3][820/1289] Elapsed 6m 7s (remain 3m 29s) Loss: 0.6302(0.2994) Grad: 163736.8438  LR: 0.00000130  \n","Epoch: [3][840/1289] Elapsed 6m 16s (remain 3m 20s) Loss: 0.2843(0.2994) Grad: 146853.5781  LR: 0.00000127  \n","Epoch: [3][860/1289] Elapsed 6m 24s (remain 3m 11s) Loss: 0.1947(0.2997) Grad: 263161.8125  LR: 0.00000125  \n","Epoch: [3][880/1289] Elapsed 6m 33s (remain 3m 2s) Loss: 0.2160(0.2993) Grad: 272743.0000  LR: 0.00000122  \n","Epoch: [3][900/1289] Elapsed 6m 42s (remain 2m 53s) Loss: 0.1902(0.2990) Grad: 184872.6875  LR: 0.00000120  \n","Epoch: [3][920/1289] Elapsed 6m 51s (remain 2m 44s) Loss: 0.1572(0.2980) Grad: 99177.7422  LR: 0.00000117  \n","Epoch: [3][940/1289] Elapsed 7m 0s (remain 2m 35s) Loss: 0.3072(0.2982) Grad: 149524.2812  LR: 0.00000114  \n","Epoch: [3][960/1289] Elapsed 7m 10s (remain 2m 26s) Loss: 0.3011(0.2975) Grad: 144932.4688  LR: 0.00000112  \n","Epoch: [3][980/1289] Elapsed 7m 18s (remain 2m 17s) Loss: 0.3335(0.2973) Grad: 331403.1875  LR: 0.00000109  \n","Epoch: [3][1000/1289] Elapsed 7m 28s (remain 2m 8s) Loss: 0.1624(0.2969) Grad: 201474.5781  LR: 0.00000107  \n","Epoch: [3][1020/1289] Elapsed 7m 37s (remain 2m 0s) Loss: 0.3697(0.2976) Grad: 170136.6250  LR: 0.00000104  \n","Epoch: [3][1040/1289] Elapsed 7m 46s (remain 1m 51s) Loss: 0.3147(0.2970) Grad: 128328.1406  LR: 0.00000102  \n","Epoch: [3][1060/1289] Elapsed 7m 55s (remain 1m 42s) Loss: 0.2924(0.2973) Grad: 141238.1094  LR: 0.00000099  \n","Epoch: [3][1080/1289] Elapsed 8m 4s (remain 1m 33s) Loss: 0.3837(0.2972) Grad: 227767.0000  LR: 0.00000097  \n","Epoch: [3][1100/1289] Elapsed 8m 13s (remain 1m 24s) Loss: 0.4266(0.2968) Grad: 183897.1094  LR: 0.00000095  \n","Epoch: [3][1120/1289] Elapsed 8m 22s (remain 1m 15s) Loss: 0.1346(0.2970) Grad: 149193.5938  LR: 0.00000092  \n","Epoch: [3][1140/1289] Elapsed 8m 31s (remain 1m 6s) Loss: 0.1973(0.2962) Grad: 250344.9531  LR: 0.00000090  \n","Epoch: [3][1160/1289] Elapsed 8m 40s (remain 0m 57s) Loss: 0.3062(0.2962) Grad: 383043.4062  LR: 0.00000088  \n","Epoch: [3][1180/1289] Elapsed 8m 49s (remain 0m 48s) Loss: 0.2657(0.2959) Grad: 161152.7656  LR: 0.00000085  \n","Epoch: [3][1200/1289] Elapsed 8m 58s (remain 0m 39s) Loss: 0.1926(0.2952) Grad: 137753.1250  LR: 0.00000083  \n","Epoch: [3][1220/1289] Elapsed 9m 7s (remain 0m 30s) Loss: 0.2207(0.2952) Grad: 132263.7812  LR: 0.00000081  \n","Epoch: [3][1240/1289] Elapsed 9m 16s (remain 0m 21s) Loss: 0.2449(0.2951) Grad: 255406.9375  LR: 0.00000078  \n","Epoch: [3][1260/1289] Elapsed 9m 25s (remain 0m 12s) Loss: 0.2419(0.2946) Grad: 140519.8906  LR: 0.00000076  \n","Epoch: [3][1280/1289] Elapsed 9m 34s (remain 0m 3s) Loss: 0.4354(0.2952) Grad: 656492.6875  LR: 0.00000074  \n","Epoch: [3][1288/1289] Elapsed 9m 37s (remain 0m 0s) Loss: 0.3087(0.2950) Grad: 104610.2891  LR: 0.00000073  \n","EVAL: [0/252] Elapsed 0m 0s (remain 3m 40s) Loss: 0.4123(0.4123) \n","EVAL: [20/252] Elapsed 0m 13s (remain 2m 26s) Loss: 0.4173(0.3890) \n","EVAL: [40/252] Elapsed 0m 25s (remain 2m 10s) Loss: 0.3304(0.3946) \n","EVAL: [60/252] Elapsed 0m 37s (remain 1m 57s) Loss: 0.3509(0.4003) \n","EVAL: [80/252] Elapsed 0m 49s (remain 1m 45s) Loss: 0.4160(0.3974) \n","EVAL: [100/252] Elapsed 1m 1s (remain 1m 32s) Loss: 0.3200(0.3985) \n","EVAL: [120/252] Elapsed 1m 14s (remain 1m 20s) Loss: 0.3553(0.3950) \n","EVAL: [140/252] Elapsed 1m 26s (remain 1m 8s) Loss: 0.3329(0.3966) \n","EVAL: [160/252] Elapsed 1m 38s (remain 0m 55s) Loss: 0.5155(0.3952) \n","EVAL: [180/252] Elapsed 1m 49s (remain 0m 43s) Loss: 0.3877(0.3925) \n","EVAL: [200/252] Elapsed 2m 2s (remain 0m 31s) Loss: 0.3561(0.3937) \n","EVAL: [220/252] Elapsed 2m 15s (remain 0m 18s) Loss: 0.6032(0.3959) \n","EVAL: [240/252] Elapsed 2m 26s (remain 0m 6s) Loss: 0.4241(0.3932) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2950  avg_val_loss: 0.3934  time: 731s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2950  avg_val_loss: 0.3934  time: 731s\n","Epoch 3 - Score: 0.5154  Scores: [0.4475831202910627, 0.5832722188103178]\n","INFO:__main__:Epoch 3 - Score: 0.5154  Scores: [0.4475831202910627, 0.5832722188103178]\n","Epoch 3 - Save Best Score: 0.5154 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5154 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [251/252] Elapsed 2m 33s (remain 0m 0s) Loss: 0.3511(0.3934) \n","Epoch: [4][0/1289] Elapsed 0m 0s (remain 15m 13s) Loss: 0.1822(0.1822) Grad: 724344.4375  LR: 0.00000073  \n","Epoch: [4][20/1289] Elapsed 0m 9s (remain 9m 30s) Loss: 0.3886(0.2500) Grad: 145595.4375  LR: 0.00000071  \n","Epoch: [4][40/1289] Elapsed 0m 18s (remain 9m 17s) Loss: 0.2413(0.2440) Grad: 289256.1562  LR: 0.00000069  \n","Epoch: [4][60/1289] Elapsed 0m 27s (remain 9m 8s) Loss: 0.1585(0.2562) Grad: 308742.5938  LR: 0.00000067  \n","Epoch: [4][80/1289] Elapsed 0m 36s (remain 8m 58s) Loss: 0.1058(0.2560) Grad: 322421.5938  LR: 0.00000065  \n","Epoch: [4][100/1289] Elapsed 0m 45s (remain 8m 52s) Loss: 0.4043(0.2603) Grad: 211977.3750  LR: 0.00000063  \n","Epoch: [4][120/1289] Elapsed 0m 54s (remain 8m 45s) Loss: 0.3022(0.2601) Grad: 207838.7188  LR: 0.00000061  \n","Epoch: [4][140/1289] Elapsed 1m 3s (remain 8m 37s) Loss: 0.1975(0.2568) Grad: 147779.5781  LR: 0.00000059  \n","Epoch: [4][160/1289] Elapsed 1m 12s (remain 8m 27s) Loss: 0.1016(0.2582) Grad: 277890.4688  LR: 0.00000057  \n","Epoch: [4][180/1289] Elapsed 1m 21s (remain 8m 16s) Loss: 0.3234(0.2574) Grad: 176850.5312  LR: 0.00000055  \n","Epoch: [4][200/1289] Elapsed 1m 30s (remain 8m 8s) Loss: 0.4145(0.2575) Grad: 135581.0000  LR: 0.00000053  \n","Epoch: [4][220/1289] Elapsed 1m 39s (remain 7m 59s) Loss: 0.3142(0.2580) Grad: 127353.0391  LR: 0.00000051  \n","Epoch: [4][240/1289] Elapsed 1m 48s (remain 7m 49s) Loss: 0.4177(0.2588) Grad: 166398.0938  LR: 0.00000049  \n","Epoch: [4][260/1289] Elapsed 1m 57s (remain 7m 41s) Loss: 0.1543(0.2575) Grad: 243870.8906  LR: 0.00000047  \n","Epoch: [4][280/1289] Elapsed 2m 6s (remain 7m 33s) Loss: 0.3930(0.2567) Grad: 301682.5000  LR: 0.00000046  \n","Epoch: [4][300/1289] Elapsed 2m 15s (remain 7m 23s) Loss: 0.3738(0.2571) Grad: 176705.5469  LR: 0.00000044  \n","Epoch: [4][320/1289] Elapsed 2m 24s (remain 7m 15s) Loss: 0.2657(0.2565) Grad: 151043.1406  LR: 0.00000042  \n","Epoch: [4][340/1289] Elapsed 2m 33s (remain 7m 5s) Loss: 0.2422(0.2573) Grad: 260344.7500  LR: 0.00000041  \n","Epoch: [4][360/1289] Elapsed 2m 41s (remain 6m 55s) Loss: 0.1174(0.2559) Grad: 262546.5312  LR: 0.00000039  \n","Epoch: [4][380/1289] Elapsed 2m 50s (remain 6m 46s) Loss: 0.3377(0.2571) Grad: 232708.2344  LR: 0.00000037  \n","Epoch: [4][400/1289] Elapsed 2m 59s (remain 6m 37s) Loss: 0.1835(0.2565) Grad: 410698.0625  LR: 0.00000036  \n","Epoch: [4][420/1289] Elapsed 3m 8s (remain 6m 28s) Loss: 0.2846(0.2572) Grad: 113816.4375  LR: 0.00000034  \n","Epoch: [4][440/1289] Elapsed 3m 17s (remain 6m 20s) Loss: 0.1018(0.2579) Grad: 228437.4219  LR: 0.00000033  \n","Epoch: [4][460/1289] Elapsed 3m 26s (remain 6m 11s) Loss: 0.2020(0.2558) Grad: 209873.6406  LR: 0.00000031  \n","Epoch: [4][480/1289] Elapsed 3m 35s (remain 6m 2s) Loss: 0.3867(0.2545) Grad: 210956.5000  LR: 0.00000030  \n","Epoch: [4][500/1289] Elapsed 3m 44s (remain 5m 53s) Loss: 0.3368(0.2561) Grad: 136123.3750  LR: 0.00000028  \n","Epoch: [4][520/1289] Elapsed 3m 54s (remain 5m 45s) Loss: 0.1833(0.2569) Grad: 197921.7344  LR: 0.00000027  \n","Epoch: [4][540/1289] Elapsed 4m 3s (remain 5m 36s) Loss: 0.2513(0.2566) Grad: 342246.5000  LR: 0.00000026  \n","Epoch: [4][560/1289] Elapsed 4m 12s (remain 5m 27s) Loss: 0.2317(0.2575) Grad: 284532.4062  LR: 0.00000024  \n","Epoch: [4][580/1289] Elapsed 4m 21s (remain 5m 18s) Loss: 0.1946(0.2584) Grad: 254423.4062  LR: 0.00000023  \n","Epoch: [4][600/1289] Elapsed 4m 30s (remain 5m 9s) Loss: 0.1367(0.2574) Grad: 185944.5781  LR: 0.00000022  \n","Epoch: [4][620/1289] Elapsed 4m 39s (remain 5m 0s) Loss: 0.2799(0.2575) Grad: 916260.3125  LR: 0.00000020  \n","Epoch: [4][640/1289] Elapsed 4m 48s (remain 4m 51s) Loss: 0.1792(0.2572) Grad: 244126.9062  LR: 0.00000019  \n","Epoch: [4][660/1289] Elapsed 4m 57s (remain 4m 42s) Loss: 0.1655(0.2572) Grad: 150707.8281  LR: 0.00000018  \n","Epoch: [4][680/1289] Elapsed 5m 6s (remain 4m 33s) Loss: 0.4021(0.2580) Grad: 304893.5625  LR: 0.00000017  \n","Epoch: [4][700/1289] Elapsed 5m 15s (remain 4m 24s) Loss: 0.3522(0.2577) Grad: 226055.7812  LR: 0.00000016  \n","Epoch: [4][720/1289] Elapsed 5m 24s (remain 4m 15s) Loss: 0.2099(0.2585) Grad: 82719.7188  LR: 0.00000015  \n","Epoch: [4][740/1289] Elapsed 5m 33s (remain 4m 6s) Loss: 0.1900(0.2591) Grad: 104608.1797  LR: 0.00000014  \n","Epoch: [4][760/1289] Elapsed 5m 42s (remain 3m 57s) Loss: 0.2430(0.2596) Grad: 251885.9062  LR: 0.00000013  \n","Epoch: [4][780/1289] Elapsed 5m 50s (remain 3m 48s) Loss: 0.1143(0.2596) Grad: 290300.2812  LR: 0.00000012  \n","Epoch: [4][800/1289] Elapsed 5m 59s (remain 3m 39s) Loss: 0.5023(0.2609) Grad: 332338.1875  LR: 0.00000011  \n","Epoch: [4][820/1289] Elapsed 6m 9s (remain 3m 30s) Loss: 0.2257(0.2603) Grad: 177177.3750  LR: 0.00000010  \n","Epoch: [4][840/1289] Elapsed 6m 18s (remain 3m 21s) Loss: 0.2483(0.2602) Grad: 163746.4844  LR: 0.00000009  \n","Epoch: [4][860/1289] Elapsed 6m 27s (remain 3m 12s) Loss: 0.2157(0.2602) Grad: 267768.4062  LR: 0.00000008  \n","Epoch: [4][880/1289] Elapsed 6m 36s (remain 3m 3s) Loss: 0.3840(0.2602) Grad: 280606.4688  LR: 0.00000008  \n","Epoch: [4][900/1289] Elapsed 6m 45s (remain 2m 54s) Loss: 0.3115(0.2595) Grad: 184180.6562  LR: 0.00000007  \n","Epoch: [4][920/1289] Elapsed 6m 54s (remain 2m 45s) Loss: 0.2494(0.2595) Grad: 211266.4844  LR: 0.00000006  \n","Epoch: [4][940/1289] Elapsed 7m 3s (remain 2m 36s) Loss: 0.1933(0.2593) Grad: 166118.3750  LR: 0.00000006  \n","Epoch: [4][960/1289] Elapsed 7m 12s (remain 2m 27s) Loss: 0.2193(0.2592) Grad: 250794.2188  LR: 0.00000005  \n","Epoch: [4][980/1289] Elapsed 7m 21s (remain 2m 18s) Loss: 0.3069(0.2586) Grad: 299929.6875  LR: 0.00000004  \n","Epoch: [4][1000/1289] Elapsed 7m 30s (remain 2m 9s) Loss: 0.2288(0.2589) Grad: 175490.4375  LR: 0.00000004  \n","Epoch: [4][1020/1289] Elapsed 7m 38s (remain 2m 0s) Loss: 0.3976(0.2597) Grad: 200377.5000  LR: 0.00000003  \n","Epoch: [4][1040/1289] Elapsed 7m 47s (remain 1m 51s) Loss: 0.2652(0.2594) Grad: 159714.5469  LR: 0.00000003  \n","Epoch: [4][1060/1289] Elapsed 7m 56s (remain 1m 42s) Loss: 0.1474(0.2585) Grad: 172195.3750  LR: 0.00000002  \n","Epoch: [4][1080/1289] Elapsed 8m 5s (remain 1m 33s) Loss: 0.2936(0.2590) Grad: 197979.7812  LR: 0.00000002  \n","Epoch: [4][1100/1289] Elapsed 8m 14s (remain 1m 24s) Loss: 0.2294(0.2591) Grad: 174460.0781  LR: 0.00000002  \n","Epoch: [4][1120/1289] Elapsed 8m 23s (remain 1m 15s) Loss: 0.1032(0.2595) Grad: 264314.6875  LR: 0.00000001  \n","Epoch: [4][1140/1289] Elapsed 8m 32s (remain 1m 6s) Loss: 0.4275(0.2596) Grad: 269341.5000  LR: 0.00000001  \n","Epoch: [4][1160/1289] Elapsed 8m 41s (remain 0m 57s) Loss: 0.2364(0.2596) Grad: 142450.1562  LR: 0.00000001  \n","Epoch: [4][1180/1289] Elapsed 8m 50s (remain 0m 48s) Loss: 0.2297(0.2592) Grad: 255796.2188  LR: 0.00000001  \n","Epoch: [4][1200/1289] Elapsed 8m 59s (remain 0m 39s) Loss: 0.2504(0.2590) Grad: 169285.4531  LR: 0.00000000  \n","Epoch: [4][1220/1289] Elapsed 9m 8s (remain 0m 30s) Loss: 0.2056(0.2588) Grad: 256065.3281  LR: 0.00000000  \n","Epoch: [4][1240/1289] Elapsed 9m 17s (remain 0m 21s) Loss: 0.2600(0.2584) Grad: 157653.4375  LR: 0.00000000  \n","Epoch: [4][1260/1289] Elapsed 9m 26s (remain 0m 12s) Loss: 0.3765(0.2584) Grad: 191301.9375  LR: 0.00000000  \n","Epoch: [4][1280/1289] Elapsed 9m 35s (remain 0m 3s) Loss: 0.3162(0.2580) Grad: 174885.7031  LR: 0.00000000  \n","Epoch: [4][1288/1289] Elapsed 9m 38s (remain 0m 0s) Loss: 0.3452(0.2581) Grad: 324631.9062  LR: 0.00000000  \n","EVAL: [0/252] Elapsed 0m 0s (remain 3m 40s) Loss: 0.4307(0.4307) \n","EVAL: [20/252] Elapsed 0m 13s (remain 2m 27s) Loss: 0.4501(0.3945) \n","EVAL: [40/252] Elapsed 0m 25s (remain 2m 11s) Loss: 0.3347(0.3978) \n","EVAL: [60/252] Elapsed 0m 37s (remain 1m 57s) Loss: 0.3650(0.4029) \n","EVAL: [80/252] Elapsed 0m 49s (remain 1m 45s) Loss: 0.4272(0.4001) \n","EVAL: [100/252] Elapsed 1m 2s (remain 1m 32s) Loss: 0.3299(0.4004) \n","EVAL: [120/252] Elapsed 1m 14s (remain 1m 20s) Loss: 0.3811(0.3979) \n","EVAL: [140/252] Elapsed 1m 26s (remain 1m 8s) Loss: 0.3227(0.4001) \n","EVAL: [160/252] Elapsed 1m 38s (remain 0m 55s) Loss: 0.5500(0.3976) \n","EVAL: [180/252] Elapsed 1m 50s (remain 0m 43s) Loss: 0.4005(0.3933) \n","EVAL: [200/252] Elapsed 2m 2s (remain 0m 31s) Loss: 0.3764(0.3951) \n","EVAL: [220/252] Elapsed 2m 15s (remain 0m 18s) Loss: 0.6323(0.3968) \n","EVAL: [240/252] Elapsed 2m 26s (remain 0m 6s) Loss: 0.4412(0.3941) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2581  avg_val_loss: 0.3946  time: 732s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2581  avg_val_loss: 0.3946  time: 732s\n","Epoch 4 - Score: 0.5228  Scores: [0.450661410491065, 0.5948672079203755]\n","INFO:__main__:Epoch 4 - Score: 0.5228  Scores: [0.450661410491065, 0.5948672079203755]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [251/252] Elapsed 2m 33s (remain 0m 0s) Loss: 0.3116(0.3946) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.5154  Scores: [0.4475831202910627, 0.5832722188103178]\n","INFO:__main__:Score: 0.5154  Scores: [0.4475831202910627, 0.5832722188103178]\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["========== prompt_id: ['ebad26'] validation ==========\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1292] Elapsed 0m 0s (remain 16m 9s) Loss: 1.4342(1.4342) Grad: nan  LR: 0.00000500  \n","Epoch: [1][20/1292] Elapsed 0m 8s (remain 8m 28s) Loss: 1.0119(0.9455) Grad: 201054.6562  LR: 0.00000500  \n","Epoch: [1][40/1292] Elapsed 0m 15s (remain 7m 57s) Loss: 1.0625(0.8883) Grad: 75256.3672  LR: 0.00000500  \n","Epoch: [1][60/1292] Elapsed 0m 22s (remain 7m 43s) Loss: 1.1341(0.8801) Grad: 81185.2031  LR: 0.00000500  \n","Epoch: [1][80/1292] Elapsed 0m 30s (remain 7m 34s) Loss: 0.9065(0.8563) Grad: 486867.8438  LR: 0.00000500  \n","Epoch: [1][100/1292] Elapsed 0m 37s (remain 7m 22s) Loss: 0.7311(0.8419) Grad: 333033.4375  LR: 0.00000500  \n","Epoch: [1][120/1292] Elapsed 0m 44s (remain 7m 12s) Loss: 0.8501(0.8026) Grad: 1027921.8750  LR: 0.00000499  \n","Epoch: [1][140/1292] Elapsed 0m 52s (remain 7m 4s) Loss: 0.7499(0.7703) Grad: 273457.9375  LR: 0.00000499  \n","Epoch: [1][160/1292] Elapsed 0m 59s (remain 6m 59s) Loss: 0.5519(0.7593) Grad: 168532.8750  LR: 0.00000499  \n","Epoch: [1][180/1292] Elapsed 1m 6s (remain 6m 48s) Loss: 0.4082(0.7419) Grad: 167107.2656  LR: 0.00000498  \n","Epoch: [1][200/1292] Elapsed 1m 13s (remain 6m 39s) Loss: 0.6370(0.7266) Grad: 206139.8125  LR: 0.00000498  \n","Epoch: [1][220/1292] Elapsed 1m 20s (remain 6m 31s) Loss: 0.3339(0.7104) Grad: 213061.9062  LR: 0.00000498  \n","Epoch: [1][240/1292] Elapsed 1m 27s (remain 6m 22s) Loss: 0.4159(0.6910) Grad: 205713.8750  LR: 0.00000497  \n","Epoch: [1][260/1292] Elapsed 1m 34s (remain 6m 15s) Loss: 0.4893(0.6778) Grad: 216110.8281  LR: 0.00000497  \n","Epoch: [1][280/1292] Elapsed 1m 42s (remain 6m 8s) Loss: 0.4081(0.6644) Grad: 296221.4062  LR: 0.00000496  \n","Epoch: [1][300/1292] Elapsed 1m 49s (remain 6m 0s) Loss: 0.5664(0.6588) Grad: 174124.3906  LR: 0.00000496  \n","Epoch: [1][320/1292] Elapsed 1m 56s (remain 5m 53s) Loss: 0.6443(0.6550) Grad: 125706.6641  LR: 0.00000495  \n","Epoch: [1][340/1292] Elapsed 2m 4s (remain 5m 45s) Loss: 0.7005(0.6499) Grad: 82254.1250  LR: 0.00000495  \n","Epoch: [1][360/1292] Elapsed 2m 11s (remain 5m 38s) Loss: 0.4514(0.6398) Grad: 117702.7109  LR: 0.00000494  \n","Epoch: [1][380/1292] Elapsed 2m 18s (remain 5m 30s) Loss: 0.4146(0.6304) Grad: 85197.6172  LR: 0.00000493  \n","Epoch: [1][400/1292] Elapsed 2m 25s (remain 5m 22s) Loss: 0.2573(0.6227) Grad: 121447.4609  LR: 0.00000493  \n","Epoch: [1][420/1292] Elapsed 2m 32s (remain 5m 15s) Loss: 0.3014(0.6146) Grad: 86117.4844  LR: 0.00000492  \n","Epoch: [1][440/1292] Elapsed 2m 39s (remain 5m 7s) Loss: 0.3788(0.6078) Grad: 113868.9297  LR: 0.00000491  \n","Epoch: [1][460/1292] Elapsed 2m 46s (remain 5m 0s) Loss: 0.4337(0.6007) Grad: 137510.7969  LR: 0.00000490  \n","Epoch: [1][480/1292] Elapsed 2m 53s (remain 4m 52s) Loss: 0.4048(0.5926) Grad: 156556.8594  LR: 0.00000489  \n","Epoch: [1][500/1292] Elapsed 3m 0s (remain 4m 45s) Loss: 0.5728(0.5862) Grad: 229262.5312  LR: 0.00000488  \n","Epoch: [1][520/1292] Elapsed 3m 7s (remain 4m 38s) Loss: 0.4845(0.5808) Grad: 161266.5938  LR: 0.00000488  \n","Epoch: [1][540/1292] Elapsed 3m 15s (remain 4m 31s) Loss: 0.3236(0.5763) Grad: 95945.1719  LR: 0.00000487  \n","Epoch: [1][560/1292] Elapsed 3m 22s (remain 4m 24s) Loss: 0.3050(0.5697) Grad: 140082.2812  LR: 0.00000486  \n","Epoch: [1][580/1292] Elapsed 3m 30s (remain 4m 17s) Loss: 0.3662(0.5643) Grad: 76523.2734  LR: 0.00000485  \n","Epoch: [1][600/1292] Elapsed 3m 37s (remain 4m 9s) Loss: 0.7876(0.5610) Grad: 156967.3906  LR: 0.00000484  \n","Epoch: [1][620/1292] Elapsed 3m 44s (remain 4m 2s) Loss: 0.2681(0.5583) Grad: 123785.5469  LR: 0.00000482  \n","Epoch: [1][640/1292] Elapsed 3m 51s (remain 3m 55s) Loss: 0.8319(0.5556) Grad: 473783.0625  LR: 0.00000481  \n","Epoch: [1][660/1292] Elapsed 3m 58s (remain 3m 48s) Loss: 0.4614(0.5537) Grad: 123588.5625  LR: 0.00000480  \n","Epoch: [1][680/1292] Elapsed 4m 5s (remain 3m 40s) Loss: 0.4961(0.5488) Grad: 92536.3594  LR: 0.00000479  \n","Epoch: [1][700/1292] Elapsed 4m 12s (remain 3m 33s) Loss: 0.2549(0.5441) Grad: 80961.5000  LR: 0.00000478  \n","Epoch: [1][720/1292] Elapsed 4m 19s (remain 3m 25s) Loss: 0.3709(0.5410) Grad: 240234.5938  LR: 0.00000476  \n","Epoch: [1][740/1292] Elapsed 4m 27s (remain 3m 18s) Loss: 0.3267(0.5374) Grad: 112065.6016  LR: 0.00000475  \n","Epoch: [1][760/1292] Elapsed 4m 34s (remain 3m 11s) Loss: 0.3815(0.5331) Grad: 334808.4688  LR: 0.00000474  \n","Epoch: [1][780/1292] Elapsed 4m 41s (remain 3m 4s) Loss: 0.5016(0.5279) Grad: 88379.1641  LR: 0.00000472  \n","Epoch: [1][800/1292] Elapsed 4m 48s (remain 2m 57s) Loss: 0.3537(0.5249) Grad: 92633.1172  LR: 0.00000471  \n","Epoch: [1][820/1292] Elapsed 4m 56s (remain 2m 49s) Loss: 0.2108(0.5228) Grad: 94478.6406  LR: 0.00000470  \n","Epoch: [1][840/1292] Elapsed 5m 3s (remain 2m 42s) Loss: 0.3472(0.5207) Grad: 89855.3984  LR: 0.00000468  \n","Epoch: [1][860/1292] Elapsed 5m 10s (remain 2m 35s) Loss: 0.3372(0.5189) Grad: 70073.8672  LR: 0.00000467  \n","Epoch: [1][880/1292] Elapsed 5m 17s (remain 2m 28s) Loss: 0.2822(0.5162) Grad: 103483.1953  LR: 0.00000465  \n","Epoch: [1][900/1292] Elapsed 5m 24s (remain 2m 20s) Loss: 0.3065(0.5133) Grad: 250483.2344  LR: 0.00000463  \n","Epoch: [1][920/1292] Elapsed 5m 31s (remain 2m 13s) Loss: 0.7529(0.5110) Grad: 150263.7500  LR: 0.00000462  \n","Epoch: [1][940/1292] Elapsed 5m 38s (remain 2m 6s) Loss: 0.1988(0.5089) Grad: 115004.7891  LR: 0.00000460  \n","Epoch: [1][960/1292] Elapsed 5m 45s (remain 1m 59s) Loss: 0.2219(0.5072) Grad: 125298.7344  LR: 0.00000459  \n","Epoch: [1][980/1292] Elapsed 5m 52s (remain 1m 51s) Loss: 0.4113(0.5043) Grad: 182642.9062  LR: 0.00000457  \n","Epoch: [1][1000/1292] Elapsed 5m 59s (remain 1m 44s) Loss: 0.2736(0.5026) Grad: 143676.2500  LR: 0.00000455  \n","Epoch: [1][1020/1292] Elapsed 6m 6s (remain 1m 37s) Loss: 0.5628(0.5007) Grad: 142385.6875  LR: 0.00000453  \n","Epoch: [1][1040/1292] Elapsed 6m 13s (remain 1m 30s) Loss: 0.2945(0.4988) Grad: 48131.0938  LR: 0.00000452  \n","Epoch: [1][1060/1292] Elapsed 6m 21s (remain 1m 22s) Loss: 0.6945(0.4968) Grad: 193020.2969  LR: 0.00000450  \n","Epoch: [1][1080/1292] Elapsed 6m 28s (remain 1m 15s) Loss: 0.2645(0.4947) Grad: 67534.4062  LR: 0.00000448  \n","Epoch: [1][1100/1292] Elapsed 6m 35s (remain 1m 8s) Loss: 0.3710(0.4931) Grad: 285716.1875  LR: 0.00000446  \n","Epoch: [1][1120/1292] Elapsed 6m 43s (remain 1m 1s) Loss: 0.2860(0.4913) Grad: 92390.0078  LR: 0.00000444  \n","Epoch: [1][1140/1292] Elapsed 6m 50s (remain 0m 54s) Loss: 0.3997(0.4900) Grad: 114566.0938  LR: 0.00000442  \n","Epoch: [1][1160/1292] Elapsed 6m 57s (remain 0m 47s) Loss: 0.3897(0.4878) Grad: 69206.1875  LR: 0.00000440  \n","Epoch: [1][1180/1292] Elapsed 7m 5s (remain 0m 39s) Loss: 0.4379(0.4873) Grad: 103012.8984  LR: 0.00000438  \n","Epoch: [1][1200/1292] Elapsed 7m 12s (remain 0m 32s) Loss: 0.3820(0.4858) Grad: 89048.1328  LR: 0.00000436  \n","Epoch: [1][1220/1292] Elapsed 7m 19s (remain 0m 25s) Loss: 0.4420(0.4859) Grad: 124174.9688  LR: 0.00000434  \n","Epoch: [1][1240/1292] Elapsed 7m 27s (remain 0m 18s) Loss: 0.5376(0.4842) Grad: 74018.1719  LR: 0.00000432  \n","Epoch: [1][1260/1292] Elapsed 7m 34s (remain 0m 11s) Loss: 0.4025(0.4829) Grad: 138208.0938  LR: 0.00000430  \n","Epoch: [1][1280/1292] Elapsed 7m 41s (remain 0m 3s) Loss: 0.4840(0.4818) Grad: 100045.2422  LR: 0.00000428  \n","Epoch: [1][1291/1292] Elapsed 7m 45s (remain 0m 0s) Loss: 0.4353(0.4806) Grad: 106618.3125  LR: 0.00000427  \n","EVAL: [0/250] Elapsed 0m 0s (remain 4m 2s) Loss: 0.4533(0.4533) \n","EVAL: [20/250] Elapsed 0m 15s (remain 2m 50s) Loss: 0.4073(0.3975) \n","EVAL: [40/250] Elapsed 0m 30s (remain 2m 34s) Loss: 0.3828(0.4024) \n","EVAL: [60/250] Elapsed 0m 45s (remain 2m 19s) Loss: 0.4142(0.4143) \n","EVAL: [80/250] Elapsed 0m 59s (remain 2m 4s) Loss: 0.4093(0.4197) \n","EVAL: [100/250] Elapsed 1m 14s (remain 1m 49s) Loss: 0.4053(0.4184) \n","EVAL: [120/250] Elapsed 1m 29s (remain 1m 34s) Loss: 0.4758(0.4099) \n","EVAL: [140/250] Elapsed 1m 43s (remain 1m 20s) Loss: 0.4756(0.4091) \n","EVAL: [160/250] Elapsed 1m 58s (remain 1m 5s) Loss: 0.3395(0.4067) \n","EVAL: [180/250] Elapsed 2m 13s (remain 0m 50s) Loss: 0.2943(0.4010) \n","EVAL: [200/250] Elapsed 2m 27s (remain 0m 36s) Loss: 0.4236(0.3971) \n","EVAL: [220/250] Elapsed 2m 42s (remain 0m 21s) Loss: 0.4615(0.4013) \n","EVAL: [240/250] Elapsed 2m 57s (remain 0m 6s) Loss: 0.4126(0.3999) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.4806  avg_val_loss: 0.3996  time: 650s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4806  avg_val_loss: 0.3996  time: 650s\n","Epoch 1 - Score: 0.5002  Scores: [0.4389835248834194, 0.5613366926829896]\n","INFO:__main__:Epoch 1 - Score: 0.5002  Scores: [0.4389835248834194, 0.5613366926829896]\n","Epoch 1 - Save Best Score: 0.5002 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5002 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [249/250] Elapsed 3m 3s (remain 0m 0s) Loss: 0.4872(0.3996) \n","Epoch: [2][0/1292] Elapsed 0m 0s (remain 11m 26s) Loss: 0.2848(0.2848) Grad: inf  LR: 0.00000427  \n","Epoch: [2][20/1292] Elapsed 0m 7s (remain 7m 43s) Loss: 0.4052(0.3811) Grad: 538999.3125  LR: 0.00000425  \n","Epoch: [2][40/1292] Elapsed 0m 15s (remain 7m 40s) Loss: 0.2990(0.3766) Grad: 385781.5000  LR: 0.00000422  \n","Epoch: [2][60/1292] Elapsed 0m 22s (remain 7m 34s) Loss: 0.3043(0.3611) Grad: 732251.7500  LR: 0.00000420  \n","Epoch: [2][80/1292] Elapsed 0m 29s (remain 7m 25s) Loss: 0.3198(0.3547) Grad: 813795.0625  LR: 0.00000418  \n","Epoch: [2][100/1292] Elapsed 0m 36s (remain 7m 15s) Loss: 0.2493(0.3517) Grad: 433702.3750  LR: 0.00000416  \n","Epoch: [2][120/1292] Elapsed 0m 43s (remain 7m 4s) Loss: 0.2955(0.3478) Grad: 559360.2500  LR: 0.00000413  \n","Epoch: [2][140/1292] Elapsed 0m 51s (remain 6m 58s) Loss: 0.5200(0.3454) Grad: inf  LR: 0.00000411  \n","Epoch: [2][160/1292] Elapsed 0m 58s (remain 6m 51s) Loss: 0.4143(0.3473) Grad: 400169.0000  LR: 0.00000409  \n","Epoch: [2][180/1292] Elapsed 1m 5s (remain 6m 43s) Loss: 0.3907(0.3475) Grad: 226462.7656  LR: 0.00000406  \n","Epoch: [2][200/1292] Elapsed 1m 13s (remain 6m 36s) Loss: 0.2213(0.3516) Grad: 426621.8750  LR: 0.00000404  \n","Epoch: [2][220/1292] Elapsed 1m 20s (remain 6m 28s) Loss: 0.5628(0.3516) Grad: 349687.4375  LR: 0.00000402  \n","Epoch: [2][240/1292] Elapsed 1m 27s (remain 6m 21s) Loss: 0.4272(0.3484) Grad: 455963.8125  LR: 0.00000399  \n","Epoch: [2][260/1292] Elapsed 1m 34s (remain 6m 14s) Loss: 0.2841(0.3489) Grad: 399075.6250  LR: 0.00000397  \n","Epoch: [2][280/1292] Elapsed 1m 41s (remain 6m 6s) Loss: 0.4757(0.3435) Grad: 516119.9375  LR: 0.00000394  \n","Epoch: [2][300/1292] Elapsed 1m 49s (remain 5m 59s) Loss: 0.3056(0.3424) Grad: 426010.0000  LR: 0.00000392  \n","Epoch: [2][320/1292] Elapsed 1m 56s (remain 5m 52s) Loss: 0.4071(0.3419) Grad: 215713.9219  LR: 0.00000389  \n","Epoch: [2][340/1292] Elapsed 2m 3s (remain 5m 45s) Loss: 0.2201(0.3384) Grad: 319770.5625  LR: 0.00000387  \n","Epoch: [2][360/1292] Elapsed 2m 11s (remain 5m 38s) Loss: 0.4568(0.3370) Grad: 672877.3125  LR: 0.00000384  \n","Epoch: [2][380/1292] Elapsed 2m 18s (remain 5m 31s) Loss: 0.2880(0.3362) Grad: 274315.9062  LR: 0.00000382  \n","Epoch: [2][400/1292] Elapsed 2m 25s (remain 5m 23s) Loss: 0.2273(0.3355) Grad: 188003.9062  LR: 0.00000379  \n","Epoch: [2][420/1292] Elapsed 2m 32s (remain 5m 15s) Loss: 0.3862(0.3330) Grad: 230056.5156  LR: 0.00000376  \n","Epoch: [2][440/1292] Elapsed 2m 39s (remain 5m 7s) Loss: 0.6140(0.3348) Grad: 401885.1875  LR: 0.00000374  \n","Epoch: [2][460/1292] Elapsed 2m 46s (remain 5m 0s) Loss: 0.5814(0.3365) Grad: 209478.5625  LR: 0.00000371  \n","Epoch: [2][480/1292] Elapsed 2m 54s (remain 4m 53s) Loss: 0.3131(0.3367) Grad: 282217.6875  LR: 0.00000368  \n","Epoch: [2][500/1292] Elapsed 3m 1s (remain 4m 46s) Loss: 0.1696(0.3371) Grad: 447578.2188  LR: 0.00000366  \n","Epoch: [2][520/1292] Elapsed 3m 8s (remain 4m 38s) Loss: 0.3163(0.3349) Grad: 291242.4062  LR: 0.00000363  \n","Epoch: [2][540/1292] Elapsed 3m 15s (remain 4m 31s) Loss: 0.3001(0.3328) Grad: 291283.0625  LR: 0.00000360  \n","Epoch: [2][560/1292] Elapsed 3m 22s (remain 4m 24s) Loss: 0.3354(0.3317) Grad: 625468.0000  LR: 0.00000358  \n","Epoch: [2][580/1292] Elapsed 3m 30s (remain 4m 17s) Loss: 0.3045(0.3328) Grad: 128570.9844  LR: 0.00000355  \n","Epoch: [2][600/1292] Elapsed 3m 37s (remain 4m 9s) Loss: 0.3628(0.3315) Grad: 144931.8125  LR: 0.00000352  \n","Epoch: [2][620/1292] Elapsed 3m 44s (remain 4m 2s) Loss: 0.1865(0.3305) Grad: 535750.1250  LR: 0.00000349  \n","Epoch: [2][640/1292] Elapsed 3m 51s (remain 3m 55s) Loss: 0.3568(0.3311) Grad: 332352.4062  LR: 0.00000346  \n","Epoch: [2][660/1292] Elapsed 3m 58s (remain 3m 47s) Loss: 0.3678(0.3316) Grad: 246874.7031  LR: 0.00000344  \n","Epoch: [2][680/1292] Elapsed 4m 6s (remain 3m 40s) Loss: 0.1949(0.3314) Grad: 264369.5938  LR: 0.00000341  \n","Epoch: [2][700/1292] Elapsed 4m 13s (remain 3m 33s) Loss: 0.5073(0.3310) Grad: 411370.6250  LR: 0.00000338  \n","Epoch: [2][720/1292] Elapsed 4m 20s (remain 3m 26s) Loss: 0.1828(0.3313) Grad: 251673.5781  LR: 0.00000335  \n","Epoch: [2][740/1292] Elapsed 4m 27s (remain 3m 18s) Loss: 0.4136(0.3324) Grad: 379713.4062  LR: 0.00000332  \n","Epoch: [2][760/1292] Elapsed 4m 34s (remain 3m 11s) Loss: 0.3290(0.3318) Grad: 276239.5938  LR: 0.00000329  \n","Epoch: [2][780/1292] Elapsed 4m 42s (remain 3m 4s) Loss: 0.2543(0.3312) Grad: 420817.1875  LR: 0.00000326  \n","Epoch: [2][800/1292] Elapsed 4m 49s (remain 2m 57s) Loss: 0.3188(0.3307) Grad: 346190.7500  LR: 0.00000324  \n","Epoch: [2][820/1292] Elapsed 4m 56s (remain 2m 50s) Loss: 0.2591(0.3303) Grad: 459827.3438  LR: 0.00000321  \n","Epoch: [2][840/1292] Elapsed 5m 3s (remain 2m 42s) Loss: 0.1829(0.3308) Grad: 362668.1250  LR: 0.00000318  \n","Epoch: [2][860/1292] Elapsed 5m 10s (remain 2m 35s) Loss: 0.4130(0.3308) Grad: 330799.3125  LR: 0.00000315  \n","Epoch: [2][880/1292] Elapsed 5m 18s (remain 2m 28s) Loss: 0.1810(0.3310) Grad: 306696.7500  LR: 0.00000312  \n","Epoch: [2][900/1292] Elapsed 5m 25s (remain 2m 21s) Loss: 0.2333(0.3301) Grad: 106669.5781  LR: 0.00000309  \n","Epoch: [2][920/1292] Elapsed 5m 32s (remain 2m 13s) Loss: 0.4796(0.3298) Grad: 320370.4062  LR: 0.00000306  \n","Epoch: [2][940/1292] Elapsed 5m 39s (remain 2m 6s) Loss: 0.4878(0.3297) Grad: 489956.6250  LR: 0.00000303  \n","Epoch: [2][960/1292] Elapsed 5m 46s (remain 1m 59s) Loss: 0.2381(0.3300) Grad: 392057.7812  LR: 0.00000300  \n","Epoch: [2][980/1292] Elapsed 5m 54s (remain 1m 52s) Loss: 0.5050(0.3306) Grad: 244221.3125  LR: 0.00000297  \n","Epoch: [2][1000/1292] Elapsed 6m 0s (remain 1m 44s) Loss: 0.5014(0.3305) Grad: 530026.7500  LR: 0.00000294  \n","Epoch: [2][1020/1292] Elapsed 6m 8s (remain 1m 37s) Loss: 0.4063(0.3297) Grad: 281126.0312  LR: 0.00000291  \n","Epoch: [2][1040/1292] Elapsed 6m 15s (remain 1m 30s) Loss: 0.3509(0.3306) Grad: 357603.9062  LR: 0.00000288  \n","Epoch: [2][1060/1292] Elapsed 6m 22s (remain 1m 23s) Loss: 0.2131(0.3302) Grad: 134257.4844  LR: 0.00000285  \n","Epoch: [2][1080/1292] Elapsed 6m 29s (remain 1m 16s) Loss: 0.4018(0.3303) Grad: 225446.8438  LR: 0.00000282  \n","Epoch: [2][1100/1292] Elapsed 6m 36s (remain 1m 8s) Loss: 0.4691(0.3303) Grad: 243769.8438  LR: 0.00000279  \n","Epoch: [2][1120/1292] Elapsed 6m 43s (remain 1m 1s) Loss: 0.2395(0.3301) Grad: 361793.0625  LR: 0.00000276  \n","Epoch: [2][1140/1292] Elapsed 6m 51s (remain 0m 54s) Loss: 0.2614(0.3300) Grad: 308578.1875  LR: 0.00000273  \n","Epoch: [2][1160/1292] Elapsed 6m 58s (remain 0m 47s) Loss: 0.2185(0.3301) Grad: 228756.3281  LR: 0.00000270  \n","Epoch: [2][1180/1292] Elapsed 7m 5s (remain 0m 39s) Loss: 0.2990(0.3302) Grad: 387710.3125  LR: 0.00000267  \n","Epoch: [2][1200/1292] Elapsed 7m 12s (remain 0m 32s) Loss: 0.2871(0.3301) Grad: 326741.3125  LR: 0.00000264  \n","Epoch: [2][1220/1292] Elapsed 7m 19s (remain 0m 25s) Loss: 0.1773(0.3300) Grad: 221578.6094  LR: 0.00000261  \n","Epoch: [2][1240/1292] Elapsed 7m 27s (remain 0m 18s) Loss: 0.4211(0.3303) Grad: 420975.2812  LR: 0.00000258  \n","Epoch: [2][1260/1292] Elapsed 7m 34s (remain 0m 11s) Loss: 0.4799(0.3306) Grad: 453001.5938  LR: 0.00000255  \n","Epoch: [2][1280/1292] Elapsed 7m 41s (remain 0m 3s) Loss: 0.1847(0.3310) Grad: 285315.8750  LR: 0.00000252  \n","Epoch: [2][1291/1292] Elapsed 7m 45s (remain 0m 0s) Loss: 0.2283(0.3312) Grad: 258627.6719  LR: 0.00000250  \n","EVAL: [0/250] Elapsed 0m 0s (remain 4m 3s) Loss: 0.3730(0.3730) \n","EVAL: [20/250] Elapsed 0m 15s (remain 2m 50s) Loss: 0.3512(0.3321) \n","EVAL: [40/250] Elapsed 0m 30s (remain 2m 34s) Loss: 0.3055(0.3403) \n","EVAL: [60/250] Elapsed 0m 45s (remain 2m 19s) Loss: 0.2212(0.3514) \n","EVAL: [80/250] Elapsed 0m 59s (remain 2m 4s) Loss: 0.3818(0.3531) \n","EVAL: [100/250] Elapsed 1m 14s (remain 1m 49s) Loss: 0.2816(0.3515) \n","EVAL: [120/250] Elapsed 1m 29s (remain 1m 35s) Loss: 0.3392(0.3464) \n","EVAL: [140/250] Elapsed 1m 43s (remain 1m 20s) Loss: 0.3412(0.3499) \n","EVAL: [160/250] Elapsed 1m 58s (remain 1m 5s) Loss: 0.2545(0.3491) \n","EVAL: [180/250] Elapsed 2m 13s (remain 0m 50s) Loss: 0.3134(0.3436) \n","EVAL: [200/250] Elapsed 2m 27s (remain 0m 36s) Loss: 0.2880(0.3379) \n","EVAL: [220/250] Elapsed 2m 42s (remain 0m 21s) Loss: 0.3599(0.3423) \n","EVAL: [240/250] Elapsed 2m 57s (remain 0m 6s) Loss: 0.3341(0.3419) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3312  avg_val_loss: 0.3415  time: 650s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3312  avg_val_loss: 0.3415  time: 650s\n","Epoch 2 - Score: 0.4441  Scores: [0.40082272650325246, 0.487430838850914]\n","INFO:__main__:Epoch 2 - Score: 0.4441  Scores: [0.40082272650325246, 0.487430838850914]\n","Epoch 2 - Save Best Score: 0.4441 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.4441 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [249/250] Elapsed 3m 3s (remain 0m 0s) Loss: 0.4223(0.3415) \n","Epoch: [3][0/1292] Elapsed 0m 0s (remain 13m 32s) Loss: 0.2184(0.2184) Grad: inf  LR: 0.00000250  \n","Epoch: [3][20/1292] Elapsed 0m 7s (remain 7m 47s) Loss: 0.3060(0.2515) Grad: 761353.0625  LR: 0.00000247  \n","Epoch: [3][40/1292] Elapsed 0m 15s (remain 7m 51s) Loss: 0.2965(0.2878) Grad: 852475.7500  LR: 0.00000244  \n","Epoch: [3][60/1292] Elapsed 0m 22s (remain 7m 32s) Loss: 0.4065(0.2956) Grad: 383121.5312  LR: 0.00000241  \n","Epoch: [3][80/1292] Elapsed 0m 29s (remain 7m 18s) Loss: 0.2792(0.2959) Grad: 242881.2500  LR: 0.00000238  \n","Epoch: [3][100/1292] Elapsed 0m 36s (remain 7m 12s) Loss: 0.3050(0.2992) Grad: 364845.8438  LR: 0.00000235  \n","Epoch: [3][120/1292] Elapsed 0m 43s (remain 7m 4s) Loss: 0.4634(0.3012) Grad: 503092.6250  LR: 0.00000232  \n","Epoch: [3][140/1292] Elapsed 0m 50s (remain 6m 55s) Loss: 0.3593(0.3090) Grad: 257657.5938  LR: 0.00000229  \n","Epoch: [3][160/1292] Elapsed 0m 58s (remain 6m 48s) Loss: 0.3660(0.3110) Grad: 268796.3438  LR: 0.00000226  \n","Epoch: [3][180/1292] Elapsed 1m 5s (remain 6m 40s) Loss: 0.3654(0.3137) Grad: 304500.7188  LR: 0.00000223  \n","Epoch: [3][200/1292] Elapsed 1m 12s (remain 6m 33s) Loss: 0.3935(0.3129) Grad: 379081.7500  LR: 0.00000220  \n","Epoch: [3][220/1292] Elapsed 1m 19s (remain 6m 27s) Loss: 0.4540(0.3177) Grad: 376060.3750  LR: 0.00000217  \n","Epoch: [3][240/1292] Elapsed 1m 27s (remain 6m 20s) Loss: 0.2342(0.3159) Grad: 341662.5312  LR: 0.00000214  \n","Epoch: [3][260/1292] Elapsed 1m 34s (remain 6m 12s) Loss: 0.1030(0.3118) Grad: 268620.0625  LR: 0.00000211  \n","Epoch: [3][280/1292] Elapsed 1m 41s (remain 6m 5s) Loss: 0.1872(0.3091) Grad: 282254.8750  LR: 0.00000208  \n","Epoch: [3][300/1292] Elapsed 1m 48s (remain 5m 56s) Loss: 0.3801(0.3103) Grad: 367214.2812  LR: 0.00000205  \n","Epoch: [3][320/1292] Elapsed 1m 55s (remain 5m 49s) Loss: 0.4103(0.3109) Grad: 431467.2188  LR: 0.00000202  \n","Epoch: [3][340/1292] Elapsed 2m 2s (remain 5m 41s) Loss: 0.3320(0.3109) Grad: 406310.1562  LR: 0.00000199  \n","Epoch: [3][360/1292] Elapsed 2m 9s (remain 5m 34s) Loss: 0.1843(0.3094) Grad: 311973.1250  LR: 0.00000196  \n","Epoch: [3][380/1292] Elapsed 2m 17s (remain 5m 28s) Loss: 0.3146(0.3091) Grad: 501022.6562  LR: 0.00000193  \n","Epoch: [3][400/1292] Elapsed 2m 24s (remain 5m 20s) Loss: 0.5419(0.3092) Grad: 422537.1562  LR: 0.00000190  \n","Epoch: [3][420/1292] Elapsed 2m 31s (remain 5m 13s) Loss: 0.3831(0.3087) Grad: 236411.4531  LR: 0.00000187  \n","Epoch: [3][440/1292] Elapsed 2m 38s (remain 5m 6s) Loss: 0.2882(0.3083) Grad: 397042.3125  LR: 0.00000184  \n","Epoch: [3][460/1292] Elapsed 2m 45s (remain 4m 59s) Loss: 0.1852(0.3077) Grad: 458855.3125  LR: 0.00000181  \n","Epoch: [3][480/1292] Elapsed 2m 52s (remain 4m 51s) Loss: 0.2044(0.3076) Grad: 378166.9062  LR: 0.00000178  \n","Epoch: [3][500/1292] Elapsed 3m 0s (remain 4m 45s) Loss: 0.0890(0.3076) Grad: 232195.5156  LR: 0.00000175  \n","Epoch: [3][520/1292] Elapsed 3m 8s (remain 4m 38s) Loss: 0.4064(0.3081) Grad: 287275.2188  LR: 0.00000172  \n","Epoch: [3][540/1292] Elapsed 3m 15s (remain 4m 31s) Loss: 0.4865(0.3083) Grad: 389817.3438  LR: 0.00000169  \n","Epoch: [3][560/1292] Elapsed 3m 22s (remain 4m 24s) Loss: 0.2939(0.3078) Grad: 329746.4062  LR: 0.00000166  \n","Epoch: [3][580/1292] Elapsed 3m 30s (remain 4m 17s) Loss: 0.5330(0.3083) Grad: 308347.2188  LR: 0.00000164  \n","Epoch: [3][600/1292] Elapsed 3m 37s (remain 4m 9s) Loss: 0.4040(0.3073) Grad: 248446.5000  LR: 0.00000161  \n","Epoch: [3][620/1292] Elapsed 3m 44s (remain 4m 2s) Loss: 0.1667(0.3062) Grad: 360357.1562  LR: 0.00000158  \n","Epoch: [3][640/1292] Elapsed 3m 51s (remain 3m 55s) Loss: 0.2516(0.3059) Grad: 405608.4375  LR: 0.00000155  \n","Epoch: [3][660/1292] Elapsed 3m 58s (remain 3m 47s) Loss: 0.3755(0.3061) Grad: 740935.1250  LR: 0.00000152  \n","Epoch: [3][680/1292] Elapsed 4m 6s (remain 3m 40s) Loss: 0.2063(0.3063) Grad: 328743.5312  LR: 0.00000150  \n","Epoch: [3][700/1292] Elapsed 4m 13s (remain 3m 33s) Loss: 0.2647(0.3077) Grad: 153088.6094  LR: 0.00000147  \n","Epoch: [3][720/1292] Elapsed 4m 20s (remain 3m 26s) Loss: 0.4012(0.3079) Grad: 349286.0000  LR: 0.00000144  \n","Epoch: [3][740/1292] Elapsed 4m 28s (remain 3m 19s) Loss: 0.1715(0.3078) Grad: 239718.9688  LR: 0.00000141  \n","Epoch: [3][760/1292] Elapsed 4m 35s (remain 3m 12s) Loss: 0.4035(0.3074) Grad: 325671.9062  LR: 0.00000139  \n","Epoch: [3][780/1292] Elapsed 4m 42s (remain 3m 5s) Loss: 0.4505(0.3075) Grad: 264074.6250  LR: 0.00000136  \n","Epoch: [3][800/1292] Elapsed 4m 49s (remain 2m 57s) Loss: 0.2705(0.3064) Grad: 293094.3750  LR: 0.00000133  \n","Epoch: [3][820/1292] Elapsed 4m 57s (remain 2m 50s) Loss: 0.3112(0.3067) Grad: 320720.6250  LR: 0.00000130  \n","Epoch: [3][840/1292] Elapsed 5m 4s (remain 2m 43s) Loss: 0.1761(0.3068) Grad: 351120.9375  LR: 0.00000128  \n","Epoch: [3][860/1292] Elapsed 5m 11s (remain 2m 35s) Loss: 0.2539(0.3069) Grad: 273688.8438  LR: 0.00000125  \n","Epoch: [3][880/1292] Elapsed 5m 18s (remain 2m 28s) Loss: 0.4611(0.3068) Grad: 184183.9062  LR: 0.00000123  \n","Epoch: [3][900/1292] Elapsed 5m 25s (remain 2m 21s) Loss: 0.4353(0.3062) Grad: 650505.1875  LR: 0.00000120  \n","Epoch: [3][920/1292] Elapsed 5m 33s (remain 2m 14s) Loss: 0.5466(0.3063) Grad: 312350.0000  LR: 0.00000117  \n","Epoch: [3][940/1292] Elapsed 5m 39s (remain 2m 6s) Loss: 0.0884(0.3046) Grad: 639755.5625  LR: 0.00000115  \n","Epoch: [3][960/1292] Elapsed 5m 47s (remain 1m 59s) Loss: 0.3616(0.3044) Grad: 375189.1875  LR: 0.00000112  \n","Epoch: [3][980/1292] Elapsed 5m 54s (remain 1m 52s) Loss: 0.3615(0.3047) Grad: 617205.1875  LR: 0.00000110  \n","Epoch: [3][1000/1292] Elapsed 6m 2s (remain 1m 45s) Loss: 0.1689(0.3042) Grad: 417686.7812  LR: 0.00000107  \n","Epoch: [3][1020/1292] Elapsed 6m 9s (remain 1m 38s) Loss: 0.3596(0.3040) Grad: 213573.4531  LR: 0.00000105  \n","Epoch: [3][1040/1292] Elapsed 6m 16s (remain 1m 30s) Loss: 0.4831(0.3043) Grad: 361587.6250  LR: 0.00000102  \n","Epoch: [3][1060/1292] Elapsed 6m 23s (remain 1m 23s) Loss: 0.3891(0.3038) Grad: 363065.3125  LR: 0.00000100  \n","Epoch: [3][1080/1292] Elapsed 6m 31s (remain 1m 16s) Loss: 0.2176(0.3039) Grad: 273994.4062  LR: 0.00000097  \n","Epoch: [3][1100/1292] Elapsed 6m 38s (remain 1m 9s) Loss: 0.2047(0.3031) Grad: 248838.4375  LR: 0.00000095  \n","Epoch: [3][1120/1292] Elapsed 6m 45s (remain 1m 1s) Loss: 0.4176(0.3029) Grad: 298559.3438  LR: 0.00000093  \n","Epoch: [3][1140/1292] Elapsed 6m 52s (remain 0m 54s) Loss: 0.1053(0.3027) Grad: 348021.0312  LR: 0.00000090  \n","Epoch: [3][1160/1292] Elapsed 7m 0s (remain 0m 47s) Loss: 0.3136(0.3021) Grad: 345381.3125  LR: 0.00000088  \n","Epoch: [3][1180/1292] Elapsed 7m 6s (remain 0m 40s) Loss: 0.1827(0.3017) Grad: 479123.1875  LR: 0.00000086  \n","Epoch: [3][1200/1292] Elapsed 7m 13s (remain 0m 32s) Loss: 0.1575(0.3015) Grad: 337611.6875  LR: 0.00000083  \n","Epoch: [3][1220/1292] Elapsed 7m 21s (remain 0m 25s) Loss: 0.3944(0.3022) Grad: 253378.8125  LR: 0.00000081  \n","Epoch: [3][1240/1292] Elapsed 7m 28s (remain 0m 18s) Loss: 0.2037(0.3017) Grad: 278690.9688  LR: 0.00000079  \n","Epoch: [3][1260/1292] Elapsed 7m 35s (remain 0m 11s) Loss: 0.3842(0.3020) Grad: 360174.2500  LR: 0.00000077  \n","Epoch: [3][1280/1292] Elapsed 7m 42s (remain 0m 3s) Loss: 0.3497(0.3016) Grad: 374774.1250  LR: 0.00000074  \n","Epoch: [3][1291/1292] Elapsed 7m 46s (remain 0m 0s) Loss: 0.3841(0.3018) Grad: 221095.2812  LR: 0.00000073  \n","EVAL: [0/250] Elapsed 0m 0s (remain 4m 4s) Loss: 0.3790(0.3790) \n","EVAL: [20/250] Elapsed 0m 15s (remain 2m 51s) Loss: 0.3389(0.3412) \n","EVAL: [40/250] Elapsed 0m 30s (remain 2m 34s) Loss: 0.3005(0.3458) \n","EVAL: [60/250] Elapsed 0m 45s (remain 2m 19s) Loss: 0.2516(0.3556) \n","EVAL: [80/250] Elapsed 0m 59s (remain 2m 4s) Loss: 0.3720(0.3550) \n","EVAL: [100/250] Elapsed 1m 14s (remain 1m 49s) Loss: 0.2879(0.3539) \n","EVAL: [120/250] Elapsed 1m 29s (remain 1m 35s) Loss: 0.3348(0.3481) \n","EVAL: [140/250] Elapsed 1m 43s (remain 1m 20s) Loss: 0.3910(0.3512) \n","EVAL: [160/250] Elapsed 1m 58s (remain 1m 5s) Loss: 0.2621(0.3495) \n","EVAL: [180/250] Elapsed 2m 13s (remain 0m 50s) Loss: 0.2403(0.3433) \n","EVAL: [200/250] Elapsed 2m 28s (remain 0m 36s) Loss: 0.2946(0.3379) \n","EVAL: [220/250] Elapsed 2m 42s (remain 0m 21s) Loss: 0.3281(0.3438) \n","EVAL: [240/250] Elapsed 2m 57s (remain 0m 6s) Loss: 0.3403(0.3426) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3018  avg_val_loss: 0.3427  time: 650s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3018  avg_val_loss: 0.3427  time: 650s\n","Epoch 3 - Score: 0.4430  Scores: [0.39420794966145534, 0.4918089882330459]\n","INFO:__main__:Epoch 3 - Score: 0.4430  Scores: [0.39420794966145534, 0.4918089882330459]\n","Epoch 3 - Save Best Score: 0.4430 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.4430 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [249/250] Elapsed 3m 3s (remain 0m 0s) Loss: 0.4407(0.3427) \n","Epoch: [4][0/1292] Elapsed 0m 0s (remain 13m 27s) Loss: 0.2759(0.2759) Grad: inf  LR: 0.00000073  \n","Epoch: [4][20/1292] Elapsed 0m 7s (remain 7m 55s) Loss: 0.1952(0.2357) Grad: 231553.3438  LR: 0.00000071  \n","Epoch: [4][40/1292] Elapsed 0m 14s (remain 7m 28s) Loss: 0.2322(0.2546) Grad: 471317.9375  LR: 0.00000069  \n","Epoch: [4][60/1292] Elapsed 0m 21s (remain 7m 15s) Loss: 0.3739(0.2542) Grad: 402525.7812  LR: 0.00000067  \n","Epoch: [4][80/1292] Elapsed 0m 28s (remain 7m 9s) Loss: 0.1285(0.2579) Grad: 358868.0000  LR: 0.00000065  \n","Epoch: [4][100/1292] Elapsed 0m 35s (remain 7m 3s) Loss: 0.4731(0.2740) Grad: 562502.0000  LR: 0.00000063  \n","Epoch: [4][120/1292] Elapsed 0m 43s (remain 7m 0s) Loss: 0.1825(0.2690) Grad: 583410.6250  LR: 0.00000061  \n","Epoch: [4][140/1292] Elapsed 0m 50s (remain 6m 51s) Loss: 0.3811(0.2696) Grad: 478652.0625  LR: 0.00000059  \n","Epoch: [4][160/1292] Elapsed 0m 57s (remain 6m 42s) Loss: 0.1696(0.2704) Grad: 280592.5625  LR: 0.00000057  \n","Epoch: [4][180/1292] Elapsed 1m 4s (remain 6m 35s) Loss: 0.2669(0.2754) Grad: 341360.0312  LR: 0.00000055  \n","Epoch: [4][200/1292] Elapsed 1m 11s (remain 6m 29s) Loss: 0.2202(0.2778) Grad: 498542.9688  LR: 0.00000053  \n","Epoch: [4][220/1292] Elapsed 1m 18s (remain 6m 21s) Loss: 0.3332(0.2779) Grad: 659532.6875  LR: 0.00000051  \n","Epoch: [4][240/1292] Elapsed 1m 26s (remain 6m 15s) Loss: 0.2958(0.2744) Grad: 262895.5312  LR: 0.00000049  \n","Epoch: [4][260/1292] Elapsed 1m 33s (remain 6m 9s) Loss: 0.2222(0.2746) Grad: 298136.8438  LR: 0.00000048  \n","Epoch: [4][280/1292] Elapsed 1m 40s (remain 6m 2s) Loss: 0.1446(0.2719) Grad: 202381.9062  LR: 0.00000046  \n","Epoch: [4][300/1292] Elapsed 1m 47s (remain 5m 55s) Loss: 0.4023(0.2723) Grad: 388163.8438  LR: 0.00000044  \n","Epoch: [4][320/1292] Elapsed 1m 54s (remain 5m 47s) Loss: 0.1489(0.2728) Grad: 592340.7500  LR: 0.00000042  \n","Epoch: [4][340/1292] Elapsed 2m 1s (remain 5m 39s) Loss: 0.2307(0.2739) Grad: 277309.4688  LR: 0.00000041  \n","Epoch: [4][360/1292] Elapsed 2m 9s (remain 5m 32s) Loss: 0.2027(0.2752) Grad: 270075.3750  LR: 0.00000039  \n","Epoch: [4][380/1292] Elapsed 2m 16s (remain 5m 26s) Loss: 0.2397(0.2749) Grad: 308102.9375  LR: 0.00000037  \n","Epoch: [4][400/1292] Elapsed 2m 23s (remain 5m 19s) Loss: 0.3359(0.2751) Grad: 731327.2500  LR: 0.00000036  \n","Epoch: [4][420/1292] Elapsed 2m 30s (remain 5m 12s) Loss: 0.1340(0.2760) Grad: 243611.6250  LR: 0.00000034  \n","Epoch: [4][440/1292] Elapsed 2m 38s (remain 5m 4s) Loss: 0.2522(0.2743) Grad: 495676.8750  LR: 0.00000033  \n","Epoch: [4][460/1292] Elapsed 2m 45s (remain 4m 57s) Loss: 0.2993(0.2743) Grad: 301984.1875  LR: 0.00000031  \n","Epoch: [4][480/1292] Elapsed 2m 52s (remain 4m 50s) Loss: 0.3092(0.2732) Grad: 432378.1875  LR: 0.00000030  \n","Epoch: [4][500/1292] Elapsed 2m 59s (remain 4m 43s) Loss: 0.2951(0.2731) Grad: 497371.2188  LR: 0.00000028  \n","Epoch: [4][520/1292] Elapsed 3m 6s (remain 4m 36s) Loss: 0.2852(0.2731) Grad: 328727.5625  LR: 0.00000027  \n","Epoch: [4][540/1292] Elapsed 3m 13s (remain 4m 28s) Loss: 0.2528(0.2735) Grad: 285339.6875  LR: 0.00000026  \n","Epoch: [4][560/1292] Elapsed 3m 20s (remain 4m 21s) Loss: 0.1233(0.2725) Grad: 232995.9688  LR: 0.00000024  \n","Epoch: [4][580/1292] Elapsed 3m 28s (remain 4m 14s) Loss: 0.4071(0.2725) Grad: 539759.2500  LR: 0.00000023  \n","Epoch: [4][600/1292] Elapsed 3m 35s (remain 4m 7s) Loss: 0.4118(0.2731) Grad: 412882.1562  LR: 0.00000022  \n","Epoch: [4][620/1292] Elapsed 3m 42s (remain 4m 0s) Loss: 0.1993(0.2726) Grad: 475334.6875  LR: 0.00000021  \n","Epoch: [4][640/1292] Elapsed 3m 49s (remain 3m 53s) Loss: 0.1710(0.2724) Grad: 271259.0625  LR: 0.00000019  \n","Epoch: [4][660/1292] Elapsed 3m 56s (remain 3m 46s) Loss: 0.2132(0.2727) Grad: 406324.0312  LR: 0.00000018  \n","Epoch: [4][680/1292] Elapsed 4m 4s (remain 3m 39s) Loss: 0.3450(0.2739) Grad: 569469.2500  LR: 0.00000017  \n","Epoch: [4][700/1292] Elapsed 4m 11s (remain 3m 31s) Loss: 0.2094(0.2742) Grad: 236664.4531  LR: 0.00000016  \n","Epoch: [4][720/1292] Elapsed 4m 18s (remain 3m 24s) Loss: 0.2076(0.2747) Grad: 325721.4062  LR: 0.00000015  \n","Epoch: [4][740/1292] Elapsed 4m 25s (remain 3m 17s) Loss: 0.4028(0.2752) Grad: 396669.8438  LR: 0.00000014  \n","Epoch: [4][760/1292] Elapsed 4m 33s (remain 3m 10s) Loss: 0.2667(0.2758) Grad: 415682.7812  LR: 0.00000013  \n","Epoch: [4][780/1292] Elapsed 4m 40s (remain 3m 3s) Loss: 0.3323(0.2758) Grad: 438756.0312  LR: 0.00000012  \n","Epoch: [4][800/1292] Elapsed 4m 47s (remain 2m 56s) Loss: 0.3813(0.2756) Grad: 395040.9062  LR: 0.00000011  \n","Epoch: [4][820/1292] Elapsed 4m 54s (remain 2m 48s) Loss: 0.2301(0.2762) Grad: 333146.0625  LR: 0.00000010  \n","Epoch: [4][840/1292] Elapsed 5m 1s (remain 2m 41s) Loss: 0.2079(0.2758) Grad: 282516.2500  LR: 0.00000009  \n","Epoch: [4][860/1292] Elapsed 5m 9s (remain 2m 34s) Loss: 0.4179(0.2766) Grad: 329759.0938  LR: 0.00000009  \n","Epoch: [4][880/1292] Elapsed 5m 16s (remain 2m 27s) Loss: 0.1998(0.2760) Grad: 206902.5312  LR: 0.00000008  \n","Epoch: [4][900/1292] Elapsed 5m 23s (remain 2m 20s) Loss: 0.3869(0.2765) Grad: 280445.0938  LR: 0.00000007  \n","Epoch: [4][920/1292] Elapsed 5m 30s (remain 2m 13s) Loss: 0.3138(0.2762) Grad: 430076.0000  LR: 0.00000006  \n","Epoch: [4][940/1292] Elapsed 5m 37s (remain 2m 6s) Loss: 0.2402(0.2767) Grad: 450122.8125  LR: 0.00000006  \n","Epoch: [4][960/1292] Elapsed 5m 45s (remain 1m 58s) Loss: 0.3485(0.2771) Grad: 516809.7500  LR: 0.00000005  \n","Epoch: [4][980/1292] Elapsed 5m 52s (remain 1m 51s) Loss: 0.2130(0.2769) Grad: 510374.4688  LR: 0.00000004  \n","Epoch: [4][1000/1292] Elapsed 5m 59s (remain 1m 44s) Loss: 0.3546(0.2763) Grad: 364005.7812  LR: 0.00000004  \n","Epoch: [4][1020/1292] Elapsed 6m 6s (remain 1m 37s) Loss: 0.3700(0.2760) Grad: 422812.7188  LR: 0.00000003  \n","Epoch: [4][1040/1292] Elapsed 6m 14s (remain 1m 30s) Loss: 0.4706(0.2763) Grad: 441630.3750  LR: 0.00000003  \n","Epoch: [4][1060/1292] Elapsed 6m 21s (remain 1m 23s) Loss: 0.1558(0.2766) Grad: 277138.3438  LR: 0.00000002  \n","Epoch: [4][1080/1292] Elapsed 6m 29s (remain 1m 15s) Loss: 0.2111(0.2768) Grad: 451591.9375  LR: 0.00000002  \n","Epoch: [4][1100/1292] Elapsed 6m 36s (remain 1m 8s) Loss: 0.1083(0.2768) Grad: 355302.4688  LR: 0.00000002  \n","Epoch: [4][1120/1292] Elapsed 6m 43s (remain 1m 1s) Loss: 0.1969(0.2769) Grad: 523602.8125  LR: 0.00000001  \n","Epoch: [4][1140/1292] Elapsed 6m 51s (remain 0m 54s) Loss: 0.1642(0.2769) Grad: 624057.8125  LR: 0.00000001  \n","Epoch: [4][1160/1292] Elapsed 6m 58s (remain 0m 47s) Loss: 0.1224(0.2769) Grad: 460252.9062  LR: 0.00000001  \n","Epoch: [4][1180/1292] Elapsed 7m 6s (remain 0m 40s) Loss: 0.2088(0.2774) Grad: 301589.3750  LR: 0.00000001  \n","Epoch: [4][1200/1292] Elapsed 7m 13s (remain 0m 32s) Loss: 0.2364(0.2772) Grad: 466176.9062  LR: 0.00000000  \n","Epoch: [4][1220/1292] Elapsed 7m 20s (remain 0m 25s) Loss: 0.2694(0.2773) Grad: 341080.5625  LR: 0.00000000  \n","Epoch: [4][1240/1292] Elapsed 7m 28s (remain 0m 18s) Loss: 0.2708(0.2774) Grad: 341111.5938  LR: 0.00000000  \n","Epoch: [4][1260/1292] Elapsed 7m 35s (remain 0m 11s) Loss: 0.1571(0.2777) Grad: 338585.2188  LR: 0.00000000  \n","Epoch: [4][1280/1292] Elapsed 7m 42s (remain 0m 3s) Loss: 0.2747(0.2777) Grad: 1153817.7500  LR: 0.00000000  \n","Epoch: [4][1291/1292] Elapsed 7m 46s (remain 0m 0s) Loss: 0.3514(0.2777) Grad: 375051.4375  LR: 0.00000000  \n","EVAL: [0/250] Elapsed 0m 0s (remain 4m 5s) Loss: 0.3733(0.3733) \n","EVAL: [20/250] Elapsed 0m 15s (remain 2m 50s) Loss: 0.3284(0.3352) \n","EVAL: [40/250] Elapsed 0m 30s (remain 2m 35s) Loss: 0.3013(0.3428) \n","EVAL: [60/250] Elapsed 0m 45s (remain 2m 19s) Loss: 0.2308(0.3528) \n","EVAL: [80/250] Elapsed 0m 59s (remain 2m 4s) Loss: 0.3562(0.3522) \n","EVAL: [100/250] Elapsed 1m 14s (remain 1m 49s) Loss: 0.2957(0.3517) \n","EVAL: [120/250] Elapsed 1m 29s (remain 1m 35s) Loss: 0.3406(0.3467) \n","EVAL: [140/250] Elapsed 1m 43s (remain 1m 20s) Loss: 0.3821(0.3500) \n","EVAL: [160/250] Elapsed 1m 58s (remain 1m 5s) Loss: 0.2598(0.3484) \n","EVAL: [180/250] Elapsed 2m 13s (remain 0m 50s) Loss: 0.2718(0.3424) \n","EVAL: [200/250] Elapsed 2m 28s (remain 0m 36s) Loss: 0.2740(0.3369) \n","EVAL: [220/250] Elapsed 2m 42s (remain 0m 21s) Loss: 0.3326(0.3429) \n","EVAL: [240/250] Elapsed 2m 57s (remain 0m 6s) Loss: 0.3363(0.3420) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2777  avg_val_loss: 0.3420  time: 651s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2777  avg_val_loss: 0.3420  time: 651s\n","Epoch 4 - Score: 0.4427  Scores: [0.399044614398343, 0.48625640610017307]\n","INFO:__main__:Epoch 4 - Score: 0.4427  Scores: [0.399044614398343, 0.48625640610017307]\n","Epoch 4 - Save Best Score: 0.4427 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.4427 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [249/250] Elapsed 3m 3s (remain 0m 0s) Loss: 0.4310(0.3420) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.4427  Scores: [0.399044614398343, 0.48625640610017307]\n","INFO:__main__:Score: 0.4427  Scores: [0.399044614398343, 0.48625640610017307]\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["========== prompt_id: ['814d6b'] validation ==========\n"]},{"output_type":"stream","name":"stderr","text":["DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 1024,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 4096,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 1024,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/1515] Elapsed 0m 0s (remain 15m 54s) Loss: 0.5770(0.5770) Grad: nan  LR: 0.00000500  \n","Epoch: [1][20/1515] Elapsed 0m 9s (remain 10m 59s) Loss: 0.7941(0.7209) Grad: 355551.6875  LR: 0.00000500  \n","Epoch: [1][40/1515] Elapsed 0m 18s (remain 10m 54s) Loss: 0.8628(0.7479) Grad: 784806.1250  LR: 0.00000500  \n","Epoch: [1][60/1515] Elapsed 0m 27s (remain 10m 47s) Loss: 1.2610(0.7374) Grad: 297604.6250  LR: 0.00000500  \n","Epoch: [1][80/1515] Elapsed 0m 36s (remain 10m 40s) Loss: 0.7148(0.7382) Grad: 3659890.2500  LR: 0.00000500  \n","Epoch: [1][100/1515] Elapsed 0m 44s (remain 10m 27s) Loss: 0.6281(0.7301) Grad: 1045654.6250  LR: 0.00000500  \n","Epoch: [1][120/1515] Elapsed 0m 53s (remain 10m 17s) Loss: 0.5832(0.7289) Grad: 974441.8125  LR: 0.00000500  \n","Epoch: [1][140/1515] Elapsed 1m 2s (remain 10m 9s) Loss: 0.7072(0.7137) Grad: 42711.2891  LR: 0.00000499  \n","Epoch: [1][160/1515] Elapsed 1m 11s (remain 10m 2s) Loss: 0.9755(0.6914) Grad: 699087.6250  LR: 0.00000499  \n","Epoch: [1][180/1515] Elapsed 1m 20s (remain 9m 54s) Loss: 0.4477(0.6777) Grad: 341183.4062  LR: 0.00000499  \n","Epoch: [1][200/1515] Elapsed 1m 29s (remain 9m 45s) Loss: 0.5582(0.6732) Grad: 326780.1875  LR: 0.00000499  \n","Epoch: [1][220/1515] Elapsed 1m 38s (remain 9m 36s) Loss: 0.4530(0.6586) Grad: 250741.6875  LR: 0.00000498  \n","Epoch: [1][240/1515] Elapsed 1m 46s (remain 9m 25s) Loss: 0.3299(0.6509) Grad: 91560.2344  LR: 0.00000498  \n","Epoch: [1][260/1515] Elapsed 1m 55s (remain 9m 17s) Loss: 0.4477(0.6406) Grad: 232445.3906  LR: 0.00000498  \n","Epoch: [1][280/1515] Elapsed 2m 4s (remain 9m 8s) Loss: 0.7295(0.6356) Grad: 221480.8125  LR: 0.00000497  \n","Epoch: [1][300/1515] Elapsed 2m 14s (remain 9m 0s) Loss: 0.4288(0.6284) Grad: 60673.4023  LR: 0.00000497  \n","Epoch: [1][320/1515] Elapsed 2m 22s (remain 8m 51s) Loss: 0.6643(0.6190) Grad: 242512.3438  LR: 0.00000497  \n","Epoch: [1][340/1515] Elapsed 2m 31s (remain 8m 42s) Loss: 0.2839(0.6102) Grad: 54666.9258  LR: 0.00000496  \n","Epoch: [1][360/1515] Elapsed 2m 40s (remain 8m 34s) Loss: 0.6055(0.6012) Grad: 155325.6094  LR: 0.00000496  \n","Epoch: [1][380/1515] Elapsed 2m 49s (remain 8m 24s) Loss: 0.3874(0.5936) Grad: 55610.7656  LR: 0.00000495  \n","Epoch: [1][400/1515] Elapsed 2m 58s (remain 8m 15s) Loss: 0.7742(0.5863) Grad: 107461.4531  LR: 0.00000495  \n","Epoch: [1][420/1515] Elapsed 3m 7s (remain 8m 6s) Loss: 0.2640(0.5812) Grad: 71705.9766  LR: 0.00000494  \n","Epoch: [1][440/1515] Elapsed 3m 16s (remain 7m 58s) Loss: 0.3301(0.5762) Grad: 65525.5273  LR: 0.00000493  \n","Epoch: [1][460/1515] Elapsed 3m 25s (remain 7m 49s) Loss: 0.5225(0.5725) Grad: 89182.8828  LR: 0.00000493  \n","Epoch: [1][480/1515] Elapsed 3m 34s (remain 7m 40s) Loss: 0.5500(0.5673) Grad: 64267.2539  LR: 0.00000492  \n","Epoch: [1][500/1515] Elapsed 3m 42s (remain 7m 30s) Loss: 0.4227(0.5625) Grad: 168452.7656  LR: 0.00000492  \n","Epoch: [1][520/1515] Elapsed 3m 51s (remain 7m 21s) Loss: 0.4769(0.5585) Grad: 76068.6484  LR: 0.00000491  \n","Epoch: [1][540/1515] Elapsed 4m 0s (remain 7m 12s) Loss: 0.4008(0.5543) Grad: 196285.3281  LR: 0.00000490  \n","Epoch: [1][560/1515] Elapsed 4m 9s (remain 7m 4s) Loss: 0.2620(0.5516) Grad: 61877.9219  LR: 0.00000490  \n","Epoch: [1][580/1515] Elapsed 4m 18s (remain 6m 55s) Loss: 0.4237(0.5495) Grad: 60316.0469  LR: 0.00000489  \n","Epoch: [1][600/1515] Elapsed 4m 27s (remain 6m 46s) Loss: 0.3933(0.5458) Grad: 34460.4297  LR: 0.00000488  \n","Epoch: [1][620/1515] Elapsed 4m 36s (remain 6m 37s) Loss: 0.3192(0.5412) Grad: 80524.8984  LR: 0.00000487  \n","Epoch: [1][640/1515] Elapsed 4m 45s (remain 6m 28s) Loss: 0.2885(0.5364) Grad: 59439.7188  LR: 0.00000486  \n","Epoch: [1][660/1515] Elapsed 4m 54s (remain 6m 20s) Loss: 0.6812(0.5319) Grad: 144073.7031  LR: 0.00000485  \n","Epoch: [1][680/1515] Elapsed 5m 3s (remain 6m 11s) Loss: 0.3365(0.5285) Grad: 150036.5312  LR: 0.00000485  \n","Epoch: [1][700/1515] Elapsed 5m 12s (remain 6m 2s) Loss: 0.8729(0.5250) Grad: 115473.3281  LR: 0.00000484  \n","Epoch: [1][720/1515] Elapsed 5m 20s (remain 5m 53s) Loss: 0.2485(0.5221) Grad: 73193.6484  LR: 0.00000483  \n","Epoch: [1][740/1515] Elapsed 5m 30s (remain 5m 44s) Loss: 0.3065(0.5194) Grad: 117554.0781  LR: 0.00000482  \n","Epoch: [1][760/1515] Elapsed 5m 38s (remain 5m 35s) Loss: 0.3342(0.5161) Grad: 61536.5977  LR: 0.00000481  \n","Epoch: [1][780/1515] Elapsed 5m 47s (remain 5m 26s) Loss: 0.1994(0.5139) Grad: 41123.5469  LR: 0.00000480  \n","Epoch: [1][800/1515] Elapsed 5m 56s (remain 5m 17s) Loss: 0.2805(0.5110) Grad: 36105.2461  LR: 0.00000479  \n","Epoch: [1][820/1515] Elapsed 6m 5s (remain 5m 8s) Loss: 0.3991(0.5086) Grad: 71428.6953  LR: 0.00000478  \n","Epoch: [1][840/1515] Elapsed 6m 14s (remain 4m 59s) Loss: 0.5538(0.5059) Grad: 52844.0352  LR: 0.00000477  \n","Epoch: [1][860/1515] Elapsed 6m 22s (remain 4m 50s) Loss: 0.3159(0.5036) Grad: 36515.2266  LR: 0.00000476  \n","Epoch: [1][880/1515] Elapsed 6m 31s (remain 4m 42s) Loss: 0.3980(0.5016) Grad: 56838.5273  LR: 0.00000474  \n","Epoch: [1][900/1515] Elapsed 6m 40s (remain 4m 33s) Loss: 0.4292(0.4988) Grad: 111275.6250  LR: 0.00000473  \n","Epoch: [1][920/1515] Elapsed 6m 49s (remain 4m 24s) Loss: 0.4048(0.4982) Grad: 66061.7656  LR: 0.00000472  \n","Epoch: [1][940/1515] Elapsed 6m 58s (remain 4m 15s) Loss: 0.2040(0.4962) Grad: 90333.6953  LR: 0.00000471  \n","Epoch: [1][960/1515] Elapsed 7m 7s (remain 4m 6s) Loss: 0.7333(0.4936) Grad: 84501.9219  LR: 0.00000470  \n","Epoch: [1][980/1515] Elapsed 7m 16s (remain 3m 57s) Loss: 0.2763(0.4927) Grad: 85951.1172  LR: 0.00000468  \n","Epoch: [1][1000/1515] Elapsed 7m 25s (remain 3m 48s) Loss: 0.4255(0.4907) Grad: 76985.4766  LR: 0.00000467  \n","Epoch: [1][1020/1515] Elapsed 7m 34s (remain 3m 39s) Loss: 0.2733(0.4880) Grad: 40877.3086  LR: 0.00000466  \n","Epoch: [1][1040/1515] Elapsed 7m 42s (remain 3m 30s) Loss: 0.3129(0.4863) Grad: 106361.2656  LR: 0.00000464  \n","Epoch: [1][1060/1515] Elapsed 7m 51s (remain 3m 21s) Loss: 0.4207(0.4851) Grad: 100076.2109  LR: 0.00000463  \n","Epoch: [1][1080/1515] Elapsed 8m 0s (remain 3m 13s) Loss: 0.4336(0.4830) Grad: 51337.8047  LR: 0.00000462  \n","Epoch: [1][1100/1515] Elapsed 8m 9s (remain 3m 4s) Loss: 0.1124(0.4806) Grad: 77470.9531  LR: 0.00000460  \n","Epoch: [1][1120/1515] Elapsed 8m 18s (remain 2m 55s) Loss: 0.9035(0.4792) Grad: 61411.2148  LR: 0.00000459  \n","Epoch: [1][1140/1515] Elapsed 8m 27s (remain 2m 46s) Loss: 0.3988(0.4777) Grad: 57368.8750  LR: 0.00000458  \n","Epoch: [1][1160/1515] Elapsed 8m 36s (remain 2m 37s) Loss: 0.4889(0.4761) Grad: 62268.8320  LR: 0.00000456  \n","Epoch: [1][1180/1515] Elapsed 8m 45s (remain 2m 28s) Loss: 0.6031(0.4758) Grad: 61108.1484  LR: 0.00000455  \n","Epoch: [1][1200/1515] Elapsed 8m 53s (remain 2m 19s) Loss: 0.4457(0.4738) Grad: 113579.7422  LR: 0.00000453  \n","Epoch: [1][1220/1515] Elapsed 9m 2s (remain 2m 10s) Loss: 0.2756(0.4727) Grad: 43429.7500  LR: 0.00000452  \n","Epoch: [1][1240/1515] Elapsed 9m 11s (remain 2m 1s) Loss: 0.2299(0.4717) Grad: 32335.3496  LR: 0.00000450  \n","Epoch: [1][1260/1515] Elapsed 9m 20s (remain 1m 52s) Loss: 0.5304(0.4710) Grad: 80829.5391  LR: 0.00000448  \n","Epoch: [1][1280/1515] Elapsed 9m 28s (remain 1m 43s) Loss: 0.2436(0.4696) Grad: 19789.2344  LR: 0.00000447  \n","Epoch: [1][1300/1515] Elapsed 9m 37s (remain 1m 34s) Loss: 0.7721(0.4682) Grad: 36562.4375  LR: 0.00000445  \n","Epoch: [1][1320/1515] Elapsed 9m 46s (remain 1m 26s) Loss: 0.6791(0.4667) Grad: 43561.6055  LR: 0.00000444  \n","Epoch: [1][1340/1515] Elapsed 9m 55s (remain 1m 17s) Loss: 0.3073(0.4660) Grad: 37393.2148  LR: 0.00000442  \n","Epoch: [1][1360/1515] Elapsed 10m 4s (remain 1m 8s) Loss: 0.3164(0.4642) Grad: 46826.4102  LR: 0.00000440  \n","Epoch: [1][1380/1515] Elapsed 10m 12s (remain 0m 59s) Loss: 0.3960(0.4634) Grad: 36600.9375  LR: 0.00000439  \n","Epoch: [1][1400/1515] Elapsed 10m 21s (remain 0m 50s) Loss: 0.4152(0.4632) Grad: 44108.9883  LR: 0.00000437  \n","Epoch: [1][1420/1515] Elapsed 10m 30s (remain 0m 41s) Loss: 0.3188(0.4618) Grad: 42957.1797  LR: 0.00000435  \n","Epoch: [1][1440/1515] Elapsed 10m 39s (remain 0m 32s) Loss: 0.3923(0.4607) Grad: 19886.9277  LR: 0.00000433  \n","Epoch: [1][1460/1515] Elapsed 10m 48s (remain 0m 23s) Loss: 0.1635(0.4603) Grad: 42967.4727  LR: 0.00000432  \n","Epoch: [1][1480/1515] Elapsed 10m 57s (remain 0m 15s) Loss: 0.3313(0.4592) Grad: 79011.8750  LR: 0.00000430  \n","Epoch: [1][1500/1515] Elapsed 11m 5s (remain 0m 6s) Loss: 0.3765(0.4584) Grad: 27420.4121  LR: 0.00000428  \n","Epoch: [1][1514/1515] Elapsed 11m 12s (remain 0m 0s) Loss: 0.3830(0.4579) Grad: 49750.4648  LR: 0.00000427  \n","EVAL: [0/138] Elapsed 0m 0s (remain 1m 58s) Loss: 0.5611(0.5611) \n","EVAL: [20/138] Elapsed 0m 12s (remain 1m 7s) Loss: 0.3371(0.4422) \n","EVAL: [40/138] Elapsed 0m 23s (remain 0m 54s) Loss: 0.4245(0.4548) \n","EVAL: [60/138] Elapsed 0m 34s (remain 0m 43s) Loss: 0.3047(0.4380) \n","EVAL: [80/138] Elapsed 0m 45s (remain 0m 32s) Loss: 0.4109(0.4348) \n","EVAL: [100/138] Elapsed 0m 57s (remain 0m 20s) Loss: 0.4272(0.4334) \n","EVAL: [120/138] Elapsed 1m 8s (remain 0m 9s) Loss: 0.3078(0.4322) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.4579  avg_val_loss: 0.4367  time: 751s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.4579  avg_val_loss: 0.4367  time: 751s\n","Epoch 1 - Score: 0.5830  Scores: [0.4821143540349593, 0.6838480480865927]\n","INFO:__main__:Epoch 1 - Score: 0.5830  Scores: [0.4821143540349593, 0.6838480480865927]\n","Epoch 1 - Save Best Score: 0.5830 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5830 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [137/138] Elapsed 1m 18s (remain 0m 0s) Loss: 0.6436(0.4367) \n","Epoch: [2][0/1515] Elapsed 0m 0s (remain 17m 19s) Loss: 0.1788(0.1788) Grad: inf  LR: 0.00000427  \n","Epoch: [2][20/1515] Elapsed 0m 9s (remain 10m 49s) Loss: 0.2960(0.3939) Grad: 165036.8750  LR: 0.00000425  \n","Epoch: [2][40/1515] Elapsed 0m 18s (remain 10m 50s) Loss: 0.2871(0.3615) Grad: 221055.9844  LR: 0.00000423  \n","Epoch: [2][60/1515] Elapsed 0m 27s (remain 10m 52s) Loss: 0.3520(0.3655) Grad: 190240.4531  LR: 0.00000421  \n","Epoch: [2][80/1515] Elapsed 0m 36s (remain 10m 41s) Loss: 0.3831(0.3612) Grad: 247159.4688  LR: 0.00000419  \n","Epoch: [2][100/1515] Elapsed 0m 45s (remain 10m 32s) Loss: 0.3311(0.3464) Grad: 320395.9688  LR: 0.00000417  \n","Epoch: [2][120/1515] Elapsed 0m 53s (remain 10m 20s) Loss: 0.3808(0.3451) Grad: 249372.0156  LR: 0.00000415  \n","Epoch: [2][140/1515] Elapsed 1m 2s (remain 10m 12s) Loss: 0.2587(0.3424) Grad: 96885.3047  LR: 0.00000413  \n","Epoch: [2][160/1515] Elapsed 1m 11s (remain 10m 2s) Loss: 0.2502(0.3435) Grad: 89206.6562  LR: 0.00000411  \n","Epoch: [2][180/1515] Elapsed 1m 20s (remain 9m 50s) Loss: 0.3889(0.3418) Grad: 135030.9219  LR: 0.00000409  \n","Epoch: [2][200/1515] Elapsed 1m 28s (remain 9m 39s) Loss: 0.2197(0.3384) Grad: 117855.8438  LR: 0.00000407  \n","Epoch: [2][220/1515] Elapsed 1m 37s (remain 9m 32s) Loss: 0.2330(0.3387) Grad: 158160.5000  LR: 0.00000405  \n","Epoch: [2][240/1515] Elapsed 1m 46s (remain 9m 22s) Loss: 0.1607(0.3368) Grad: 110865.1562  LR: 0.00000403  \n","Epoch: [2][260/1515] Elapsed 1m 55s (remain 9m 14s) Loss: 0.2692(0.3362) Grad: 255378.2812  LR: 0.00000401  \n","Epoch: [2][280/1515] Elapsed 2m 4s (remain 9m 6s) Loss: 0.1100(0.3336) Grad: 265728.7500  LR: 0.00000399  \n","Epoch: [2][300/1515] Elapsed 2m 13s (remain 8m 57s) Loss: 0.3065(0.3321) Grad: 212570.7188  LR: 0.00000397  \n","Epoch: [2][320/1515] Elapsed 2m 22s (remain 8m 48s) Loss: 0.3770(0.3313) Grad: 166210.1406  LR: 0.00000395  \n","Epoch: [2][340/1515] Elapsed 2m 31s (remain 8m 40s) Loss: 0.4294(0.3300) Grad: 172955.6250  LR: 0.00000393  \n","Epoch: [2][360/1515] Elapsed 2m 40s (remain 8m 31s) Loss: 0.2185(0.3286) Grad: 184782.1719  LR: 0.00000391  \n","Epoch: [2][380/1515] Elapsed 2m 49s (remain 8m 23s) Loss: 0.1694(0.3259) Grad: 203362.1562  LR: 0.00000389  \n","Epoch: [2][400/1515] Elapsed 2m 57s (remain 8m 14s) Loss: 0.2613(0.3270) Grad: 188529.5781  LR: 0.00000387  \n","Epoch: [2][420/1515] Elapsed 3m 6s (remain 8m 5s) Loss: 0.2117(0.3262) Grad: 212814.0469  LR: 0.00000384  \n","Epoch: [2][440/1515] Elapsed 3m 15s (remain 7m 56s) Loss: 0.5148(0.3254) Grad: 282094.0938  LR: 0.00000382  \n","Epoch: [2][460/1515] Elapsed 3m 24s (remain 7m 47s) Loss: 0.4747(0.3260) Grad: 145349.4062  LR: 0.00000380  \n","Epoch: [2][480/1515] Elapsed 3m 33s (remain 7m 38s) Loss: 0.3698(0.3253) Grad: 125964.2031  LR: 0.00000378  \n","Epoch: [2][500/1515] Elapsed 3m 42s (remain 7m 30s) Loss: 0.4052(0.3263) Grad: 205213.4844  LR: 0.00000376  \n","Epoch: [2][520/1515] Elapsed 3m 51s (remain 7m 21s) Loss: 0.6602(0.3248) Grad: 274901.4375  LR: 0.00000373  \n","Epoch: [2][540/1515] Elapsed 4m 0s (remain 7m 12s) Loss: 0.1830(0.3247) Grad: 277348.2500  LR: 0.00000371  \n","Epoch: [2][560/1515] Elapsed 4m 8s (remain 7m 2s) Loss: 0.2483(0.3238) Grad: 160521.0781  LR: 0.00000369  \n","Epoch: [2][580/1515] Elapsed 4m 17s (remain 6m 54s) Loss: 0.2087(0.3252) Grad: 174027.3438  LR: 0.00000366  \n","Epoch: [2][600/1515] Elapsed 4m 26s (remain 6m 45s) Loss: 0.2014(0.3251) Grad: 91430.4141  LR: 0.00000364  \n","Epoch: [2][620/1515] Elapsed 4m 35s (remain 6m 36s) Loss: 0.2689(0.3257) Grad: 152775.0312  LR: 0.00000362  \n","Epoch: [2][640/1515] Elapsed 4m 44s (remain 6m 27s) Loss: 0.6152(0.3266) Grad: 186366.3594  LR: 0.00000360  \n","Epoch: [2][660/1515] Elapsed 4m 53s (remain 6m 18s) Loss: 0.5940(0.3266) Grad: 130563.2656  LR: 0.00000357  \n","Epoch: [2][680/1515] Elapsed 5m 2s (remain 6m 9s) Loss: 0.2870(0.3251) Grad: 103521.0312  LR: 0.00000355  \n","Epoch: [2][700/1515] Elapsed 5m 10s (remain 6m 0s) Loss: 0.3366(0.3250) Grad: 155042.5000  LR: 0.00000352  \n","Epoch: [2][720/1515] Elapsed 5m 19s (remain 5m 51s) Loss: 0.3637(0.3250) Grad: 235494.9844  LR: 0.00000350  \n","Epoch: [2][740/1515] Elapsed 5m 28s (remain 5m 43s) Loss: 0.5164(0.3261) Grad: 155612.2656  LR: 0.00000348  \n","Epoch: [2][760/1515] Elapsed 5m 37s (remain 5m 34s) Loss: 0.3296(0.3271) Grad: 252002.9531  LR: 0.00000345  \n","Epoch: [2][780/1515] Elapsed 5m 46s (remain 5m 25s) Loss: 0.3211(0.3276) Grad: 142803.4375  LR: 0.00000343  \n","Epoch: [2][800/1515] Elapsed 5m 54s (remain 5m 16s) Loss: 0.3362(0.3272) Grad: 197413.9219  LR: 0.00000341  \n","Epoch: [2][820/1515] Elapsed 6m 3s (remain 5m 7s) Loss: 0.4873(0.3269) Grad: 318711.3125  LR: 0.00000338  \n","Epoch: [2][840/1515] Elapsed 6m 12s (remain 4m 58s) Loss: 0.1441(0.3266) Grad: 153801.8906  LR: 0.00000336  \n","Epoch: [2][860/1515] Elapsed 6m 21s (remain 4m 49s) Loss: 0.5849(0.3269) Grad: 168320.8125  LR: 0.00000333  \n","Epoch: [2][880/1515] Elapsed 6m 30s (remain 4m 40s) Loss: 0.2645(0.3265) Grad: 201967.9219  LR: 0.00000331  \n","Epoch: [2][900/1515] Elapsed 6m 39s (remain 4m 32s) Loss: 0.2832(0.3262) Grad: 175114.1719  LR: 0.00000328  \n","Epoch: [2][920/1515] Elapsed 6m 48s (remain 4m 23s) Loss: 0.1858(0.3257) Grad: 282292.2188  LR: 0.00000326  \n","Epoch: [2][940/1515] Elapsed 6m 57s (remain 4m 14s) Loss: 0.1420(0.3253) Grad: 172702.3125  LR: 0.00000323  \n","Epoch: [2][960/1515] Elapsed 7m 6s (remain 4m 5s) Loss: 0.3143(0.3254) Grad: 154148.4062  LR: 0.00000321  \n","Epoch: [2][980/1515] Elapsed 7m 14s (remain 3m 56s) Loss: 0.3106(0.3248) Grad: 228914.7344  LR: 0.00000318  \n","Epoch: [2][1000/1515] Elapsed 7m 23s (remain 3m 47s) Loss: 0.4580(0.3245) Grad: 237164.2969  LR: 0.00000316  \n","Epoch: [2][1020/1515] Elapsed 7m 32s (remain 3m 39s) Loss: 0.1970(0.3245) Grad: 292251.2812  LR: 0.00000313  \n","Epoch: [2][1040/1515] Elapsed 7m 41s (remain 3m 30s) Loss: 0.3546(0.3242) Grad: 147737.6250  LR: 0.00000311  \n","Epoch: [2][1060/1515] Elapsed 7m 50s (remain 3m 21s) Loss: 0.2614(0.3238) Grad: 161822.4844  LR: 0.00000308  \n","Epoch: [2][1080/1515] Elapsed 7m 59s (remain 3m 12s) Loss: 0.3947(0.3240) Grad: 202235.5000  LR: 0.00000306  \n","Epoch: [2][1100/1515] Elapsed 8m 8s (remain 3m 3s) Loss: 0.2713(0.3245) Grad: 252335.2500  LR: 0.00000303  \n","Epoch: [2][1120/1515] Elapsed 8m 17s (remain 2m 54s) Loss: 0.5227(0.3247) Grad: 383861.5312  LR: 0.00000301  \n","Epoch: [2][1140/1515] Elapsed 8m 26s (remain 2m 45s) Loss: 0.2875(0.3242) Grad: 433241.4688  LR: 0.00000298  \n","Epoch: [2][1160/1515] Elapsed 8m 34s (remain 2m 37s) Loss: 0.2814(0.3245) Grad: 105764.5859  LR: 0.00000296  \n","Epoch: [2][1180/1515] Elapsed 8m 43s (remain 2m 28s) Loss: 0.3470(0.3242) Grad: 265933.5000  LR: 0.00000293  \n","Epoch: [2][1200/1515] Elapsed 8m 52s (remain 2m 19s) Loss: 0.1808(0.3248) Grad: 253741.4844  LR: 0.00000291  \n","Epoch: [2][1220/1515] Elapsed 9m 1s (remain 2m 10s) Loss: 0.3387(0.3245) Grad: 185951.0469  LR: 0.00000288  \n","Epoch: [2][1240/1515] Elapsed 9m 10s (remain 2m 1s) Loss: 0.3569(0.3240) Grad: 157304.8125  LR: 0.00000286  \n","Epoch: [2][1260/1515] Elapsed 9m 19s (remain 1m 52s) Loss: 0.2483(0.3239) Grad: 202513.7812  LR: 0.00000283  \n","Epoch: [2][1280/1515] Elapsed 9m 27s (remain 1m 43s) Loss: 0.2975(0.3230) Grad: 118547.4609  LR: 0.00000280  \n","Epoch: [2][1300/1515] Elapsed 9m 36s (remain 1m 34s) Loss: 0.3148(0.3226) Grad: 60038.9805  LR: 0.00000278  \n","Epoch: [2][1320/1515] Elapsed 9m 45s (remain 1m 26s) Loss: 0.2816(0.3223) Grad: 108227.0312  LR: 0.00000275  \n","Epoch: [2][1340/1515] Elapsed 9m 54s (remain 1m 17s) Loss: 0.1301(0.3223) Grad: 188839.4219  LR: 0.00000273  \n","Epoch: [2][1360/1515] Elapsed 10m 3s (remain 1m 8s) Loss: 0.2812(0.3226) Grad: 92607.4844  LR: 0.00000270  \n","Epoch: [2][1380/1515] Elapsed 10m 12s (remain 0m 59s) Loss: 0.3870(0.3233) Grad: 103395.5547  LR: 0.00000267  \n","Epoch: [2][1400/1515] Elapsed 10m 20s (remain 0m 50s) Loss: 0.3623(0.3234) Grad: 151951.9844  LR: 0.00000265  \n","Epoch: [2][1420/1515] Elapsed 10m 29s (remain 0m 41s) Loss: 0.3201(0.3234) Grad: 128272.8438  LR: 0.00000262  \n","Epoch: [2][1440/1515] Elapsed 10m 38s (remain 0m 32s) Loss: 0.3477(0.3233) Grad: 201870.6562  LR: 0.00000260  \n","Epoch: [2][1460/1515] Elapsed 10m 47s (remain 0m 23s) Loss: 0.2860(0.3234) Grad: 112611.8125  LR: 0.00000257  \n","Epoch: [2][1480/1515] Elapsed 10m 56s (remain 0m 15s) Loss: 0.3452(0.3235) Grad: 172593.5938  LR: 0.00000255  \n","Epoch: [2][1500/1515] Elapsed 11m 5s (remain 0m 6s) Loss: 0.3195(0.3240) Grad: 185979.0156  LR: 0.00000252  \n","Epoch: [2][1514/1515] Elapsed 11m 11s (remain 0m 0s) Loss: 0.1326(0.3233) Grad: 156136.7656  LR: 0.00000250  \n","EVAL: [0/138] Elapsed 0m 0s (remain 1m 57s) Loss: 0.6647(0.6647) \n","EVAL: [20/138] Elapsed 0m 12s (remain 1m 6s) Loss: 0.4417(0.5043) \n","EVAL: [40/138] Elapsed 0m 23s (remain 0m 54s) Loss: 0.6281(0.5272) \n","EVAL: [60/138] Elapsed 0m 34s (remain 0m 42s) Loss: 0.4796(0.5073) \n","EVAL: [80/138] Elapsed 0m 45s (remain 0m 32s) Loss: 0.3847(0.5073) \n","EVAL: [100/138] Elapsed 0m 57s (remain 0m 20s) Loss: 0.5369(0.5041) \n","EVAL: [120/138] Elapsed 1m 8s (remain 0m 9s) Loss: 0.3312(0.4997) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.3233  avg_val_loss: 0.5017  time: 750s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.3233  avg_val_loss: 0.5017  time: 750s\n","Epoch 2 - Score: 0.6588  Scores: [0.5407697951516193, 0.7769109001542583]\n","INFO:__main__:Epoch 2 - Score: 0.6588  Scores: [0.5407697951516193, 0.7769109001542583]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [137/138] Elapsed 1m 18s (remain 0m 0s) Loss: 0.7540(0.5017) \n","Epoch: [3][0/1515] Elapsed 0m 0s (remain 16m 50s) Loss: 0.1356(0.1356) Grad: inf  LR: 0.00000250  \n","Epoch: [3][20/1515] Elapsed 0m 9s (remain 10m 54s) Loss: 0.3898(0.2745) Grad: 141290.2812  LR: 0.00000247  \n","Epoch: [3][40/1515] Elapsed 0m 18s (remain 10m 47s) Loss: 0.3547(0.2878) Grad: 113002.1094  LR: 0.00000245  \n","Epoch: [3][60/1515] Elapsed 0m 26s (remain 10m 27s) Loss: 0.3050(0.2786) Grad: 170458.1250  LR: 0.00000242  \n","Epoch: [3][80/1515] Elapsed 0m 35s (remain 10m 20s) Loss: 0.1680(0.2808) Grad: 124902.6406  LR: 0.00000240  \n","Epoch: [3][100/1515] Elapsed 0m 44s (remain 10m 17s) Loss: 0.2699(0.2757) Grad: 209243.7812  LR: 0.00000237  \n","Epoch: [3][120/1515] Elapsed 0m 53s (remain 10m 10s) Loss: 0.3140(0.2805) Grad: 200345.9531  LR: 0.00000234  \n","Epoch: [3][140/1515] Elapsed 1m 1s (remain 10m 2s) Loss: 0.3792(0.2824) Grad: 337925.9688  LR: 0.00000232  \n","Epoch: [3][160/1515] Elapsed 1m 10s (remain 9m 54s) Loss: 0.1196(0.2835) Grad: 179109.7656  LR: 0.00000229  \n","Epoch: [3][180/1515] Elapsed 1m 19s (remain 9m 48s) Loss: 0.6216(0.2850) Grad: 246814.5312  LR: 0.00000227  \n","Epoch: [3][200/1515] Elapsed 1m 28s (remain 9m 40s) Loss: 0.2167(0.2890) Grad: 221778.8281  LR: 0.00000224  \n","Epoch: [3][220/1515] Elapsed 1m 37s (remain 9m 30s) Loss: 0.2174(0.2853) Grad: 179909.2812  LR: 0.00000222  \n","Epoch: [3][240/1515] Elapsed 1m 46s (remain 9m 22s) Loss: 0.1592(0.2862) Grad: 144502.2812  LR: 0.00000219  \n","Epoch: [3][260/1515] Elapsed 1m 55s (remain 9m 13s) Loss: 0.2279(0.2866) Grad: 111517.1250  LR: 0.00000216  \n","Epoch: [3][280/1515] Elapsed 2m 4s (remain 9m 5s) Loss: 0.2013(0.2834) Grad: 224785.5625  LR: 0.00000214  \n","Epoch: [3][300/1515] Elapsed 2m 13s (remain 8m 56s) Loss: 0.3338(0.2843) Grad: 233866.5156  LR: 0.00000211  \n","Epoch: [3][320/1515] Elapsed 2m 21s (remain 8m 48s) Loss: 0.2846(0.2846) Grad: 126565.6172  LR: 0.00000209  \n","Epoch: [3][340/1515] Elapsed 2m 30s (remain 8m 39s) Loss: 0.4205(0.2869) Grad: 326236.3125  LR: 0.00000206  \n","Epoch: [3][360/1515] Elapsed 2m 39s (remain 8m 29s) Loss: 0.3142(0.2862) Grad: 107276.7734  LR: 0.00000204  \n","Epoch: [3][380/1515] Elapsed 2m 48s (remain 8m 21s) Loss: 0.3511(0.2846) Grad: 198013.5000  LR: 0.00000201  \n","Epoch: [3][400/1515] Elapsed 2m 57s (remain 8m 13s) Loss: 0.1430(0.2847) Grad: 184981.6719  LR: 0.00000199  \n","Epoch: [3][420/1515] Elapsed 3m 6s (remain 8m 4s) Loss: 0.1477(0.2833) Grad: 122366.1172  LR: 0.00000196  \n","Epoch: [3][440/1515] Elapsed 3m 15s (remain 7m 55s) Loss: 0.4311(0.2850) Grad: 182284.8125  LR: 0.00000193  \n","Epoch: [3][460/1515] Elapsed 3m 24s (remain 7m 47s) Loss: 0.1660(0.2867) Grad: 214430.4844  LR: 0.00000191  \n","Epoch: [3][480/1515] Elapsed 3m 33s (remain 7m 38s) Loss: 0.2292(0.2862) Grad: 110881.4297  LR: 0.00000188  \n","Epoch: [3][500/1515] Elapsed 3m 41s (remain 7m 28s) Loss: 0.3048(0.2879) Grad: 113690.6484  LR: 0.00000186  \n","Epoch: [3][520/1515] Elapsed 3m 50s (remain 7m 20s) Loss: 0.2447(0.2888) Grad: 329259.7812  LR: 0.00000183  \n","Epoch: [3][540/1515] Elapsed 3m 59s (remain 7m 10s) Loss: 0.3536(0.2889) Grad: 109588.9766  LR: 0.00000181  \n","Epoch: [3][560/1515] Elapsed 4m 8s (remain 7m 2s) Loss: 0.1686(0.2880) Grad: 114178.5156  LR: 0.00000178  \n","Epoch: [3][580/1515] Elapsed 4m 17s (remain 6m 53s) Loss: 0.3478(0.2877) Grad: 196457.7188  LR: 0.00000176  \n","Epoch: [3][600/1515] Elapsed 4m 25s (remain 6m 43s) Loss: 0.2141(0.2877) Grad: 208464.4375  LR: 0.00000174  \n","Epoch: [3][620/1515] Elapsed 4m 34s (remain 6m 34s) Loss: 0.4471(0.2874) Grad: 194485.7031  LR: 0.00000171  \n","Epoch: [3][640/1515] Elapsed 4m 43s (remain 6m 26s) Loss: 0.2311(0.2870) Grad: 235609.6719  LR: 0.00000169  \n","Epoch: [3][660/1515] Elapsed 4m 51s (remain 6m 17s) Loss: 0.3484(0.2875) Grad: 288802.9062  LR: 0.00000166  \n","Epoch: [3][680/1515] Elapsed 5m 0s (remain 6m 8s) Loss: 0.2297(0.2874) Grad: 226295.4531  LR: 0.00000164  \n","Epoch: [3][700/1515] Elapsed 5m 9s (remain 5m 59s) Loss: 0.3551(0.2876) Grad: 292295.0625  LR: 0.00000161  \n","Epoch: [3][720/1515] Elapsed 5m 18s (remain 5m 50s) Loss: 0.3697(0.2876) Grad: 372497.0312  LR: 0.00000159  \n","Epoch: [3][740/1515] Elapsed 5m 27s (remain 5m 41s) Loss: 0.2362(0.2874) Grad: 230482.6875  LR: 0.00000156  \n","Epoch: [3][760/1515] Elapsed 5m 36s (remain 5m 33s) Loss: 0.2916(0.2884) Grad: 159427.6250  LR: 0.00000154  \n","Epoch: [3][780/1515] Elapsed 5m 45s (remain 5m 24s) Loss: 0.1596(0.2887) Grad: 199064.2031  LR: 0.00000152  \n","Epoch: [3][800/1515] Elapsed 5m 53s (remain 5m 15s) Loss: 0.1349(0.2887) Grad: 148898.2344  LR: 0.00000149  \n","Epoch: [3][820/1515] Elapsed 6m 2s (remain 5m 6s) Loss: 0.3828(0.2897) Grad: 144118.4219  LR: 0.00000147  \n","Epoch: [3][840/1515] Elapsed 6m 11s (remain 4m 57s) Loss: 0.1749(0.2896) Grad: 161363.4219  LR: 0.00000145  \n","Epoch: [3][860/1515] Elapsed 6m 20s (remain 4m 48s) Loss: 0.2307(0.2896) Grad: 186228.2812  LR: 0.00000142  \n","Epoch: [3][880/1515] Elapsed 6m 29s (remain 4m 40s) Loss: 0.3828(0.2901) Grad: 322315.6250  LR: 0.00000140  \n","Epoch: [3][900/1515] Elapsed 6m 38s (remain 4m 31s) Loss: 0.2031(0.2903) Grad: 144604.2656  LR: 0.00000138  \n","Epoch: [3][920/1515] Elapsed 6m 47s (remain 4m 22s) Loss: 0.2431(0.2900) Grad: 316859.2812  LR: 0.00000135  \n","Epoch: [3][940/1515] Elapsed 6m 55s (remain 4m 13s) Loss: 0.1613(0.2902) Grad: 184383.5156  LR: 0.00000133  \n","Epoch: [3][960/1515] Elapsed 7m 4s (remain 4m 4s) Loss: 0.2806(0.2909) Grad: 285271.0625  LR: 0.00000131  \n","Epoch: [3][980/1515] Elapsed 7m 13s (remain 3m 55s) Loss: 0.2027(0.2915) Grad: 116285.2422  LR: 0.00000128  \n","Epoch: [3][1000/1515] Elapsed 7m 21s (remain 3m 46s) Loss: 0.3835(0.2917) Grad: 161983.9844  LR: 0.00000126  \n","Epoch: [3][1020/1515] Elapsed 7m 31s (remain 3m 38s) Loss: 0.2821(0.2928) Grad: 220746.4375  LR: 0.00000124  \n","Epoch: [3][1040/1515] Elapsed 7m 40s (remain 3m 29s) Loss: 0.2954(0.2929) Grad: 382009.8750  LR: 0.00000122  \n","Epoch: [3][1060/1515] Elapsed 7m 48s (remain 3m 20s) Loss: 0.1627(0.2924) Grad: 137655.0312  LR: 0.00000119  \n","Epoch: [3][1080/1515] Elapsed 7m 57s (remain 3m 11s) Loss: 0.2463(0.2917) Grad: 342733.3750  LR: 0.00000117  \n","Epoch: [3][1100/1515] Elapsed 8m 6s (remain 3m 2s) Loss: 0.2928(0.2924) Grad: 130699.6953  LR: 0.00000115  \n","Epoch: [3][1120/1515] Elapsed 8m 14s (remain 2m 53s) Loss: 0.1952(0.2926) Grad: 148597.5625  LR: 0.00000113  \n","Epoch: [3][1140/1515] Elapsed 8m 23s (remain 2m 45s) Loss: 0.1294(0.2919) Grad: 82363.5703  LR: 0.00000111  \n","Epoch: [3][1160/1515] Elapsed 8m 33s (remain 2m 36s) Loss: 0.3235(0.2916) Grad: 174741.1875  LR: 0.00000109  \n","Epoch: [3][1180/1515] Elapsed 8m 41s (remain 2m 27s) Loss: 0.2329(0.2919) Grad: 177657.2500  LR: 0.00000106  \n","Epoch: [3][1200/1515] Elapsed 8m 50s (remain 2m 18s) Loss: 0.3567(0.2923) Grad: 184621.9219  LR: 0.00000104  \n","Epoch: [3][1220/1515] Elapsed 8m 59s (remain 2m 9s) Loss: 0.3253(0.2921) Grad: 137126.7656  LR: 0.00000102  \n","Epoch: [3][1240/1515] Elapsed 9m 8s (remain 2m 1s) Loss: 0.4269(0.2924) Grad: 287074.8125  LR: 0.00000100  \n","Epoch: [3][1260/1515] Elapsed 9m 17s (remain 1m 52s) Loss: 0.2026(0.2923) Grad: 227462.5938  LR: 0.00000098  \n","Epoch: [3][1280/1515] Elapsed 9m 25s (remain 1m 43s) Loss: 0.2617(0.2923) Grad: 155393.6406  LR: 0.00000096  \n","Epoch: [3][1300/1515] Elapsed 9m 34s (remain 1m 34s) Loss: 0.2590(0.2922) Grad: 121630.7109  LR: 0.00000094  \n","Epoch: [3][1320/1515] Elapsed 9m 43s (remain 1m 25s) Loss: 0.3014(0.2928) Grad: 112496.6875  LR: 0.00000092  \n","Epoch: [3][1340/1515] Elapsed 9m 52s (remain 1m 16s) Loss: 0.1960(0.2927) Grad: 142126.5781  LR: 0.00000090  \n","Epoch: [3][1360/1515] Elapsed 10m 0s (remain 1m 7s) Loss: 0.3086(0.2930) Grad: 206888.5469  LR: 0.00000088  \n","Epoch: [3][1380/1515] Elapsed 10m 9s (remain 0m 59s) Loss: 0.5724(0.2931) Grad: 270732.1875  LR: 0.00000086  \n","Epoch: [3][1400/1515] Elapsed 10m 18s (remain 0m 50s) Loss: 0.2074(0.2926) Grad: 126493.9453  LR: 0.00000084  \n","Epoch: [3][1420/1515] Elapsed 10m 27s (remain 0m 41s) Loss: 0.3263(0.2929) Grad: 143551.9375  LR: 0.00000082  \n","Epoch: [3][1440/1515] Elapsed 10m 36s (remain 0m 32s) Loss: 0.2889(0.2931) Grad: 133125.1719  LR: 0.00000080  \n","Epoch: [3][1460/1515] Elapsed 10m 44s (remain 0m 23s) Loss: 0.3008(0.2927) Grad: 328820.8750  LR: 0.00000078  \n","Epoch: [3][1480/1515] Elapsed 10m 53s (remain 0m 15s) Loss: 0.2608(0.2926) Grad: 244710.4531  LR: 0.00000077  \n","Epoch: [3][1500/1515] Elapsed 11m 2s (remain 0m 6s) Loss: 0.3090(0.2929) Grad: 209172.8906  LR: 0.00000075  \n","Epoch: [3][1514/1515] Elapsed 11m 8s (remain 0m 0s) Loss: 0.3301(0.2929) Grad: 132450.6719  LR: 0.00000073  \n","EVAL: [0/138] Elapsed 0m 0s (remain 1m 59s) Loss: 0.6196(0.6196) \n","EVAL: [20/138] Elapsed 0m 12s (remain 1m 6s) Loss: 0.4358(0.4635) \n","EVAL: [40/138] Elapsed 0m 23s (remain 0m 54s) Loss: 0.5509(0.4828) \n","EVAL: [60/138] Elapsed 0m 34s (remain 0m 42s) Loss: 0.3972(0.4644) \n","EVAL: [80/138] Elapsed 0m 45s (remain 0m 32s) Loss: 0.3814(0.4628) \n","EVAL: [100/138] Elapsed 0m 57s (remain 0m 20s) Loss: 0.4499(0.4609) \n","EVAL: [120/138] Elapsed 1m 8s (remain 0m 9s) Loss: 0.3208(0.4575) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2929  avg_val_loss: 0.4597  time: 747s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2929  avg_val_loss: 0.4597  time: 747s\n","Epoch 3 - Score: 0.6129  Scores: [0.5357666646148573, 0.6901104257719244]\n","INFO:__main__:Epoch 3 - Score: 0.6129  Scores: [0.5357666646148573, 0.6901104257719244]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [137/138] Elapsed 1m 18s (remain 0m 0s) Loss: 0.7014(0.4597) \n","Epoch: [4][0/1515] Elapsed 0m 0s (remain 16m 57s) Loss: 0.2927(0.2927) Grad: inf  LR: 0.00000073  \n","Epoch: [4][20/1515] Elapsed 0m 9s (remain 11m 9s) Loss: 0.2369(0.2473) Grad: 182689.9531  LR: 0.00000071  \n","Epoch: [4][40/1515] Elapsed 0m 18s (remain 10m 56s) Loss: 0.3259(0.2563) Grad: 125358.7188  LR: 0.00000070  \n","Epoch: [4][60/1515] Elapsed 0m 27s (remain 10m 45s) Loss: 0.3861(0.2837) Grad: 295428.0938  LR: 0.00000068  \n","Epoch: [4][80/1515] Elapsed 0m 35s (remain 10m 35s) Loss: 0.2564(0.2794) Grad: 195317.1094  LR: 0.00000066  \n","Epoch: [4][100/1515] Elapsed 0m 44s (remain 10m 24s) Loss: 0.2081(0.2752) Grad: 133530.8750  LR: 0.00000064  \n","Epoch: [4][120/1515] Elapsed 0m 53s (remain 10m 15s) Loss: 0.2561(0.2774) Grad: 141522.0156  LR: 0.00000063  \n","Epoch: [4][140/1515] Elapsed 1m 2s (remain 10m 5s) Loss: 0.1376(0.2750) Grad: 80357.1328  LR: 0.00000061  \n","Epoch: [4][160/1515] Elapsed 1m 10s (remain 9m 54s) Loss: 0.1892(0.2768) Grad: 185809.5625  LR: 0.00000059  \n","Epoch: [4][180/1515] Elapsed 1m 19s (remain 9m 47s) Loss: 0.2527(0.2758) Grad: 227972.5469  LR: 0.00000058  \n","Epoch: [4][200/1515] Elapsed 1m 28s (remain 9m 38s) Loss: 0.1624(0.2762) Grad: 248969.7812  LR: 0.00000056  \n","Epoch: [4][220/1515] Elapsed 1m 37s (remain 9m 29s) Loss: 0.1666(0.2740) Grad: 298918.4062  LR: 0.00000054  \n","Epoch: [4][240/1515] Elapsed 1m 46s (remain 9m 21s) Loss: 0.3136(0.2753) Grad: 212491.9219  LR: 0.00000053  \n","Epoch: [4][260/1515] Elapsed 1m 55s (remain 9m 13s) Loss: 0.3731(0.2738) Grad: 196913.6562  LR: 0.00000051  \n","Epoch: [4][280/1515] Elapsed 2m 3s (remain 9m 4s) Loss: 0.2329(0.2723) Grad: 209778.3438  LR: 0.00000050  \n","Epoch: [4][300/1515] Elapsed 2m 13s (remain 8m 57s) Loss: 0.3224(0.2737) Grad: 303255.0000  LR: 0.00000048  \n","Epoch: [4][320/1515] Elapsed 2m 22s (remain 8m 48s) Loss: 0.2057(0.2718) Grad: 171340.3125  LR: 0.00000047  \n","Epoch: [4][340/1515] Elapsed 2m 30s (remain 8m 39s) Loss: 0.2667(0.2717) Grad: 189256.4844  LR: 0.00000045  \n","Epoch: [4][360/1515] Elapsed 2m 39s (remain 8m 30s) Loss: 0.2243(0.2712) Grad: 399693.7812  LR: 0.00000044  \n","Epoch: [4][380/1515] Elapsed 2m 48s (remain 8m 22s) Loss: 0.3390(0.2705) Grad: 251247.2500  LR: 0.00000042  \n","Epoch: [4][400/1515] Elapsed 2m 58s (remain 8m 14s) Loss: 0.3877(0.2693) Grad: 248647.3281  LR: 0.00000041  \n","Epoch: [4][420/1515] Elapsed 3m 6s (remain 8m 5s) Loss: 0.5109(0.2682) Grad: 137997.4219  LR: 0.00000039  \n","Epoch: [4][440/1515] Elapsed 3m 15s (remain 7m 56s) Loss: 0.3224(0.2682) Grad: 228782.4688  LR: 0.00000038  \n","Epoch: [4][460/1515] Elapsed 3m 24s (remain 7m 47s) Loss: 0.1952(0.2686) Grad: 135698.7656  LR: 0.00000037  \n","Epoch: [4][480/1515] Elapsed 3m 33s (remain 7m 39s) Loss: 0.2360(0.2674) Grad: 221728.5781  LR: 0.00000035  \n","Epoch: [4][500/1515] Elapsed 3m 42s (remain 7m 29s) Loss: 0.1957(0.2680) Grad: 233066.7812  LR: 0.00000034  \n","Epoch: [4][520/1515] Elapsed 3m 51s (remain 7m 21s) Loss: 0.3712(0.2684) Grad: 150279.8906  LR: 0.00000033  \n","Epoch: [4][540/1515] Elapsed 4m 0s (remain 7m 12s) Loss: 0.2488(0.2680) Grad: 153312.7188  LR: 0.00000031  \n","Epoch: [4][560/1515] Elapsed 4m 9s (remain 7m 3s) Loss: 0.1949(0.2676) Grad: 215183.5156  LR: 0.00000030  \n","Epoch: [4][580/1515] Elapsed 4m 18s (remain 6m 55s) Loss: 0.2592(0.2670) Grad: 133975.7812  LR: 0.00000029  \n","Epoch: [4][600/1515] Elapsed 4m 27s (remain 6m 46s) Loss: 0.1391(0.2680) Grad: 125582.4219  LR: 0.00000028  \n","Epoch: [4][620/1515] Elapsed 4m 36s (remain 6m 38s) Loss: 0.2826(0.2680) Grad: 217288.9688  LR: 0.00000026  \n","Epoch: [4][640/1515] Elapsed 4m 45s (remain 6m 29s) Loss: 0.1654(0.2677) Grad: 160705.1094  LR: 0.00000025  \n","Epoch: [4][660/1515] Elapsed 4m 54s (remain 6m 20s) Loss: 0.2775(0.2673) Grad: 219495.4688  LR: 0.00000024  \n","Epoch: [4][680/1515] Elapsed 5m 3s (remain 6m 11s) Loss: 0.2724(0.2669) Grad: 139133.8750  LR: 0.00000023  \n","Epoch: [4][700/1515] Elapsed 5m 12s (remain 6m 2s) Loss: 0.5003(0.2675) Grad: 247598.6875  LR: 0.00000022  \n","Epoch: [4][720/1515] Elapsed 5m 20s (remain 5m 53s) Loss: 0.5270(0.2678) Grad: 148893.4688  LR: 0.00000021  \n","Epoch: [4][740/1515] Elapsed 5m 29s (remain 5m 44s) Loss: 0.4605(0.2682) Grad: 199107.3438  LR: 0.00000020  \n","Epoch: [4][760/1515] Elapsed 5m 38s (remain 5m 35s) Loss: 0.3586(0.2676) Grad: 185694.6250  LR: 0.00000019  \n","Epoch: [4][780/1515] Elapsed 5m 47s (remain 5m 26s) Loss: 0.2298(0.2673) Grad: 198919.9844  LR: 0.00000018  \n","Epoch: [4][800/1515] Elapsed 5m 56s (remain 5m 17s) Loss: 0.4432(0.2670) Grad: 189915.1875  LR: 0.00000017  \n","Epoch: [4][820/1515] Elapsed 6m 4s (remain 5m 8s) Loss: 0.2936(0.2672) Grad: 306997.0312  LR: 0.00000016  \n","Epoch: [4][840/1515] Elapsed 6m 13s (remain 4m 59s) Loss: 0.2823(0.2679) Grad: 163896.0312  LR: 0.00000015  \n","Epoch: [4][860/1515] Elapsed 6m 22s (remain 4m 50s) Loss: 0.3818(0.2672) Grad: 215792.7969  LR: 0.00000014  \n","Epoch: [4][880/1515] Elapsed 6m 31s (remain 4m 41s) Loss: 0.1660(0.2671) Grad: 137590.7500  LR: 0.00000013  \n","Epoch: [4][900/1515] Elapsed 6m 40s (remain 4m 32s) Loss: 0.1366(0.2667) Grad: 136047.8125  LR: 0.00000013  \n","Epoch: [4][920/1515] Elapsed 6m 49s (remain 4m 23s) Loss: 0.2703(0.2665) Grad: 121022.3828  LR: 0.00000012  \n","Epoch: [4][940/1515] Elapsed 6m 57s (remain 4m 14s) Loss: 0.3671(0.2665) Grad: 186624.8906  LR: 0.00000011  \n","Epoch: [4][960/1515] Elapsed 7m 7s (remain 4m 6s) Loss: 0.2516(0.2661) Grad: 146439.3281  LR: 0.00000010  \n","Epoch: [4][980/1515] Elapsed 7m 16s (remain 3m 57s) Loss: 0.2681(0.2660) Grad: 200682.8125  LR: 0.00000010  \n","Epoch: [4][1000/1515] Elapsed 7m 25s (remain 3m 48s) Loss: 0.4406(0.2661) Grad: 172628.7812  LR: 0.00000009  \n","Epoch: [4][1020/1515] Elapsed 7m 34s (remain 3m 39s) Loss: 0.2778(0.2656) Grad: 193433.0156  LR: 0.00000008  \n","Epoch: [4][1040/1515] Elapsed 7m 43s (remain 3m 30s) Loss: 0.3165(0.2650) Grad: 125166.9609  LR: 0.00000008  \n","Epoch: [4][1060/1515] Elapsed 7m 52s (remain 3m 22s) Loss: 0.1567(0.2650) Grad: 277195.1875  LR: 0.00000007  \n","Epoch: [4][1080/1515] Elapsed 8m 1s (remain 3m 13s) Loss: 0.2861(0.2642) Grad: 122045.0469  LR: 0.00000006  \n","Epoch: [4][1100/1515] Elapsed 8m 9s (remain 3m 4s) Loss: 0.2032(0.2642) Grad: 124725.8672  LR: 0.00000006  \n","Epoch: [4][1120/1515] Elapsed 8m 18s (remain 2m 55s) Loss: 0.3578(0.2640) Grad: 174140.6406  LR: 0.00000005  \n","Epoch: [4][1140/1515] Elapsed 8m 27s (remain 2m 46s) Loss: 0.4174(0.2647) Grad: 214728.4531  LR: 0.00000005  \n","Epoch: [4][1160/1515] Elapsed 8m 36s (remain 2m 37s) Loss: 0.2490(0.2647) Grad: 117528.4297  LR: 0.00000004  \n","Epoch: [4][1180/1515] Elapsed 8m 45s (remain 2m 28s) Loss: 0.2037(0.2643) Grad: 175541.8281  LR: 0.00000004  \n","Epoch: [4][1200/1515] Elapsed 8m 54s (remain 2m 19s) Loss: 0.2030(0.2646) Grad: 213235.0781  LR: 0.00000003  \n","Epoch: [4][1220/1515] Elapsed 9m 3s (remain 2m 10s) Loss: 0.3594(0.2641) Grad: 103053.3125  LR: 0.00000003  \n","Epoch: [4][1240/1515] Elapsed 9m 12s (remain 2m 1s) Loss: 0.4042(0.2642) Grad: 126612.7266  LR: 0.00000003  \n","Epoch: [4][1260/1515] Elapsed 9m 20s (remain 1m 52s) Loss: 0.2601(0.2646) Grad: 275391.9062  LR: 0.00000002  \n","Epoch: [4][1280/1515] Elapsed 9m 29s (remain 1m 44s) Loss: 0.2475(0.2645) Grad: 435453.1562  LR: 0.00000002  \n","Epoch: [4][1300/1515] Elapsed 9m 38s (remain 1m 35s) Loss: 0.1887(0.2648) Grad: 169084.1094  LR: 0.00000002  \n","Epoch: [4][1320/1515] Elapsed 9m 47s (remain 1m 26s) Loss: 0.3056(0.2645) Grad: 145667.4219  LR: 0.00000001  \n","Epoch: [4][1340/1515] Elapsed 9m 55s (remain 1m 17s) Loss: 0.2528(0.2647) Grad: 225348.6562  LR: 0.00000001  \n","Epoch: [4][1360/1515] Elapsed 10m 4s (remain 1m 8s) Loss: 0.2883(0.2646) Grad: 260610.4531  LR: 0.00000001  \n","Epoch: [4][1380/1515] Elapsed 10m 13s (remain 0m 59s) Loss: 0.2354(0.2641) Grad: 117086.5234  LR: 0.00000001  \n","Epoch: [4][1400/1515] Elapsed 10m 22s (remain 0m 50s) Loss: 0.1400(0.2639) Grad: 121269.9062  LR: 0.00000000  \n","Epoch: [4][1420/1515] Elapsed 10m 31s (remain 0m 41s) Loss: 0.0879(0.2640) Grad: 149503.7812  LR: 0.00000000  \n","Epoch: [4][1440/1515] Elapsed 10m 40s (remain 0m 32s) Loss: 0.4285(0.2649) Grad: 241510.5000  LR: 0.00000000  \n","Epoch: [4][1460/1515] Elapsed 10m 48s (remain 0m 23s) Loss: 0.4159(0.2651) Grad: 121045.6016  LR: 0.00000000  \n","Epoch: [4][1480/1515] Elapsed 10m 57s (remain 0m 15s) Loss: 0.1541(0.2651) Grad: 237100.4219  LR: 0.00000000  \n","Epoch: [4][1500/1515] Elapsed 11m 7s (remain 0m 6s) Loss: 0.3400(0.2649) Grad: 125149.9297  LR: 0.00000000  \n","Epoch: [4][1514/1515] Elapsed 11m 12s (remain 0m 0s) Loss: 0.2123(0.2648) Grad: 164408.9531  LR: 0.00000000  \n","EVAL: [0/138] Elapsed 0m 0s (remain 1m 58s) Loss: 0.5988(0.5988) \n","EVAL: [20/138] Elapsed 0m 12s (remain 1m 6s) Loss: 0.4463(0.4522) \n","EVAL: [40/138] Elapsed 0m 23s (remain 0m 54s) Loss: 0.5415(0.4683) \n","EVAL: [60/138] Elapsed 0m 34s (remain 0m 42s) Loss: 0.3779(0.4516) \n","EVAL: [80/138] Elapsed 0m 45s (remain 0m 32s) Loss: 0.3747(0.4502) \n","EVAL: [100/138] Elapsed 0m 57s (remain 0m 20s) Loss: 0.4129(0.4472) \n","EVAL: [120/138] Elapsed 1m 8s (remain 0m 9s) Loss: 0.3197(0.4444) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2648  avg_val_loss: 0.4459  time: 752s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2648  avg_val_loss: 0.4459  time: 752s\n","Epoch 4 - Score: 0.5905  Scores: [0.5192799085390658, 0.6617847598499629]\n","INFO:__main__:Epoch 4 - Score: 0.5905  Scores: [0.5192799085390658, 0.6617847598499629]\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [137/138] Elapsed 1m 18s (remain 0m 0s) Loss: 0.6599(0.4459) \n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 3 result ==========\n"]}]},{"cell_type":"code","source":["labels = oof_df[CFG.target_cols].values\n","preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n","score, scores = get_score(labels, preds)\n","print(f'Score: {score:<.4f}  Scores: {scores}')"],"metadata":{"id":"T0Lm0o28OX3g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["runtime.unassign()"],"metadata":{"id":"Hyij14sOkLv8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"R8hQaR0TZMBv"},"execution_count":null,"outputs":[]}]}